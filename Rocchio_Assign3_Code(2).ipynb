{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDzc96y9xCjz",
        "outputId": "a27032fd-bb8d-4fab-8079-001f911a8af5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=ag_news_subset\n",
        "ri = tfds.core.ReadInstruction('train') + tfds.core.ReadInstruction('test')\n",
        "dataset_all, info = tfds.load('ag_news_subset', with_info=True,  split=ri, as_supervised=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-27 04:32:19.889583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-27 04:32:20.537591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-27 04:32:20.538721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "I0827 04:32:20.539829 139958931593088 download_and_prepare.py:200] Running download_and_prepare for dataset(s):\n",
            "ag_news_subset\n",
            "2021-08-27 04:32:20.549199: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
            "2021-08-27 04:32:20.691760: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
            "2021-08-27 04:32:20.830059: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
            "I0827 04:32:20.959832 139958931593088 dataset_info.py:434] Load pre-computed DatasetInfo (eg: splits, num examples,...) from GCS: ag_news_subset/1.0.0\n",
            "2021-08-27 04:32:20.969066: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
            "2021-08-27 04:32:21.317517: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
            "I0827 04:32:21.655322 139958931593088 dataset_info.py:361] Load dataset info from /tmp/tmpva3ortmftfds\n",
            "I0827 04:32:21.657392 139958931593088 download_and_prepare.py:138] download_and_prepare for dataset ag_news_subset/1.0.0...\n",
            "I0827 04:32:21.657783 139958931593088 dataset_builder.py:357] Generating dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "\u001b[1mDownloading and preparing dataset ag_news_subset/1.0.0 (download: 11.24 MiB, generated: 35.79 MiB, total: 47.03 MiB) to /root/tensorflow_datasets/ag_news_subset/1.0.0...\u001b[0m\n",
            "2021-08-27 04:32:21.833882: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
            "2021-08-27 04:32:21.965857: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n",
            "Dl Completed...: 0 url [00:00, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:00, ? file/s]\u001b[A\u001b[AI0827 04:32:22.099136 139958931593088 download_manager.py:476] Downloading https://drive.google.com/uc?export=download&id=0Bz8a_Dbh9QhbUDNpeUdjb0wxRms into /root/tensorflow_datasets/downloads/ucexport_download_id_0Bz8a_Dbh9QhbUDNpeUdjb0wxj4g1umFAV8OV-uDwxSJR0LdxO_k1jxMuFWwAfNX9jos.tmp.ffa3f6f7928c485b92f9851938cfc8a9...\n",
            "Dl Completed...:   0% 0/1 [00:00<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 0 MiB [00:08, ? MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 1 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 2 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 3 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 4 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 5 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 6 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 7 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 8 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 9 MiB [00:08,  8.65s/ MiB]\u001b[A\n",
            "\n",
            "Extraction completed...: 0 file [00:08, ? file/s]\u001b[A\u001b[A\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 10 MiB [00:08,  1.57 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...:   0% 0/1 [00:08<?, ? url/s]\n",
            "Dl Size...: 11 MiB [00:08,  1.57 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:08<00:00,  8.77s/ url]\n",
            "Dl Size...: 11 MiB [00:08,  1.57 MiB/s]\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:08<00:00,  8.77s/ url]\n",
            "Dl Size...: 11 MiB [00:08,  1.57 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...:   0% 0/1 [00:08<?, ? file/s]\u001b[A\u001b[A\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:09<00:00,  8.77s/ url]\n",
            "Dl Size...: 11 MiB [00:09,  1.57 MiB/s]\u001b[A\n",
            "\n",
            "Extraction completed...: 100% 1/1 [00:09<00:00,  9.15s/ file]\u001b[A\u001b[A\n",
            "Extraction completed...: 100% 1/1 [00:09<00:00,  9.15s/ file]\n",
            "\n",
            "Dl Size...: 11 MiB [00:09,  1.20 MiB/s]\n",
            "\n",
            "Dl Completed...: 100% 1/1 [00:09<00:00,  9.15s/ url]\n",
            "I0827 04:32:31.251860 139958931593088 dataset_builder.py:970] Generating split train\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteX7FWT0/ag_news_subset-train.tfrecord\n",
            " 98% 117892/120000 [00:00<00:00, 337819.69 examples/s]I0827 04:33:03.952019 139958931593088 tfrecords_writer.py:226] Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteX7FWT0/ag_news_subset-train.tfrecord. Shard lengths: [120000]\n",
            "I0827 04:33:03.955038 139958931593088 dataset_builder.py:970] Generating split test\n",
            "Shuffling and writing examples to /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteX7FWT0/ag_news_subset-test.tfrecord\n",
            "  0% 0/7600 [00:00<?, ? examples/s]I0827 04:33:05.989964 139958931593088 tfrecords_writer.py:226] Done writing /root/tensorflow_datasets/ag_news_subset/1.0.0.incompleteX7FWT0/ag_news_subset-test.tfrecord. Shard lengths: [7600]\n",
            "I0827 04:33:05.990607 139958931593088 dataset_builder.py:412] Skipping computing stats for mode ComputeStatsMode.SKIP.\n",
            "\u001b[1mDataset ag_news_subset downloaded and prepared to /root/tensorflow_datasets/ag_news_subset/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
            "\u001b[1mname: \"ag_news_subset\"\n",
            "description: \"AG is a collection of more than 1 million news articles.\\nNews articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity.\\nComeToMyHead is an academic news search engine which has been running since July, 2004.\\nThe dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc),\\ninformation retrieval (ranking, search, etc), xml, data compression, data streaming,\\nand any other non-commercial activity.\\nFor more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\\n\\nThe AG\\'s news topic classification dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the dataset above.\\nIt is used as a text classification benchmark in the following paper:\\nXiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\\n\\nThe AG\\'s news topic classification dataset is constructed by choosing 4 largest classes from the original corpus.\\nEach class contains 30,000 training samples and 1,900 testing samples.\\nThe total number of training samples is 120,000 and testing 7,600.\"\n",
            "citation: \"@misc{zhang2015characterlevel,\\n    title={Character-level Convolutional Networks for Text Classification},\\n    author={Xiang Zhang and Junbo Zhao and Yann LeCun},\\n    year={2015},\\n    eprint={1509.01626},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.LG}\\n}\"\n",
            "location {\n",
            "  urls: \"https://arxiv.org/abs/1509.01626\"\n",
            "}\n",
            "splits {\n",
            "  name: \"test\"\n",
            "  shard_lengths: 7600\n",
            "  num_bytes: 2226751\n",
            "}\n",
            "splits {\n",
            "  name: \"train\"\n",
            "  shard_lengths: 120000\n",
            "  num_bytes: 35301386\n",
            "}\n",
            "supervised_keys {\n",
            "  input: \"description\"\n",
            "  output: \"label\"\n",
            "}\n",
            "version: \"1.0.0\"\n",
            "download_size: 11784327\n",
            "\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLN1DQww4opR"
      },
      "source": [
        "fig = px.histogram(comp_df, x='Words_clipped', template='plotly_white', title='Complain counts by length')\n",
        "fig.update_xaxes(categoryorder='total descending', title='Number of words (clipped at 1000 words)').update_yaxes(title='Number of complaints')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "mKVp_v7P1Ipv",
        "outputId": "f972261d-0abf-4fdb-b8be-cbede8fd0274"
      },
      "source": [
        "plt.figure(figsize=(15,9))\n",
        "plt.hist(percents, 20)\n",
        "plt.ylabel('Number of Documents')\n",
        "plt.xlabel('Percent of Non-Vocabulary Words in a Document')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Percent of Non-Vocabulary Words in a Document')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x648 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "VrHLUPq9xLB8",
        "outputId": "82a6f10c-f245-4ed2-da99-54a741c528d7"
      },
      "source": [
        "tfds.as_dataframe(dataset_all.take(10),info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "</style><table id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >description</th>        <th class=\"col_heading level0 col1\" >label</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row0_col0\" class=\"data row0 col0\" >AMD #39;s new dual-core Opteron chip is designed mainly for corporate computing applications, including databases, Web services, and financial transactions.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row0_col1\" class=\"data row0 col1\" >3 (Sci/Tech)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row1_col0\" class=\"data row1 col0\" >Reuters - Major League Baseball\\Monday announced a decision on the appeal filed by Chicago Cubs\\pitcher Kerry Wood regarding a suspension stemming from an\\incident earlier this season.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row1_col1\" class=\"data row1 col1\" >1 (Sports)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row2_col0\" class=\"data row2 col0\" >President Bush #39;s quot;revenue-neutral quot; tax reform needs losers to balance its winners, and people claiming the federal deduction for state and local taxes may be in administration planners #39; sights, news reports say.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row2_col1\" class=\"data row2 col1\" >2 (Business)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row3_col0\" class=\"data row3 col0\" >Britain will run out of leading scientists unless science education is improved, says Professor Colin Pillinger.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row3_col1\" class=\"data row3 col1\" >3 (Sci/Tech)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row4_col0\" class=\"data row4 col0\" >London, England (Sports Network) - England midfielder Steven Gerrard injured his groin late in Thursday #39;s training session, but is hopeful he will be ready for Saturday #39;s World Cup qualifier against Austria.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row4_col1\" class=\"data row4 col1\" >1 (Sports)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row5_col0\" class=\"data row5 col0\" >TOKYO - Sony Corp. is banking on the \\$3 billion deal to acquire Hollywood studio Metro-Goldwyn-Mayer Inc...</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row5_col1\" class=\"data row5 col1\" >0 (World)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row6_col0\" class=\"data row6 col0\" >Giant pandas may well prefer bamboo to laptops, but wireless technology is helping researchers in China in their efforts to protect the engandered animals living in the remote Wolong Nature Reserve.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row6_col1\" class=\"data row6 col1\" >3 (Sci/Tech)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row7_col0\" class=\"data row7 col0\" >VILNIUS, Lithuania - Lithuania #39;s main parties formed an alliance to try to keep a Russian-born tycoon and his populist promises out of the government in Sunday #39;s second round of parliamentary elections in this Baltic country.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row7_col1\" class=\"data row7 col1\" >0 (World)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row8_col0\" class=\"data row8 col0\" >Witnesses in the trial of a US soldier charged with abusing prisoners at Abu Ghraib have told the court that the CIA sometimes directed abuse and orders were received from military command to toughen interrogations.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row8_col1\" class=\"data row8 col1\" >0 (World)</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row9_col0\" class=\"data row9 col0\" >Dan Olsen of Ponte Vedra Beach, Fla., shot a 7-under 65 Thursday to take a one-shot lead after two rounds of the PGA Tour qualifying tournament.</td>\n",
              "                        <td id=\"T_e20c4632_06ef_11ec_a1ad_0242ac1c0002row9_col1\" class=\"data row9 col1\" >1 (Sports)</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "                                         description  label\n",
              "0  b'AMD #39;s new dual-core Opteron chip is desi...      3\n",
              "1  b'Reuters - Major League Baseball\\\\Monday anno...      1\n",
              "2  b'President Bush #39;s  quot;revenue-neutral q...      2\n",
              "3  b'Britain will run out of leading scientists u...      3\n",
              "4  b'London, England (Sports Network) - England m...      1\n",
              "5  b'TOKYO - Sony Corp. is banking on the \\\\$3 bi...      0\n",
              "6  b'Giant pandas may well prefer bamboo to lapto...      3\n",
              "7  b'VILNIUS, Lithuania - Lithuania #39;s main pa...      0\n",
              "8  b'Witnesses in the trial of a US soldier charg...      0\n",
              "9  b'Dan Olsen of Ponte Vedra Beach, Fla., shot a...      1"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TPtKJOA1IhS",
        "outputId": "b74a14e3-b23e-44de-e062-c079c55b496e"
      },
      "source": [
        "%%time\n",
        "encoder_1000 = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=1000)\n",
        "encoder_1000.adapt(dataset_all.map(lambda text, label: text))\n",
        "vocab_1000 = np.array(encoder_1000.get_vocabulary());"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0571e3290> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fc0571e3290>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc0571e3290> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fc0571e3290>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc0571e3290> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fc0571e3290>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "CPU times: user 7min 31s, sys: 2min 7s, total: 9min 39s\n",
            "Wall time: 3min 19s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WkHBlXZQ1InC",
        "outputId": "e07091b9-1516-460e-ceec-4c2cc59e367b"
      },
      "source": [
        "%%time\n",
        "doc1000_sizes = []\n",
        "corpus1000 = []\n",
        "count1000=0\n",
        "useless = 0\n",
        "percents = []\n",
        "for example, _ in dataset_all.as_numpy_iterator():\n",
        "  enc_example = encoder_1000(example)\n",
        "  num_ones = tf.math.count_nonzero(enc_example==1).numpy()\n",
        "  percent_ones = round(num_ones*100/len(enc_example))\n",
        "  percents.append(percent_ones)\n",
        "  s = set(list(enc_example.numpy()))\n",
        "  if s == {1}: useless+=1\n",
        "  doc1000_sizes.append(len(enc_example))\n",
        "  corpus1000+=list(enc_example.numpy())\n",
        "  count1000 += tf.math.count_nonzero(enc_example>1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 18min 3s, sys: 2min 24s, total: 20min 28s\n",
            "Wall time: 16min 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ok4uE771xiq",
        "outputId": "3c643efe-3f2c-4ba0-dcf1-5d258a8ee347"
      },
      "source": [
        "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=ag_news_subset\n",
        "dataset, info = tfds.load('ag_news_subset', with_info=True,  split=['train[:95%]','train[95%:]', 'test[:]'], as_supervised=True)\n",
        "train_dataset, validation_dataset, test_dataset = dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-08-23 08:22:24.930940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 08:22:24.940166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-23 08:22:24.941041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "I0823 08:22:24.941896 140158424983424 download_and_prepare.py:200] Running download_and_prepare for dataset(s):\n",
            "ag_news_subset\n",
            "I0823 08:22:24.942641 140158424983424 dataset_info.py:361] Load dataset info from /root/tensorflow_datasets/ag_news_subset/1.0.0\n",
            "I0823 08:22:24.944212 140158424983424 download_and_prepare.py:138] download_and_prepare for dataset ag_news_subset/1.0.0...\n",
            "I0823 08:22:24.944465 140158424983424 dataset_builder.py:299] Reusing dataset ag_news_subset (/root/tensorflow_datasets/ag_news_subset/1.0.0)\n",
            "\u001b[1mname: \"ag_news_subset\"\n",
            "description: \"AG is a collection of more than 1 million news articles.\\nNews articles have been gathered from more than 2000  news sources by ComeToMyHead in more than 1 year of activity.\\nComeToMyHead is an academic news search engine which has been running since July, 2004.\\nThe dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc),\\ninformation retrieval (ranking, search, etc), xml, data compression, data streaming,\\nand any other non-commercial activity.\\nFor more information, please refer to the link http://www.di.unipi.it/~gulli/AG_corpus_of_news_articles.html .\\n\\nThe AG\\'s news topic classification dataset is constructed by Xiang Zhang (xiang.zhang@nyu.edu) from the dataset above.\\nIt is used as a text classification benchmark in the following paper:\\nXiang Zhang, Junbo Zhao, Yann LeCun. Character-level Convolutional Networks for Text Classification. Advances in Neural Information Processing Systems 28 (NIPS 2015).\\n\\nThe AG\\'s news topic classification dataset is constructed by choosing 4 largest classes from the original corpus.\\nEach class contains 30,000 training samples and 1,900 testing samples.\\nThe total number of training samples is 120,000 and testing 7,600.\"\n",
            "citation: \"@misc{zhang2015characterlevel,\\n    title={Character-level Convolutional Networks for Text Classification},\\n    author={Xiang Zhang and Junbo Zhao and Yann LeCun},\\n    year={2015},\\n    eprint={1509.01626},\\n    archivePrefix={arXiv},\\n    primaryClass={cs.LG}\\n}\"\n",
            "location {\n",
            "  urls: \"https://arxiv.org/abs/1509.01626\"\n",
            "}\n",
            "splits {\n",
            "  name: \"test\"\n",
            "  shard_lengths: 7600\n",
            "  num_bytes: 2226751\n",
            "}\n",
            "splits {\n",
            "  name: \"train\"\n",
            "  shard_lengths: 120000\n",
            "  num_bytes: 35301386\n",
            "}\n",
            "supervised_keys {\n",
            "  input: \"description\"\n",
            "  output: \"label\"\n",
            "}\n",
            "version: \"1.0.0\"\n",
            "download_size: 11784327\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mR2FlWsX19f9"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r_1zM05A19dc"
      },
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "validation_dataset = validation_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4bbi5xHe19bM"
      },
      "source": [
        "VOCAB_SIZE=1000\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uMrpZgV5xexC"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "encoder\n",
        ",tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary())\n",
        ",output_dim=64\n",
        ",mask_zero=True)\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))\n",
        ",tf.keras.layers.Dense(64, activation='relu')\n",
        ",tf.keras.layers.Dense(4,activation='softmax')])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG1zyOtQ6rE1",
        "outputId": "6a199833-e085-4ef4-eee9-f934c3d599ed"
      },
      "source": [
        "%%time\n",
        "history = model.fit(train_dataset ,epochs = 250 ,validation_data=validation_dataset ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1782/1782 [==============================] - 41s 17ms/step - loss: 0.7068 - accuracy: 0.7402 - val_loss: 0.4811 - val_accuracy: 0.8347\n",
            "Epoch 2/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.4634 - accuracy: 0.8333 - val_loss: 0.4474 - val_accuracy: 0.8447\n",
            "Epoch 3/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.4381 - accuracy: 0.8425 - val_loss: 0.4273 - val_accuracy: 0.8507\n",
            "Epoch 4/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.4151 - accuracy: 0.8508 - val_loss: 0.4132 - val_accuracy: 0.8547\n",
            "Epoch 5/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3979 - accuracy: 0.8564 - val_loss: 0.3979 - val_accuracy: 0.8588\n",
            "Epoch 6/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3883 - accuracy: 0.8587 - val_loss: 0.3976 - val_accuracy: 0.8585\n",
            "Epoch 7/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3820 - accuracy: 0.8606 - val_loss: 0.3916 - val_accuracy: 0.8610\n",
            "Epoch 8/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3771 - accuracy: 0.8629 - val_loss: 0.3903 - val_accuracy: 0.8598\n",
            "Epoch 9/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3740 - accuracy: 0.8646 - val_loss: 0.3932 - val_accuracy: 0.8572\n",
            "Epoch 10/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3707 - accuracy: 0.8646 - val_loss: 0.3822 - val_accuracy: 0.8622\n",
            "Epoch 11/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3671 - accuracy: 0.8666 - val_loss: 0.3802 - val_accuracy: 0.8647\n",
            "Epoch 12/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3643 - accuracy: 0.8669 - val_loss: 0.3814 - val_accuracy: 0.8635\n",
            "Epoch 13/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3613 - accuracy: 0.8677 - val_loss: 0.3760 - val_accuracy: 0.8660\n",
            "Epoch 14/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3586 - accuracy: 0.8686 - val_loss: 0.3760 - val_accuracy: 0.8648\n",
            "Epoch 15/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3551 - accuracy: 0.8701 - val_loss: 0.3713 - val_accuracy: 0.8668\n",
            "Epoch 16/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3529 - accuracy: 0.8704 - val_loss: 0.3711 - val_accuracy: 0.8678\n",
            "Epoch 17/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3494 - accuracy: 0.8714 - val_loss: 0.3752 - val_accuracy: 0.8662\n",
            "Epoch 18/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3472 - accuracy: 0.8726 - val_loss: 0.3713 - val_accuracy: 0.8673\n",
            "Epoch 19/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3447 - accuracy: 0.8737 - val_loss: 0.3750 - val_accuracy: 0.8667\n",
            "Epoch 20/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3412 - accuracy: 0.8745 - val_loss: 0.3667 - val_accuracy: 0.8712\n",
            "Epoch 21/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3393 - accuracy: 0.8751 - val_loss: 0.3669 - val_accuracy: 0.8672\n",
            "Epoch 22/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3365 - accuracy: 0.8761 - val_loss: 0.3646 - val_accuracy: 0.8698\n",
            "Epoch 23/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3349 - accuracy: 0.8771 - val_loss: 0.3664 - val_accuracy: 0.8703\n",
            "Epoch 24/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3318 - accuracy: 0.8785 - val_loss: 0.3663 - val_accuracy: 0.8703\n",
            "Epoch 25/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3293 - accuracy: 0.8785 - val_loss: 0.3676 - val_accuracy: 0.8690\n",
            "Epoch 26/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3268 - accuracy: 0.8798 - val_loss: 0.3693 - val_accuracy: 0.8652\n",
            "Epoch 27/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3239 - accuracy: 0.8809 - val_loss: 0.3628 - val_accuracy: 0.8683\n",
            "Epoch 28/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3220 - accuracy: 0.8813 - val_loss: 0.3617 - val_accuracy: 0.8700\n",
            "Epoch 29/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3188 - accuracy: 0.8829 - val_loss: 0.3672 - val_accuracy: 0.8662\n",
            "Epoch 30/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3172 - accuracy: 0.8835 - val_loss: 0.3655 - val_accuracy: 0.8678\n",
            "Epoch 31/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3150 - accuracy: 0.8846 - val_loss: 0.3645 - val_accuracy: 0.8707\n",
            "Epoch 32/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3126 - accuracy: 0.8854 - val_loss: 0.3647 - val_accuracy: 0.8690\n",
            "Epoch 33/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3099 - accuracy: 0.8860 - val_loss: 0.3637 - val_accuracy: 0.8707\n",
            "Epoch 34/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3080 - accuracy: 0.8864 - val_loss: 0.3647 - val_accuracy: 0.8692\n",
            "Epoch 35/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3059 - accuracy: 0.8880 - val_loss: 0.3673 - val_accuracy: 0.8665\n",
            "Epoch 36/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3033 - accuracy: 0.8887 - val_loss: 0.3665 - val_accuracy: 0.8687\n",
            "Epoch 37/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3014 - accuracy: 0.8900 - val_loss: 0.3665 - val_accuracy: 0.8703\n",
            "Epoch 38/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2985 - accuracy: 0.8915 - val_loss: 0.3715 - val_accuracy: 0.8685\n",
            "Epoch 39/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2966 - accuracy: 0.8920 - val_loss: 0.3711 - val_accuracy: 0.8683\n",
            "Epoch 40/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2946 - accuracy: 0.8920 - val_loss: 0.3709 - val_accuracy: 0.8670\n",
            "Epoch 41/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2919 - accuracy: 0.8928 - val_loss: 0.3704 - val_accuracy: 0.8697\n",
            "Epoch 42/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2902 - accuracy: 0.8940 - val_loss: 0.3692 - val_accuracy: 0.8663\n",
            "Epoch 43/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2878 - accuracy: 0.8953 - val_loss: 0.3703 - val_accuracy: 0.8675\n",
            "Epoch 44/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2850 - accuracy: 0.8963 - val_loss: 0.3720 - val_accuracy: 0.8667\n",
            "Epoch 45/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2835 - accuracy: 0.8965 - val_loss: 0.3782 - val_accuracy: 0.8672\n",
            "Epoch 46/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2809 - accuracy: 0.8975 - val_loss: 0.3771 - val_accuracy: 0.8690\n",
            "Epoch 47/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2783 - accuracy: 0.8987 - val_loss: 0.3801 - val_accuracy: 0.8662\n",
            "Epoch 48/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2765 - accuracy: 0.8990 - val_loss: 0.3783 - val_accuracy: 0.8648\n",
            "Epoch 49/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2744 - accuracy: 0.8990 - val_loss: 0.3951 - val_accuracy: 0.8612\n",
            "Epoch 50/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2723 - accuracy: 0.9004 - val_loss: 0.3859 - val_accuracy: 0.8628\n",
            "Epoch 51/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2700 - accuracy: 0.9014 - val_loss: 0.3818 - val_accuracy: 0.8643\n",
            "Epoch 52/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2676 - accuracy: 0.9023 - val_loss: 0.3814 - val_accuracy: 0.8642\n",
            "Epoch 53/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2653 - accuracy: 0.9035 - val_loss: 0.3934 - val_accuracy: 0.8655\n",
            "Epoch 54/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2629 - accuracy: 0.9041 - val_loss: 0.3937 - val_accuracy: 0.8635\n",
            "Epoch 55/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2605 - accuracy: 0.9050 - val_loss: 0.3900 - val_accuracy: 0.8642\n",
            "Epoch 56/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2587 - accuracy: 0.9059 - val_loss: 0.3972 - val_accuracy: 0.8628\n",
            "Epoch 57/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2563 - accuracy: 0.9068 - val_loss: 0.3981 - val_accuracy: 0.8612\n",
            "Epoch 58/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2542 - accuracy: 0.9073 - val_loss: 0.3966 - val_accuracy: 0.8643\n",
            "Epoch 59/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2521 - accuracy: 0.9077 - val_loss: 0.3968 - val_accuracy: 0.8628\n",
            "Epoch 60/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2501 - accuracy: 0.9090 - val_loss: 0.4035 - val_accuracy: 0.8643\n",
            "Epoch 61/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2477 - accuracy: 0.9099 - val_loss: 0.4049 - val_accuracy: 0.8607\n",
            "Epoch 62/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2450 - accuracy: 0.9112 - val_loss: 0.4050 - val_accuracy: 0.8612\n",
            "Epoch 63/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2426 - accuracy: 0.9119 - val_loss: 0.4062 - val_accuracy: 0.8608\n",
            "Epoch 64/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2410 - accuracy: 0.9128 - val_loss: 0.4125 - val_accuracy: 0.8630\n",
            "Epoch 65/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2383 - accuracy: 0.9137 - val_loss: 0.4137 - val_accuracy: 0.8627\n",
            "Epoch 66/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2361 - accuracy: 0.9150 - val_loss: 0.4191 - val_accuracy: 0.8612\n",
            "Epoch 67/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2342 - accuracy: 0.9149 - val_loss: 0.4154 - val_accuracy: 0.8605\n",
            "Epoch 68/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2314 - accuracy: 0.9163 - val_loss: 0.4322 - val_accuracy: 0.8602\n",
            "Epoch 69/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2296 - accuracy: 0.9172 - val_loss: 0.4306 - val_accuracy: 0.8603\n",
            "Epoch 70/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2271 - accuracy: 0.9188 - val_loss: 0.4260 - val_accuracy: 0.8583\n",
            "Epoch 71/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2247 - accuracy: 0.9189 - val_loss: 0.4317 - val_accuracy: 0.8600\n",
            "Epoch 72/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2225 - accuracy: 0.9193 - val_loss: 0.4372 - val_accuracy: 0.8593\n",
            "Epoch 73/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2209 - accuracy: 0.9204 - val_loss: 0.4424 - val_accuracy: 0.8597\n",
            "Epoch 74/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2177 - accuracy: 0.9214 - val_loss: 0.4551 - val_accuracy: 0.8573\n",
            "Epoch 75/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2151 - accuracy: 0.9228 - val_loss: 0.4564 - val_accuracy: 0.8578\n",
            "Epoch 76/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2131 - accuracy: 0.9236 - val_loss: 0.4576 - val_accuracy: 0.8602\n",
            "Epoch 77/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2110 - accuracy: 0.9241 - val_loss: 0.4664 - val_accuracy: 0.8582\n",
            "Epoch 78/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2088 - accuracy: 0.9254 - val_loss: 0.4666 - val_accuracy: 0.8588\n",
            "Epoch 79/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2060 - accuracy: 0.9262 - val_loss: 0.4669 - val_accuracy: 0.8577\n",
            "Epoch 80/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2042 - accuracy: 0.9266 - val_loss: 0.4737 - val_accuracy: 0.8567\n",
            "Epoch 81/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2019 - accuracy: 0.9280 - val_loss: 0.4749 - val_accuracy: 0.8552\n",
            "Epoch 82/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2000 - accuracy: 0.9288 - val_loss: 0.4911 - val_accuracy: 0.8547\n",
            "Epoch 83/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1975 - accuracy: 0.9293 - val_loss: 0.4886 - val_accuracy: 0.8530\n",
            "Epoch 84/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1961 - accuracy: 0.9297 - val_loss: 0.4854 - val_accuracy: 0.8585\n",
            "Epoch 85/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1922 - accuracy: 0.9316 - val_loss: 0.4943 - val_accuracy: 0.8580\n",
            "Epoch 86/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1910 - accuracy: 0.9317 - val_loss: 0.5002 - val_accuracy: 0.8547\n",
            "Epoch 87/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1877 - accuracy: 0.9336 - val_loss: 0.5003 - val_accuracy: 0.8557\n",
            "Epoch 88/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1856 - accuracy: 0.9339 - val_loss: 0.5034 - val_accuracy: 0.8568\n",
            "Epoch 89/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1860 - accuracy: 0.9337 - val_loss: 0.5132 - val_accuracy: 0.8538\n",
            "Epoch 90/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1814 - accuracy: 0.9358 - val_loss: 0.5083 - val_accuracy: 0.8492\n",
            "Epoch 91/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1788 - accuracy: 0.9364 - val_loss: 0.5196 - val_accuracy: 0.8523\n",
            "Epoch 92/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1768 - accuracy: 0.9370 - val_loss: 0.5345 - val_accuracy: 0.8505\n",
            "Epoch 93/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1751 - accuracy: 0.9381 - val_loss: 0.5299 - val_accuracy: 0.8535\n",
            "Epoch 94/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1727 - accuracy: 0.9384 - val_loss: 0.5427 - val_accuracy: 0.8527\n",
            "Epoch 95/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1697 - accuracy: 0.9404 - val_loss: 0.5690 - val_accuracy: 0.8530\n",
            "Epoch 96/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1689 - accuracy: 0.9407 - val_loss: 0.5539 - val_accuracy: 0.8485\n",
            "Epoch 97/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1647 - accuracy: 0.9418 - val_loss: 0.5935 - val_accuracy: 0.8493\n",
            "Epoch 98/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1628 - accuracy: 0.9425 - val_loss: 0.5769 - val_accuracy: 0.8503\n",
            "Epoch 99/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1613 - accuracy: 0.9431 - val_loss: 0.5873 - val_accuracy: 0.8483\n",
            "Epoch 100/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1585 - accuracy: 0.9438 - val_loss: 0.5964 - val_accuracy: 0.8447\n",
            "Epoch 101/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1569 - accuracy: 0.9437 - val_loss: 0.5925 - val_accuracy: 0.8473\n",
            "Epoch 102/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1542 - accuracy: 0.9459 - val_loss: 0.6127 - val_accuracy: 0.8480\n",
            "Epoch 103/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1525 - accuracy: 0.9460 - val_loss: 0.6173 - val_accuracy: 0.8505\n",
            "Epoch 104/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1507 - accuracy: 0.9467 - val_loss: 0.6284 - val_accuracy: 0.8493\n",
            "Epoch 105/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1489 - accuracy: 0.9476 - val_loss: 0.6368 - val_accuracy: 0.8462\n",
            "Epoch 106/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1458 - accuracy: 0.9490 - val_loss: 0.6441 - val_accuracy: 0.8483\n",
            "Epoch 107/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1430 - accuracy: 0.9500 - val_loss: 0.6465 - val_accuracy: 0.8482\n",
            "Epoch 108/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1410 - accuracy: 0.9506 - val_loss: 0.6562 - val_accuracy: 0.8488\n",
            "Epoch 109/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1405 - accuracy: 0.9511 - val_loss: 0.6599 - val_accuracy: 0.8495\n",
            "Epoch 110/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1365 - accuracy: 0.9528 - val_loss: 0.6797 - val_accuracy: 0.8487\n",
            "Epoch 111/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1358 - accuracy: 0.9525 - val_loss: 0.6853 - val_accuracy: 0.8473\n",
            "Epoch 112/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1330 - accuracy: 0.9538 - val_loss: 0.6884 - val_accuracy: 0.8460\n",
            "Epoch 113/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1304 - accuracy: 0.9547 - val_loss: 0.6895 - val_accuracy: 0.8415\n",
            "Epoch 114/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1293 - accuracy: 0.9551 - val_loss: 0.7095 - val_accuracy: 0.8463\n",
            "Epoch 115/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1262 - accuracy: 0.9566 - val_loss: 0.7456 - val_accuracy: 0.8418\n",
            "Epoch 116/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1241 - accuracy: 0.9572 - val_loss: 0.7324 - val_accuracy: 0.8447\n",
            "Epoch 117/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1226 - accuracy: 0.9576 - val_loss: 0.7422 - val_accuracy: 0.8455\n",
            "Epoch 118/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1207 - accuracy: 0.9585 - val_loss: 0.7578 - val_accuracy: 0.8400\n",
            "Epoch 119/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1168 - accuracy: 0.9601 - val_loss: 0.7586 - val_accuracy: 0.8432\n",
            "Epoch 120/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1165 - accuracy: 0.9601 - val_loss: 0.7766 - val_accuracy: 0.8445\n",
            "Epoch 121/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1150 - accuracy: 0.9609 - val_loss: 0.8115 - val_accuracy: 0.8428\n",
            "Epoch 122/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1132 - accuracy: 0.9612 - val_loss: 0.8087 - val_accuracy: 0.8423\n",
            "Epoch 123/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1091 - accuracy: 0.9634 - val_loss: 0.8014 - val_accuracy: 0.8427\n",
            "Epoch 124/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1089 - accuracy: 0.9631 - val_loss: 0.8412 - val_accuracy: 0.8407\n",
            "Epoch 125/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1071 - accuracy: 0.9636 - val_loss: 0.8373 - val_accuracy: 0.8445\n",
            "Epoch 126/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1050 - accuracy: 0.9648 - val_loss: 0.8426 - val_accuracy: 0.8422\n",
            "Epoch 127/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1026 - accuracy: 0.9654 - val_loss: 0.8592 - val_accuracy: 0.8402\n",
            "Epoch 128/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.1015 - accuracy: 0.9661 - val_loss: 0.8699 - val_accuracy: 0.8415\n",
            "Epoch 129/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0995 - accuracy: 0.9666 - val_loss: 0.8582 - val_accuracy: 0.8380\n",
            "Epoch 130/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0997 - accuracy: 0.9669 - val_loss: 0.8885 - val_accuracy: 0.8412\n",
            "Epoch 131/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0946 - accuracy: 0.9685 - val_loss: 0.8966 - val_accuracy: 0.8398\n",
            "Epoch 132/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0939 - accuracy: 0.9688 - val_loss: 0.9241 - val_accuracy: 0.8377\n",
            "Epoch 133/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0946 - accuracy: 0.9689 - val_loss: 0.9233 - val_accuracy: 0.8393\n",
            "Epoch 134/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0927 - accuracy: 0.9696 - val_loss: 0.9311 - val_accuracy: 0.8380\n",
            "Epoch 135/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0879 - accuracy: 0.9711 - val_loss: 0.9596 - val_accuracy: 0.8383\n",
            "Epoch 136/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0874 - accuracy: 0.9714 - val_loss: 0.9876 - val_accuracy: 0.8378\n",
            "Epoch 137/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0872 - accuracy: 0.9708 - val_loss: 0.9845 - val_accuracy: 0.8352\n",
            "Epoch 138/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0892 - accuracy: 0.9705 - val_loss: 0.9936 - val_accuracy: 0.8382\n",
            "Epoch 139/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0804 - accuracy: 0.9741 - val_loss: 1.0500 - val_accuracy: 0.8340\n",
            "Epoch 140/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0801 - accuracy: 0.9739 - val_loss: 1.0702 - val_accuracy: 0.8370\n",
            "Epoch 141/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0810 - accuracy: 0.9737 - val_loss: 1.0425 - val_accuracy: 0.8335\n",
            "Epoch 142/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0796 - accuracy: 0.9741 - val_loss: 1.0559 - val_accuracy: 0.8338\n",
            "Epoch 143/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0767 - accuracy: 0.9749 - val_loss: 1.0697 - val_accuracy: 0.8337\n",
            "Epoch 144/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0819 - accuracy: 0.9731 - val_loss: 1.0720 - val_accuracy: 0.8330\n",
            "Epoch 145/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0727 - accuracy: 0.9769 - val_loss: 1.0908 - val_accuracy: 0.8352\n",
            "Epoch 146/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0729 - accuracy: 0.9768 - val_loss: 1.1020 - val_accuracy: 0.8333\n",
            "Epoch 147/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0716 - accuracy: 0.9768 - val_loss: 1.1290 - val_accuracy: 0.8315\n",
            "Epoch 148/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0709 - accuracy: 0.9776 - val_loss: 1.1301 - val_accuracy: 0.8333\n",
            "Epoch 149/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0709 - accuracy: 0.9776 - val_loss: 1.1275 - val_accuracy: 0.8323\n",
            "Epoch 150/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0667 - accuracy: 0.9787 - val_loss: 1.1071 - val_accuracy: 0.8337\n",
            "Epoch 151/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0671 - accuracy: 0.9788 - val_loss: 1.1541 - val_accuracy: 0.8325\n",
            "Epoch 152/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0642 - accuracy: 0.9798 - val_loss: 1.1838 - val_accuracy: 0.8340\n",
            "Epoch 153/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0643 - accuracy: 0.9796 - val_loss: 1.2143 - val_accuracy: 0.8335\n",
            "Epoch 154/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0625 - accuracy: 0.9805 - val_loss: 1.2283 - val_accuracy: 0.8322\n",
            "Epoch 155/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0625 - accuracy: 0.9804 - val_loss: 1.2538 - val_accuracy: 0.8297\n",
            "Epoch 156/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0599 - accuracy: 0.9810 - val_loss: 1.2474 - val_accuracy: 0.8340\n",
            "Epoch 157/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0608 - accuracy: 0.9809 - val_loss: 1.2559 - val_accuracy: 0.8340\n",
            "Epoch 158/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0566 - accuracy: 0.9826 - val_loss: 1.2445 - val_accuracy: 0.8297\n",
            "Epoch 159/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 1.2887 - val_accuracy: 0.8325\n",
            "Epoch 160/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0572 - accuracy: 0.9819 - val_loss: 1.3196 - val_accuracy: 0.8367\n",
            "Epoch 161/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0564 - accuracy: 0.9821 - val_loss: 1.3254 - val_accuracy: 0.8312\n",
            "Epoch 162/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0548 - accuracy: 0.9828 - val_loss: 1.3384 - val_accuracy: 0.8283\n",
            "Epoch 163/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0537 - accuracy: 0.9829 - val_loss: 1.3501 - val_accuracy: 0.8285\n",
            "Epoch 164/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0525 - accuracy: 0.9837 - val_loss: 1.3592 - val_accuracy: 0.8310\n",
            "Epoch 165/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0540 - accuracy: 0.9833 - val_loss: 1.3613 - val_accuracy: 0.8292\n",
            "Epoch 166/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0496 - accuracy: 0.9845 - val_loss: 1.3652 - val_accuracy: 0.8323\n",
            "Epoch 167/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0495 - accuracy: 0.9846 - val_loss: 1.4105 - val_accuracy: 0.8282\n",
            "Epoch 168/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0467 - accuracy: 0.9854 - val_loss: 1.4339 - val_accuracy: 0.8265\n",
            "Epoch 169/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0484 - accuracy: 0.9847 - val_loss: 1.4039 - val_accuracy: 0.8327\n",
            "Epoch 170/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0486 - accuracy: 0.9848 - val_loss: 1.3998 - val_accuracy: 0.8292\n",
            "Epoch 171/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0450 - accuracy: 0.9863 - val_loss: 1.4487 - val_accuracy: 0.8302\n",
            "Epoch 172/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 1.4459 - val_accuracy: 0.8293\n",
            "Epoch 173/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0440 - accuracy: 0.9865 - val_loss: 1.4954 - val_accuracy: 0.8298\n",
            "Epoch 174/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 1.4984 - val_accuracy: 0.8283\n",
            "Epoch 175/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0414 - accuracy: 0.9871 - val_loss: 1.4741 - val_accuracy: 0.8328\n",
            "Epoch 176/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 1.4869 - val_accuracy: 0.8278\n",
            "Epoch 177/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0393 - accuracy: 0.9881 - val_loss: 1.5270 - val_accuracy: 0.8280\n",
            "Epoch 178/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0429 - accuracy: 0.9866 - val_loss: 1.5476 - val_accuracy: 0.8257\n",
            "Epoch 179/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0394 - accuracy: 0.9881 - val_loss: 1.5655 - val_accuracy: 0.8312\n",
            "Epoch 180/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0417 - accuracy: 0.9869 - val_loss: 1.5793 - val_accuracy: 0.8293\n",
            "Epoch 181/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0370 - accuracy: 0.9888 - val_loss: 1.6013 - val_accuracy: 0.8297\n",
            "Epoch 182/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0399 - accuracy: 0.9877 - val_loss: 1.6271 - val_accuracy: 0.8268\n",
            "Epoch 183/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 1.5717 - val_accuracy: 0.8288\n",
            "Epoch 184/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 1.6135 - val_accuracy: 0.8260\n",
            "Epoch 185/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0377 - accuracy: 0.9884 - val_loss: 1.6246 - val_accuracy: 0.8298\n",
            "Epoch 186/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0360 - accuracy: 0.9894 - val_loss: 1.6508 - val_accuracy: 0.8298\n",
            "Epoch 187/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 1.6471 - val_accuracy: 0.8285\n",
            "Epoch 188/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0371 - accuracy: 0.9884 - val_loss: 1.6348 - val_accuracy: 0.8262\n",
            "Epoch 189/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0341 - accuracy: 0.9898 - val_loss: 1.6699 - val_accuracy: 0.8283\n",
            "Epoch 190/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0367 - accuracy: 0.9892 - val_loss: 1.7051 - val_accuracy: 0.8312\n",
            "Epoch 191/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0333 - accuracy: 0.9901 - val_loss: 1.6928 - val_accuracy: 0.8322\n",
            "Epoch 192/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0323 - accuracy: 0.9904 - val_loss: 1.6875 - val_accuracy: 0.8263\n",
            "Epoch 193/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0312 - accuracy: 0.9903 - val_loss: 1.7438 - val_accuracy: 0.8297\n",
            "Epoch 194/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0319 - accuracy: 0.9904 - val_loss: 1.7553 - val_accuracy: 0.8255\n",
            "Epoch 195/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 1.7237 - val_accuracy: 0.8263\n",
            "Epoch 196/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0339 - accuracy: 0.9898 - val_loss: 1.7907 - val_accuracy: 0.8292\n",
            "Epoch 197/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0290 - accuracy: 0.9914 - val_loss: 1.7522 - val_accuracy: 0.8275\n",
            "Epoch 198/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 1.7716 - val_accuracy: 0.8278\n",
            "Epoch 199/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0313 - accuracy: 0.9907 - val_loss: 1.8060 - val_accuracy: 0.8267\n",
            "Epoch 200/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 1.8228 - val_accuracy: 0.8267\n",
            "Epoch 201/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0287 - accuracy: 0.9914 - val_loss: 1.8035 - val_accuracy: 0.8263\n",
            "Epoch 202/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0278 - accuracy: 0.9918 - val_loss: 1.8437 - val_accuracy: 0.8260\n",
            "Epoch 203/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 1.8215 - val_accuracy: 0.8303\n",
            "Epoch 204/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0262 - accuracy: 0.9922 - val_loss: 1.8337 - val_accuracy: 0.8308\n",
            "Epoch 205/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 1.8437 - val_accuracy: 0.8282\n",
            "Epoch 206/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 1.8442 - val_accuracy: 0.8270\n",
            "Epoch 207/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 1.8606 - val_accuracy: 0.8283\n",
            "Epoch 208/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0283 - accuracy: 0.9916 - val_loss: 1.8265 - val_accuracy: 0.8345\n",
            "Epoch 209/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0284 - accuracy: 0.9914 - val_loss: 1.8947 - val_accuracy: 0.8285\n",
            "Epoch 210/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 1.9407 - val_accuracy: 0.8303\n",
            "Epoch 211/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 1.8961 - val_accuracy: 0.8312\n",
            "Epoch 212/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 1.9330 - val_accuracy: 0.8288\n",
            "Epoch 213/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 1.9578 - val_accuracy: 0.8272\n",
            "Epoch 214/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0225 - accuracy: 0.9934 - val_loss: 1.9212 - val_accuracy: 0.8265\n",
            "Epoch 215/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 1.9520 - val_accuracy: 0.8302\n",
            "Epoch 216/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 1.9608 - val_accuracy: 0.8305\n",
            "Epoch 217/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0210 - accuracy: 0.9941 - val_loss: 1.9799 - val_accuracy: 0.8307\n",
            "Epoch 218/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 1.9732 - val_accuracy: 0.8295\n",
            "Epoch 219/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0215 - accuracy: 0.9939 - val_loss: 1.9851 - val_accuracy: 0.8257\n",
            "Epoch 220/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0248 - accuracy: 0.9928 - val_loss: 2.0162 - val_accuracy: 0.8277\n",
            "Epoch 221/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 2.0388 - val_accuracy: 0.8307\n",
            "Epoch 222/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 2.0111 - val_accuracy: 0.8268\n",
            "Epoch 223/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 2.0297 - val_accuracy: 0.8278\n",
            "Epoch 224/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 2.0230 - val_accuracy: 0.8272\n",
            "Epoch 225/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0222 - accuracy: 0.9936 - val_loss: 1.9910 - val_accuracy: 0.8288\n",
            "Epoch 226/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 2.0321 - val_accuracy: 0.8262\n",
            "Epoch 227/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 2.0463 - val_accuracy: 0.8285\n",
            "Epoch 228/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 2.0596 - val_accuracy: 0.8310\n",
            "Epoch 229/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 2.1037 - val_accuracy: 0.8280\n",
            "Epoch 230/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 2.0633 - val_accuracy: 0.8295\n",
            "Epoch 231/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 2.0687 - val_accuracy: 0.8312\n",
            "Epoch 232/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0227 - accuracy: 0.9934 - val_loss: 2.0776 - val_accuracy: 0.8302\n",
            "Epoch 233/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0188 - accuracy: 0.9948 - val_loss: 2.1356 - val_accuracy: 0.8280\n",
            "Epoch 234/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 2.1203 - val_accuracy: 0.8308\n",
            "Epoch 235/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 2.1257 - val_accuracy: 0.8302\n",
            "Epoch 236/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0207 - accuracy: 0.9942 - val_loss: 2.1088 - val_accuracy: 0.8282\n",
            "Epoch 237/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0193 - accuracy: 0.9946 - val_loss: 2.1320 - val_accuracy: 0.8277\n",
            "Epoch 238/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 2.1153 - val_accuracy: 0.8308\n",
            "Epoch 239/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0201 - accuracy: 0.9942 - val_loss: 2.1204 - val_accuracy: 0.8325\n",
            "Epoch 240/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 2.0585 - val_accuracy: 0.8328\n",
            "Epoch 241/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 2.1356 - val_accuracy: 0.8265\n",
            "Epoch 242/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 2.1457 - val_accuracy: 0.8290\n",
            "Epoch 243/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 2.1680 - val_accuracy: 0.8317\n",
            "Epoch 244/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 2.1382 - val_accuracy: 0.8322\n",
            "Epoch 245/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0174 - accuracy: 0.9950 - val_loss: 2.1496 - val_accuracy: 0.8270\n",
            "Epoch 246/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 2.2014 - val_accuracy: 0.8343\n",
            "Epoch 247/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 2.1459 - val_accuracy: 0.8297\n",
            "Epoch 248/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 2.1390 - val_accuracy: 0.8348\n",
            "Epoch 249/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 2.1485 - val_accuracy: 0.8290\n",
            "Epoch 250/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 2.1106 - val_accuracy: 0.8255\n",
            "CPU times: user 4h 8min 2s, sys: 1h 15min 11s, total: 5h 23min 13s\n",
            "Wall time: 1h 58min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v8lxBTbLtIu5"
      },
      "source": [
        "model = tf.keras.Sequential([encoder,tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()),output_dim=64,mask_zero=True)\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,  return_sequences=True))\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))\n",
        ",tf.keras.layers.Dense(64, activation='relu')\n",
        ",tf.keras.layers.Dense(4,activation='softmax')])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nRzvkZjltIY0",
        "outputId": "a81256f4-bf6a-46f8-e397-fce090a3a1cd"
      },
      "source": [
        "%%time\n",
        "history = model.fit(train_dataset ,epochs = 250 ,validation_data=validation_dataset ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1782/1782 [==============================] - 69s 31ms/step - loss: 0.6064 - accuracy: 0.7687 - val_loss: 0.4392 - val_accuracy: 0.8455\n",
            "Epoch 2/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.4179 - accuracy: 0.8505 - val_loss: 0.4183 - val_accuracy: 0.8530\n",
            "Epoch 3/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3947 - accuracy: 0.8570 - val_loss: 0.3897 - val_accuracy: 0.8632\n",
            "Epoch 4/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3852 - accuracy: 0.8607 - val_loss: 0.3901 - val_accuracy: 0.8642\n",
            "Epoch 5/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3788 - accuracy: 0.8624 - val_loss: 0.3875 - val_accuracy: 0.8607\n",
            "Epoch 6/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3736 - accuracy: 0.8637 - val_loss: 0.3807 - val_accuracy: 0.8647\n",
            "Epoch 7/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3684 - accuracy: 0.8659 - val_loss: 0.3805 - val_accuracy: 0.8653\n",
            "Epoch 8/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.3649 - accuracy: 0.8663 - val_loss: 0.3832 - val_accuracy: 0.8632\n",
            "Epoch 9/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3607 - accuracy: 0.8679 - val_loss: 0.3749 - val_accuracy: 0.8667\n",
            "Epoch 10/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3572 - accuracy: 0.8693 - val_loss: 0.3780 - val_accuracy: 0.8668\n",
            "Epoch 11/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3537 - accuracy: 0.8701 - val_loss: 0.3729 - val_accuracy: 0.8705\n",
            "Epoch 12/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3507 - accuracy: 0.8712 - val_loss: 0.3727 - val_accuracy: 0.8662\n",
            "Epoch 13/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3479 - accuracy: 0.8727 - val_loss: 0.3779 - val_accuracy: 0.8640\n",
            "Epoch 14/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3444 - accuracy: 0.8733 - val_loss: 0.3783 - val_accuracy: 0.8638\n",
            "Epoch 15/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3416 - accuracy: 0.8747 - val_loss: 0.3773 - val_accuracy: 0.8625\n",
            "Epoch 16/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3386 - accuracy: 0.8756 - val_loss: 0.3707 - val_accuracy: 0.8662\n",
            "Epoch 17/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3359 - accuracy: 0.8773 - val_loss: 0.3698 - val_accuracy: 0.8658\n",
            "Epoch 18/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3340 - accuracy: 0.8776 - val_loss: 0.3674 - val_accuracy: 0.8665\n",
            "Epoch 19/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3298 - accuracy: 0.8788 - val_loss: 0.3677 - val_accuracy: 0.8668\n",
            "Epoch 20/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3275 - accuracy: 0.8798 - val_loss: 0.3695 - val_accuracy: 0.8653\n",
            "Epoch 21/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3245 - accuracy: 0.8813 - val_loss: 0.3743 - val_accuracy: 0.8625\n",
            "Epoch 22/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3225 - accuracy: 0.8823 - val_loss: 0.3721 - val_accuracy: 0.8655\n",
            "Epoch 23/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3198 - accuracy: 0.8827 - val_loss: 0.3742 - val_accuracy: 0.8648\n",
            "Epoch 24/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3158 - accuracy: 0.8847 - val_loss: 0.3722 - val_accuracy: 0.8635\n",
            "Epoch 25/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3137 - accuracy: 0.8857 - val_loss: 0.3706 - val_accuracy: 0.8650\n",
            "Epoch 26/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3115 - accuracy: 0.8860 - val_loss: 0.3726 - val_accuracy: 0.8637\n",
            "Epoch 27/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3083 - accuracy: 0.8870 - val_loss: 0.3811 - val_accuracy: 0.8620\n",
            "Epoch 28/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3055 - accuracy: 0.8882 - val_loss: 0.3876 - val_accuracy: 0.8602\n",
            "Epoch 29/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.3029 - accuracy: 0.8891 - val_loss: 0.3801 - val_accuracy: 0.8620\n",
            "Epoch 30/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2996 - accuracy: 0.8904 - val_loss: 0.3760 - val_accuracy: 0.8660\n",
            "Epoch 31/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2970 - accuracy: 0.8917 - val_loss: 0.3793 - val_accuracy: 0.8678\n",
            "Epoch 32/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2943 - accuracy: 0.8929 - val_loss: 0.3934 - val_accuracy: 0.8610\n",
            "Epoch 33/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2919 - accuracy: 0.8937 - val_loss: 0.3808 - val_accuracy: 0.8653\n",
            "Epoch 34/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2888 - accuracy: 0.8946 - val_loss: 0.3809 - val_accuracy: 0.8658\n",
            "Epoch 35/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2859 - accuracy: 0.8961 - val_loss: 0.3910 - val_accuracy: 0.8655\n",
            "Epoch 36/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2839 - accuracy: 0.8967 - val_loss: 0.3846 - val_accuracy: 0.8657\n",
            "Epoch 37/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.2805 - accuracy: 0.8976 - val_loss: 0.3912 - val_accuracy: 0.8627\n",
            "Epoch 38/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2778 - accuracy: 0.8988 - val_loss: 0.3987 - val_accuracy: 0.8630\n",
            "Epoch 39/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2741 - accuracy: 0.9011 - val_loss: 0.3925 - val_accuracy: 0.8662\n",
            "Epoch 40/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2723 - accuracy: 0.9015 - val_loss: 0.3991 - val_accuracy: 0.8635\n",
            "Epoch 41/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2697 - accuracy: 0.9023 - val_loss: 0.4001 - val_accuracy: 0.8607\n",
            "Epoch 42/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2662 - accuracy: 0.9034 - val_loss: 0.4012 - val_accuracy: 0.8645\n",
            "Epoch 43/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2637 - accuracy: 0.9046 - val_loss: 0.4026 - val_accuracy: 0.8627\n",
            "Epoch 44/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2612 - accuracy: 0.9052 - val_loss: 0.4109 - val_accuracy: 0.8560\n",
            "Epoch 45/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2576 - accuracy: 0.9067 - val_loss: 0.4178 - val_accuracy: 0.8598\n",
            "Epoch 46/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.2546 - accuracy: 0.9082 - val_loss: 0.4285 - val_accuracy: 0.8497\n",
            "Epoch 47/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.2508 - accuracy: 0.9096 - val_loss: 0.4264 - val_accuracy: 0.8573\n",
            "Epoch 48/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2502 - accuracy: 0.9097 - val_loss: 0.4295 - val_accuracy: 0.8585\n",
            "Epoch 49/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2463 - accuracy: 0.9114 - val_loss: 0.4268 - val_accuracy: 0.8592\n",
            "Epoch 50/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.2431 - accuracy: 0.9121 - val_loss: 0.4305 - val_accuracy: 0.8568\n",
            "Epoch 51/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2394 - accuracy: 0.9136 - val_loss: 0.4381 - val_accuracy: 0.8572\n",
            "Epoch 52/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2369 - accuracy: 0.9152 - val_loss: 0.4430 - val_accuracy: 0.8548\n",
            "Epoch 53/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2341 - accuracy: 0.9153 - val_loss: 0.4409 - val_accuracy: 0.8535\n",
            "Epoch 54/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2308 - accuracy: 0.9169 - val_loss: 0.4435 - val_accuracy: 0.8552\n",
            "Epoch 55/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2281 - accuracy: 0.9176 - val_loss: 0.4532 - val_accuracy: 0.8542\n",
            "Epoch 56/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2239 - accuracy: 0.9194 - val_loss: 0.4537 - val_accuracy: 0.8548\n",
            "Epoch 57/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2225 - accuracy: 0.9193 - val_loss: 0.4629 - val_accuracy: 0.8503\n",
            "Epoch 58/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2195 - accuracy: 0.9212 - val_loss: 0.4628 - val_accuracy: 0.8490\n",
            "Epoch 59/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2160 - accuracy: 0.9224 - val_loss: 0.4772 - val_accuracy: 0.8528\n",
            "Epoch 60/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2125 - accuracy: 0.9234 - val_loss: 0.4797 - val_accuracy: 0.8493\n",
            "Epoch 61/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2099 - accuracy: 0.9243 - val_loss: 0.4811 - val_accuracy: 0.8497\n",
            "Epoch 62/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.2076 - accuracy: 0.9254 - val_loss: 0.4856 - val_accuracy: 0.8503\n",
            "Epoch 63/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.2036 - accuracy: 0.9274 - val_loss: 0.5057 - val_accuracy: 0.8463\n",
            "Epoch 64/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.2024 - accuracy: 0.9276 - val_loss: 0.5131 - val_accuracy: 0.8513\n",
            "Epoch 65/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1987 - accuracy: 0.9289 - val_loss: 0.4979 - val_accuracy: 0.8455\n",
            "Epoch 66/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1950 - accuracy: 0.9304 - val_loss: 0.5189 - val_accuracy: 0.8487\n",
            "Epoch 67/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1914 - accuracy: 0.9311 - val_loss: 0.5248 - val_accuracy: 0.8513\n",
            "Epoch 68/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1921 - accuracy: 0.9306 - val_loss: 0.5309 - val_accuracy: 0.8463\n",
            "Epoch 69/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1862 - accuracy: 0.9332 - val_loss: 0.5384 - val_accuracy: 0.8468\n",
            "Epoch 70/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1828 - accuracy: 0.9349 - val_loss: 0.5417 - val_accuracy: 0.8498\n",
            "Epoch 71/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1820 - accuracy: 0.9350 - val_loss: 0.5428 - val_accuracy: 0.8480\n",
            "Epoch 72/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1775 - accuracy: 0.9373 - val_loss: 0.5476 - val_accuracy: 0.8472\n",
            "Epoch 73/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1755 - accuracy: 0.9380 - val_loss: 0.5541 - val_accuracy: 0.8467\n",
            "Epoch 74/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1739 - accuracy: 0.9382 - val_loss: 0.5629 - val_accuracy: 0.8453\n",
            "Epoch 75/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1709 - accuracy: 0.9393 - val_loss: 0.5869 - val_accuracy: 0.8465\n",
            "Epoch 76/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1692 - accuracy: 0.9404 - val_loss: 0.5634 - val_accuracy: 0.8480\n",
            "Epoch 77/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1638 - accuracy: 0.9417 - val_loss: 0.5906 - val_accuracy: 0.8445\n",
            "Epoch 78/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1627 - accuracy: 0.9423 - val_loss: 0.6151 - val_accuracy: 0.8457\n",
            "Epoch 79/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1590 - accuracy: 0.9445 - val_loss: 0.5977 - val_accuracy: 0.8447\n",
            "Epoch 80/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1622 - accuracy: 0.9421 - val_loss: 0.6074 - val_accuracy: 0.8450\n",
            "Epoch 81/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1536 - accuracy: 0.9464 - val_loss: 0.6140 - val_accuracy: 0.8443\n",
            "Epoch 82/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1521 - accuracy: 0.9469 - val_loss: 0.6142 - val_accuracy: 0.8435\n",
            "Epoch 83/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1474 - accuracy: 0.9479 - val_loss: 0.6299 - val_accuracy: 0.8453\n",
            "Epoch 84/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1454 - accuracy: 0.9484 - val_loss: 0.6655 - val_accuracy: 0.8448\n",
            "Epoch 85/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1474 - accuracy: 0.9486 - val_loss: 0.6479 - val_accuracy: 0.8450\n",
            "Epoch 86/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1419 - accuracy: 0.9502 - val_loss: 0.6542 - val_accuracy: 0.8458\n",
            "Epoch 87/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1383 - accuracy: 0.9517 - val_loss: 0.6716 - val_accuracy: 0.8427\n",
            "Epoch 88/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1369 - accuracy: 0.9523 - val_loss: 0.6735 - val_accuracy: 0.8422\n",
            "Epoch 89/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1375 - accuracy: 0.9519 - val_loss: 0.6828 - val_accuracy: 0.8382\n",
            "Epoch 90/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1299 - accuracy: 0.9548 - val_loss: 0.7064 - val_accuracy: 0.8388\n",
            "Epoch 91/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1292 - accuracy: 0.9549 - val_loss: 0.7132 - val_accuracy: 0.8425\n",
            "Epoch 92/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1314 - accuracy: 0.9539 - val_loss: 0.7195 - val_accuracy: 0.8400\n",
            "Epoch 93/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1261 - accuracy: 0.9558 - val_loss: 0.7299 - val_accuracy: 0.8415\n",
            "Epoch 94/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1224 - accuracy: 0.9580 - val_loss: 0.7378 - val_accuracy: 0.8418\n",
            "Epoch 95/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1232 - accuracy: 0.9570 - val_loss: 0.7369 - val_accuracy: 0.8418\n",
            "Epoch 96/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1185 - accuracy: 0.9592 - val_loss: 0.7716 - val_accuracy: 0.8372\n",
            "Epoch 97/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1199 - accuracy: 0.9576 - val_loss: 0.7691 - val_accuracy: 0.8402\n",
            "Epoch 98/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1147 - accuracy: 0.9598 - val_loss: 0.7857 - val_accuracy: 0.8367\n",
            "Epoch 99/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1171 - accuracy: 0.9594 - val_loss: 0.7513 - val_accuracy: 0.8392\n",
            "Epoch 100/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1209 - accuracy: 0.9582 - val_loss: 0.7739 - val_accuracy: 0.8393\n",
            "Epoch 101/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1078 - accuracy: 0.9632 - val_loss: 0.7950 - val_accuracy: 0.8400\n",
            "Epoch 102/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1088 - accuracy: 0.9621 - val_loss: 0.8012 - val_accuracy: 0.8388\n",
            "Epoch 103/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1046 - accuracy: 0.9640 - val_loss: 0.7943 - val_accuracy: 0.8357\n",
            "Epoch 104/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1064 - accuracy: 0.9634 - val_loss: 0.8202 - val_accuracy: 0.8402\n",
            "Epoch 105/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1062 - accuracy: 0.9632 - val_loss: 0.8130 - val_accuracy: 0.8400\n",
            "Epoch 106/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1024 - accuracy: 0.9648 - val_loss: 0.8360 - val_accuracy: 0.8388\n",
            "Epoch 107/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0986 - accuracy: 0.9656 - val_loss: 0.8575 - val_accuracy: 0.8328\n",
            "Epoch 108/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0950 - accuracy: 0.9670 - val_loss: 0.8653 - val_accuracy: 0.8362\n",
            "Epoch 109/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0975 - accuracy: 0.9664 - val_loss: 0.8798 - val_accuracy: 0.8387\n",
            "Epoch 110/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0937 - accuracy: 0.9679 - val_loss: 0.8927 - val_accuracy: 0.8403\n",
            "Epoch 111/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0928 - accuracy: 0.9684 - val_loss: 0.8834 - val_accuracy: 0.8398\n",
            "Epoch 112/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0897 - accuracy: 0.9695 - val_loss: 0.8787 - val_accuracy: 0.8395\n",
            "Epoch 113/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0911 - accuracy: 0.9685 - val_loss: 0.9103 - val_accuracy: 0.8370\n",
            "Epoch 114/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0860 - accuracy: 0.9709 - val_loss: 0.9364 - val_accuracy: 0.8387\n",
            "Epoch 115/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0870 - accuracy: 0.9703 - val_loss: 0.9219 - val_accuracy: 0.8372\n",
            "Epoch 116/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0819 - accuracy: 0.9716 - val_loss: 0.9847 - val_accuracy: 0.8345\n",
            "Epoch 117/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0822 - accuracy: 0.9720 - val_loss: 0.9283 - val_accuracy: 0.8388\n",
            "Epoch 118/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0863 - accuracy: 0.9701 - val_loss: 0.9271 - val_accuracy: 0.8403\n",
            "Epoch 119/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0759 - accuracy: 0.9742 - val_loss: 0.9306 - val_accuracy: 0.8405\n",
            "Epoch 120/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0824 - accuracy: 0.9718 - val_loss: 0.9519 - val_accuracy: 0.8362\n",
            "Epoch 121/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0743 - accuracy: 0.9751 - val_loss: 0.9742 - val_accuracy: 0.8368\n",
            "Epoch 122/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0731 - accuracy: 0.9750 - val_loss: 0.9920 - val_accuracy: 0.8368\n",
            "Epoch 123/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0777 - accuracy: 0.9739 - val_loss: 0.9604 - val_accuracy: 0.8373\n",
            "Epoch 124/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0729 - accuracy: 0.9753 - val_loss: 0.9841 - val_accuracy: 0.8377\n",
            "Epoch 125/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0724 - accuracy: 0.9758 - val_loss: 0.9781 - val_accuracy: 0.8425\n",
            "Epoch 126/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0709 - accuracy: 0.9763 - val_loss: 0.9995 - val_accuracy: 0.8400\n",
            "Epoch 127/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 1.0303 - val_accuracy: 0.8397\n",
            "Epoch 128/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0680 - accuracy: 0.9772 - val_loss: 1.0337 - val_accuracy: 0.8400\n",
            "Epoch 129/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0687 - accuracy: 0.9768 - val_loss: 1.0311 - val_accuracy: 0.8390\n",
            "Epoch 130/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0680 - accuracy: 0.9773 - val_loss: 1.0534 - val_accuracy: 0.8380\n",
            "Epoch 131/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0669 - accuracy: 0.9780 - val_loss: 1.0432 - val_accuracy: 0.8387\n",
            "Epoch 132/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0611 - accuracy: 0.9796 - val_loss: 1.0771 - val_accuracy: 0.8388\n",
            "Epoch 133/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0609 - accuracy: 0.9797 - val_loss: 1.0703 - val_accuracy: 0.8388\n",
            "Epoch 134/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0663 - accuracy: 0.9773 - val_loss: 1.0564 - val_accuracy: 0.8388\n",
            "Epoch 135/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0605 - accuracy: 0.9801 - val_loss: 1.1097 - val_accuracy: 0.8343\n",
            "Epoch 136/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0579 - accuracy: 0.9809 - val_loss: 1.1504 - val_accuracy: 0.8337\n",
            "Epoch 137/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0628 - accuracy: 0.9793 - val_loss: 1.1115 - val_accuracy: 0.8392\n",
            "Epoch 138/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0513 - accuracy: 0.9830 - val_loss: 1.1140 - val_accuracy: 0.8395\n",
            "Epoch 139/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0634 - accuracy: 0.9786 - val_loss: 1.0953 - val_accuracy: 0.8417\n",
            "Epoch 140/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0514 - accuracy: 0.9830 - val_loss: 1.1353 - val_accuracy: 0.8378\n",
            "Epoch 141/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0549 - accuracy: 0.9813 - val_loss: 1.1675 - val_accuracy: 0.8382\n",
            "Epoch 142/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0601 - accuracy: 0.9800 - val_loss: 1.1229 - val_accuracy: 0.8395\n",
            "Epoch 143/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 1.1616 - val_accuracy: 0.8350\n",
            "Epoch 144/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0546 - accuracy: 0.9821 - val_loss: 1.1418 - val_accuracy: 0.8425\n",
            "Epoch 145/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0471 - accuracy: 0.9845 - val_loss: 1.2008 - val_accuracy: 0.8377\n",
            "Epoch 146/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0555 - accuracy: 0.9812 - val_loss: 1.1680 - val_accuracy: 0.8385\n",
            "Epoch 147/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0490 - accuracy: 0.9844 - val_loss: 1.2545 - val_accuracy: 0.8380\n",
            "Epoch 148/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0500 - accuracy: 0.9839 - val_loss: 1.1806 - val_accuracy: 0.8398\n",
            "Epoch 149/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0464 - accuracy: 0.9844 - val_loss: 1.1941 - val_accuracy: 0.8388\n",
            "Epoch 150/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0532 - accuracy: 0.9822 - val_loss: 1.1976 - val_accuracy: 0.8408\n",
            "Epoch 151/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 1.2028 - val_accuracy: 0.8407\n",
            "Epoch 152/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0518 - accuracy: 0.9829 - val_loss: 1.1771 - val_accuracy: 0.8397\n",
            "Epoch 153/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0459 - accuracy: 0.9847 - val_loss: 1.2002 - val_accuracy: 0.8397\n",
            "Epoch 154/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0412 - accuracy: 0.9861 - val_loss: 1.2299 - val_accuracy: 0.8408\n",
            "Epoch 155/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0477 - accuracy: 0.9844 - val_loss: 1.2033 - val_accuracy: 0.8405\n",
            "Epoch 156/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 1.2413 - val_accuracy: 0.8363\n",
            "Epoch 157/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0425 - accuracy: 0.9860 - val_loss: 1.2555 - val_accuracy: 0.8347\n",
            "Epoch 158/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0437 - accuracy: 0.9858 - val_loss: 1.2742 - val_accuracy: 0.8378\n",
            "Epoch 159/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 1.3182 - val_accuracy: 0.8390\n",
            "Epoch 160/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0445 - accuracy: 0.9855 - val_loss: 1.2763 - val_accuracy: 0.8348\n",
            "Epoch 161/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0447 - accuracy: 0.9855 - val_loss: 1.2759 - val_accuracy: 0.8348\n",
            "Epoch 162/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0359 - accuracy: 0.9883 - val_loss: 1.3068 - val_accuracy: 0.8388\n",
            "Epoch 163/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 1.2643 - val_accuracy: 0.8330\n",
            "Epoch 164/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0407 - accuracy: 0.9865 - val_loss: 1.2691 - val_accuracy: 0.8370\n",
            "Epoch 165/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 1.3282 - val_accuracy: 0.8415\n",
            "Epoch 166/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0338 - accuracy: 0.9893 - val_loss: 1.3137 - val_accuracy: 0.8402\n",
            "Epoch 167/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0482 - accuracy: 0.9845 - val_loss: 1.2566 - val_accuracy: 0.8423\n",
            "Epoch 168/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0306 - accuracy: 0.9907 - val_loss: 1.2981 - val_accuracy: 0.8375\n",
            "Epoch 169/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0431 - accuracy: 0.9864 - val_loss: 1.2989 - val_accuracy: 0.8385\n",
            "Epoch 170/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0345 - accuracy: 0.9888 - val_loss: 1.3427 - val_accuracy: 0.8390\n",
            "Epoch 171/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 1.2883 - val_accuracy: 0.8363\n",
            "Epoch 172/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 1.3594 - val_accuracy: 0.8303\n",
            "Epoch 173/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0330 - accuracy: 0.9896 - val_loss: 1.3510 - val_accuracy: 0.8373\n",
            "Epoch 174/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0386 - accuracy: 0.9875 - val_loss: 1.3334 - val_accuracy: 0.8428\n",
            "Epoch 175/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 1.3196 - val_accuracy: 0.8387\n",
            "Epoch 176/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 1.3664 - val_accuracy: 0.8420\n",
            "Epoch 177/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 1.3297 - val_accuracy: 0.8353\n",
            "Epoch 178/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0357 - accuracy: 0.9884 - val_loss: 1.3566 - val_accuracy: 0.8352\n",
            "Epoch 179/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 1.3680 - val_accuracy: 0.8372\n",
            "Epoch 180/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0281 - accuracy: 0.9912 - val_loss: 1.3970 - val_accuracy: 0.8347\n",
            "Epoch 181/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0356 - accuracy: 0.9889 - val_loss: 1.4031 - val_accuracy: 0.8388\n",
            "Epoch 182/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 1.3676 - val_accuracy: 0.8393\n",
            "Epoch 183/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 1.4121 - val_accuracy: 0.8340\n",
            "Epoch 184/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 1.4323 - val_accuracy: 0.8367\n",
            "Epoch 185/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 1.3864 - val_accuracy: 0.8407\n",
            "Epoch 186/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 1.4145 - val_accuracy: 0.8387\n",
            "Epoch 187/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 1.4211 - val_accuracy: 0.8372\n",
            "Epoch 188/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0254 - accuracy: 0.9915 - val_loss: 1.4030 - val_accuracy: 0.8393\n",
            "Epoch 189/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0335 - accuracy: 0.9892 - val_loss: 1.4242 - val_accuracy: 0.8408\n",
            "Epoch 190/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 1.3940 - val_accuracy: 0.8377\n",
            "Epoch 191/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 1.4622 - val_accuracy: 0.8343\n",
            "Epoch 192/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 1.4015 - val_accuracy: 0.8427\n",
            "Epoch 193/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 1.4125 - val_accuracy: 0.8425\n",
            "Epoch 194/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 1.4575 - val_accuracy: 0.8413\n",
            "Epoch 195/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 1.4614 - val_accuracy: 0.8365\n",
            "Epoch 196/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0238 - accuracy: 0.9924 - val_loss: 1.4551 - val_accuracy: 0.8397\n",
            "Epoch 197/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 1.4366 - val_accuracy: 0.8398\n",
            "Epoch 198/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 1.4635 - val_accuracy: 0.8413\n",
            "Epoch 199/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 1.5411 - val_accuracy: 0.8387\n",
            "Epoch 200/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 1.4557 - val_accuracy: 0.8387\n",
            "Epoch 201/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0246 - accuracy: 0.9924 - val_loss: 1.4904 - val_accuracy: 0.8378\n",
            "Epoch 202/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 1.4745 - val_accuracy: 0.8367\n",
            "Epoch 203/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 1.4757 - val_accuracy: 0.8362\n",
            "Epoch 204/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 1.4693 - val_accuracy: 0.8412\n",
            "Epoch 205/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0197 - accuracy: 0.9941 - val_loss: 1.4935 - val_accuracy: 0.8388\n",
            "Epoch 206/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0323 - accuracy: 0.9900 - val_loss: 1.5049 - val_accuracy: 0.8388\n",
            "Epoch 207/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 1.5200 - val_accuracy: 0.8352\n",
            "Epoch 208/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 1.4915 - val_accuracy: 0.8400\n",
            "Epoch 209/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 1.4909 - val_accuracy: 0.8330\n",
            "Epoch 210/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 1.5512 - val_accuracy: 0.8352\n",
            "Epoch 211/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 1.5592 - val_accuracy: 0.8352\n",
            "Epoch 212/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0248 - accuracy: 0.9923 - val_loss: 1.5003 - val_accuracy: 0.8387\n",
            "Epoch 213/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 1.5301 - val_accuracy: 0.8398\n",
            "Epoch 214/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 1.4911 - val_accuracy: 0.8367\n",
            "Epoch 215/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 1.5445 - val_accuracy: 0.8387\n",
            "Epoch 216/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 1.4920 - val_accuracy: 0.8408\n",
            "Epoch 217/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0194 - accuracy: 0.9938 - val_loss: 1.5241 - val_accuracy: 0.8400\n",
            "Epoch 218/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 1.5430 - val_accuracy: 0.8375\n",
            "Epoch 219/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 1.5404 - val_accuracy: 0.8383\n",
            "Epoch 220/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 1.5353 - val_accuracy: 0.8400\n",
            "Epoch 221/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 1.5257 - val_accuracy: 0.8402\n",
            "Epoch 222/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 1.5454 - val_accuracy: 0.8367\n",
            "Epoch 223/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 1.5238 - val_accuracy: 0.8405\n",
            "Epoch 224/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0202 - accuracy: 0.9939 - val_loss: 1.5350 - val_accuracy: 0.8427\n",
            "Epoch 225/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 1.5391 - val_accuracy: 0.8403\n",
            "Epoch 226/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 1.5884 - val_accuracy: 0.8355\n",
            "Epoch 227/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 1.5933 - val_accuracy: 0.8343\n",
            "Epoch 228/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 1.5557 - val_accuracy: 0.8405\n",
            "Epoch 229/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 1.5692 - val_accuracy: 0.8392\n",
            "Epoch 230/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 1.5810 - val_accuracy: 0.8373\n",
            "Epoch 231/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 1.5715 - val_accuracy: 0.8442\n",
            "Epoch 232/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 1.5631 - val_accuracy: 0.8382\n",
            "Epoch 233/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 1.5836 - val_accuracy: 0.8368\n",
            "Epoch 234/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 1.5764 - val_accuracy: 0.8393\n",
            "Epoch 235/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 1.5715 - val_accuracy: 0.8343\n",
            "Epoch 236/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 1.5900 - val_accuracy: 0.8385\n",
            "Epoch 237/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 1.5586 - val_accuracy: 0.8403\n",
            "Epoch 238/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 1.5350 - val_accuracy: 0.8383\n",
            "Epoch 239/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 1.5860 - val_accuracy: 0.8398\n",
            "Epoch 240/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 1.5779 - val_accuracy: 0.8410\n",
            "Epoch 241/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 1.5420 - val_accuracy: 0.8347\n",
            "Epoch 242/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0173 - accuracy: 0.9941 - val_loss: 1.5749 - val_accuracy: 0.8405\n",
            "Epoch 243/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0189 - accuracy: 0.9938 - val_loss: 1.5700 - val_accuracy: 0.8357\n",
            "Epoch 244/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 1.5736 - val_accuracy: 0.8400\n",
            "Epoch 245/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 1.5660 - val_accuracy: 0.8428\n",
            "Epoch 246/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 1.6203 - val_accuracy: 0.8385\n",
            "Epoch 247/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 1.5794 - val_accuracy: 0.8420\n",
            "Epoch 248/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 1.5633 - val_accuracy: 0.8407\n",
            "Epoch 249/250\n",
            "1782/1782 [==============================] - 52s 29ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 1.5432 - val_accuracy: 0.8393\n",
            "Epoch 250/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 1.5669 - val_accuracy: 0.8403\n",
            "CPU times: user 7h 3min 54s, sys: 2h 5min 15s, total: 9h 9min 10s\n",
            "Wall time: 3h 27min 49s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v9Y7CQFa64UM",
        "outputId": "24c9b53a-bbe4-4b93-c8da-71b9ff6e454d"
      },
      "source": [
        "%%time\n",
        "encoder_2000 = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=2000)\n",
        "encoder_2000.adapt(dataset_all.map(lambda text, label: text))\n",
        "vocab_2000 = np.array(encoder_2000.get_vocabulary());"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fbfdfb50b90> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fbfdfb50b90>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fbfdfb50b90> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fbfdfb50b90>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7fbfdfb50b90> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fbfdfb50b90>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "CPU times: user 6min 54s, sys: 1min 58s, total: 8min 53s\n",
            "Wall time: 3min 17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PYzG6Po68yHC",
        "outputId": "a4b96fb9-d37e-41e0-adbe-c9560acb5e2f"
      },
      "source": [
        "%%time\n",
        "doc2000_sizes = []\n",
        "corpus2000 = []\n",
        "count2000=0\n",
        "useless = 0\n",
        "percents = []\n",
        "for example, _ in dataset_all.as_numpy_iterator():\n",
        "  enc_example = encoder_2000(example)\n",
        "  num_ones = tf.math.count_nonzero(enc_example==1).numpy()\n",
        "  percent_ones = round(num_ones*100/len(enc_example))\n",
        "  percents.append(percent_ones)\n",
        "\n",
        "  s = set(list(enc_example.numpy()))\n",
        "  if s == {1}: useless+=1\n",
        "\n",
        "  doc2000_sizes.append(len(enc_example))\n",
        "  corpus2000+=list(enc_example.numpy())\n",
        "\n",
        "  count2000 += tf.math.count_nonzero(enc_example>1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 18min 34s, sys: 2min 19s, total: 20min 53s\n",
            "Wall time: 17min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nGKfQ9xc80wT"
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "encoder\n",
        ",tf.keras.layers.Embedding(input_dim=len(encoder_2000.get_vocabulary())\n",
        ",output_dim=64\n",
        ",mask_zero=True)\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))\n",
        ",tf.keras.layers.Dense(64, activation='relu')\n",
        ",tf.keras.layers.Dense(4,activation='softmax')])\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(1e-4),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tQDYVF0P83sn",
        "outputId": "49638cbd-854d-42ef-d653-46d312921a7c"
      },
      "source": [
        "%%time\n",
        "history2 = model2.fit(train_dataset ,epochs = 250 ,validation_data=validation_dataset ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1782/1782 [==============================] - 39s 18ms/step - loss: 0.7455 - accuracy: 0.7194 - val_loss: 0.4996 - val_accuracy: 0.8257\n",
            "Epoch 2/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.4565 - accuracy: 0.8408 - val_loss: 0.4509 - val_accuracy: 0.8430\n",
            "Epoch 3/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.4126 - accuracy: 0.8527 - val_loss: 0.4219 - val_accuracy: 0.8500\n",
            "Epoch 4/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3961 - accuracy: 0.8580 - val_loss: 0.4037 - val_accuracy: 0.8540\n",
            "Epoch 5/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3876 - accuracy: 0.8591 - val_loss: 0.3918 - val_accuracy: 0.8628\n",
            "Epoch 6/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3824 - accuracy: 0.8615 - val_loss: 0.3813 - val_accuracy: 0.8648\n",
            "Epoch 7/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3780 - accuracy: 0.8622 - val_loss: 0.3836 - val_accuracy: 0.8657\n",
            "Epoch 8/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3744 - accuracy: 0.8635 - val_loss: 0.3792 - val_accuracy: 0.8627\n",
            "Epoch 9/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3714 - accuracy: 0.8641 - val_loss: 0.3790 - val_accuracy: 0.8628\n",
            "Epoch 10/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3682 - accuracy: 0.8654 - val_loss: 0.3844 - val_accuracy: 0.8618\n",
            "Epoch 11/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3660 - accuracy: 0.8663 - val_loss: 0.3836 - val_accuracy: 0.8653\n",
            "Epoch 12/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3626 - accuracy: 0.8672 - val_loss: 0.3699 - val_accuracy: 0.8675\n",
            "Epoch 13/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3597 - accuracy: 0.8681 - val_loss: 0.3708 - val_accuracy: 0.8685\n",
            "Epoch 14/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3570 - accuracy: 0.8690 - val_loss: 0.3723 - val_accuracy: 0.8677\n",
            "Epoch 15/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3534 - accuracy: 0.8701 - val_loss: 0.3676 - val_accuracy: 0.8690\n",
            "Epoch 16/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3511 - accuracy: 0.8711 - val_loss: 0.3660 - val_accuracy: 0.8673\n",
            "Epoch 17/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3477 - accuracy: 0.8724 - val_loss: 0.3700 - val_accuracy: 0.8658\n",
            "Epoch 18/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3445 - accuracy: 0.8733 - val_loss: 0.3639 - val_accuracy: 0.8680\n",
            "Epoch 19/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3420 - accuracy: 0.8741 - val_loss: 0.3663 - val_accuracy: 0.8685\n",
            "Epoch 20/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3388 - accuracy: 0.8758 - val_loss: 0.3661 - val_accuracy: 0.8672\n",
            "Epoch 21/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3366 - accuracy: 0.8771 - val_loss: 0.3640 - val_accuracy: 0.8677\n",
            "Epoch 22/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3338 - accuracy: 0.8776 - val_loss: 0.3625 - val_accuracy: 0.8697\n",
            "Epoch 23/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3307 - accuracy: 0.8785 - val_loss: 0.3701 - val_accuracy: 0.8680\n",
            "Epoch 24/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3288 - accuracy: 0.8797 - val_loss: 0.3631 - val_accuracy: 0.8673\n",
            "Epoch 25/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3264 - accuracy: 0.8803 - val_loss: 0.3647 - val_accuracy: 0.8675\n",
            "Epoch 26/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3239 - accuracy: 0.8810 - val_loss: 0.3700 - val_accuracy: 0.8673\n",
            "Epoch 27/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3218 - accuracy: 0.8823 - val_loss: 0.3650 - val_accuracy: 0.8658\n",
            "Epoch 28/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3193 - accuracy: 0.8831 - val_loss: 0.3671 - val_accuracy: 0.8682\n",
            "Epoch 29/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3175 - accuracy: 0.8837 - val_loss: 0.3665 - val_accuracy: 0.8695\n",
            "Epoch 30/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3151 - accuracy: 0.8848 - val_loss: 0.3664 - val_accuracy: 0.8688\n",
            "Epoch 31/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3130 - accuracy: 0.8851 - val_loss: 0.3668 - val_accuracy: 0.8677\n",
            "Epoch 32/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3105 - accuracy: 0.8858 - val_loss: 0.3685 - val_accuracy: 0.8680\n",
            "Epoch 33/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3086 - accuracy: 0.8865 - val_loss: 0.3712 - val_accuracy: 0.8685\n",
            "Epoch 34/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3064 - accuracy: 0.8874 - val_loss: 0.3678 - val_accuracy: 0.8662\n",
            "Epoch 35/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3042 - accuracy: 0.8882 - val_loss: 0.3780 - val_accuracy: 0.8638\n",
            "Epoch 36/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3018 - accuracy: 0.8895 - val_loss: 0.3705 - val_accuracy: 0.8682\n",
            "Epoch 37/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2995 - accuracy: 0.8898 - val_loss: 0.3722 - val_accuracy: 0.8662\n",
            "Epoch 38/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2974 - accuracy: 0.8906 - val_loss: 0.3758 - val_accuracy: 0.8663\n",
            "Epoch 39/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2946 - accuracy: 0.8921 - val_loss: 0.3717 - val_accuracy: 0.8663\n",
            "Epoch 40/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2922 - accuracy: 0.8922 - val_loss: 0.3727 - val_accuracy: 0.8648\n",
            "Epoch 41/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2900 - accuracy: 0.8929 - val_loss: 0.3737 - val_accuracy: 0.8663\n",
            "Epoch 42/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2870 - accuracy: 0.8946 - val_loss: 0.3725 - val_accuracy: 0.8643\n",
            "Epoch 43/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2851 - accuracy: 0.8952 - val_loss: 0.3801 - val_accuracy: 0.8618\n",
            "Epoch 44/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2830 - accuracy: 0.8965 - val_loss: 0.3793 - val_accuracy: 0.8637\n",
            "Epoch 45/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2803 - accuracy: 0.8973 - val_loss: 0.3784 - val_accuracy: 0.8655\n",
            "Epoch 46/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2778 - accuracy: 0.8984 - val_loss: 0.3780 - val_accuracy: 0.8653\n",
            "Epoch 47/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2759 - accuracy: 0.8989 - val_loss: 0.3828 - val_accuracy: 0.8640\n",
            "Epoch 48/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2730 - accuracy: 0.8998 - val_loss: 0.3847 - val_accuracy: 0.8623\n",
            "Epoch 49/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2706 - accuracy: 0.9008 - val_loss: 0.3899 - val_accuracy: 0.8625\n",
            "Epoch 50/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2682 - accuracy: 0.9018 - val_loss: 0.3900 - val_accuracy: 0.8628\n",
            "Epoch 51/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2658 - accuracy: 0.9026 - val_loss: 0.3958 - val_accuracy: 0.8608\n",
            "Epoch 52/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2634 - accuracy: 0.9035 - val_loss: 0.3947 - val_accuracy: 0.8623\n",
            "Epoch 53/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2610 - accuracy: 0.9050 - val_loss: 0.3942 - val_accuracy: 0.8642\n",
            "Epoch 54/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2585 - accuracy: 0.9058 - val_loss: 0.3939 - val_accuracy: 0.8628\n",
            "Epoch 55/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2565 - accuracy: 0.9065 - val_loss: 0.4046 - val_accuracy: 0.8625\n",
            "Epoch 56/250\n",
            "1782/1782 [==============================] - 30s 17ms/step - loss: 0.2537 - accuracy: 0.9074 - val_loss: 0.4029 - val_accuracy: 0.8615\n",
            "Epoch 57/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2522 - accuracy: 0.9079 - val_loss: 0.4113 - val_accuracy: 0.8625\n",
            "Epoch 58/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2497 - accuracy: 0.9087 - val_loss: 0.4114 - val_accuracy: 0.8595\n",
            "Epoch 59/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2474 - accuracy: 0.9097 - val_loss: 0.4218 - val_accuracy: 0.8570\n",
            "Epoch 60/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2446 - accuracy: 0.9109 - val_loss: 0.4138 - val_accuracy: 0.8565\n",
            "Epoch 61/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2436 - accuracy: 0.9115 - val_loss: 0.4147 - val_accuracy: 0.8605\n",
            "Epoch 62/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2405 - accuracy: 0.9124 - val_loss: 0.4216 - val_accuracy: 0.8568\n",
            "Epoch 63/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2389 - accuracy: 0.9129 - val_loss: 0.4172 - val_accuracy: 0.8580\n",
            "Epoch 64/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2361 - accuracy: 0.9139 - val_loss: 0.4262 - val_accuracy: 0.8588\n",
            "Epoch 65/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2341 - accuracy: 0.9143 - val_loss: 0.4201 - val_accuracy: 0.8568\n",
            "Epoch 66/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2317 - accuracy: 0.9162 - val_loss: 0.4315 - val_accuracy: 0.8558\n",
            "Epoch 67/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2302 - accuracy: 0.9165 - val_loss: 0.4370 - val_accuracy: 0.8585\n",
            "Epoch 68/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2281 - accuracy: 0.9171 - val_loss: 0.4417 - val_accuracy: 0.8543\n",
            "Epoch 69/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2256 - accuracy: 0.9178 - val_loss: 0.4326 - val_accuracy: 0.8590\n",
            "Epoch 70/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2231 - accuracy: 0.9186 - val_loss: 0.4502 - val_accuracy: 0.8562\n",
            "Epoch 71/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2212 - accuracy: 0.9202 - val_loss: 0.4518 - val_accuracy: 0.8575\n",
            "Epoch 72/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2193 - accuracy: 0.9204 - val_loss: 0.4544 - val_accuracy: 0.8557\n",
            "Epoch 73/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2168 - accuracy: 0.9218 - val_loss: 0.4468 - val_accuracy: 0.8560\n",
            "Epoch 74/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2145 - accuracy: 0.9228 - val_loss: 0.4551 - val_accuracy: 0.8567\n",
            "Epoch 75/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2125 - accuracy: 0.9230 - val_loss: 0.4614 - val_accuracy: 0.8558\n",
            "Epoch 76/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2101 - accuracy: 0.9237 - val_loss: 0.4643 - val_accuracy: 0.8520\n",
            "Epoch 77/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2073 - accuracy: 0.9253 - val_loss: 0.4734 - val_accuracy: 0.8570\n",
            "Epoch 78/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2050 - accuracy: 0.9268 - val_loss: 0.4794 - val_accuracy: 0.8562\n",
            "Epoch 79/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2033 - accuracy: 0.9265 - val_loss: 0.4879 - val_accuracy: 0.8528\n",
            "Epoch 80/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2012 - accuracy: 0.9275 - val_loss: 0.5023 - val_accuracy: 0.8568\n",
            "Epoch 81/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1982 - accuracy: 0.9285 - val_loss: 0.5030 - val_accuracy: 0.8563\n",
            "Epoch 82/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1962 - accuracy: 0.9294 - val_loss: 0.4918 - val_accuracy: 0.8540\n",
            "Epoch 83/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1951 - accuracy: 0.9296 - val_loss: 0.5113 - val_accuracy: 0.8562\n",
            "Epoch 84/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1935 - accuracy: 0.9300 - val_loss: 0.5120 - val_accuracy: 0.8552\n",
            "Epoch 85/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1890 - accuracy: 0.9319 - val_loss: 0.5220 - val_accuracy: 0.8493\n",
            "Epoch 86/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1876 - accuracy: 0.9324 - val_loss: 0.5141 - val_accuracy: 0.8517\n",
            "Epoch 87/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1858 - accuracy: 0.9332 - val_loss: 0.5318 - val_accuracy: 0.8518\n",
            "Epoch 88/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1826 - accuracy: 0.9348 - val_loss: 0.5327 - val_accuracy: 0.8517\n",
            "Epoch 89/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1814 - accuracy: 0.9348 - val_loss: 0.5582 - val_accuracy: 0.8530\n",
            "Epoch 90/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1787 - accuracy: 0.9363 - val_loss: 0.5446 - val_accuracy: 0.8503\n",
            "Epoch 91/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1768 - accuracy: 0.9369 - val_loss: 0.5370 - val_accuracy: 0.8512\n",
            "Epoch 92/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1737 - accuracy: 0.9379 - val_loss: 0.5424 - val_accuracy: 0.8477\n",
            "Epoch 93/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1719 - accuracy: 0.9383 - val_loss: 0.5615 - val_accuracy: 0.8502\n",
            "Epoch 94/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1726 - accuracy: 0.9380 - val_loss: 0.5758 - val_accuracy: 0.8467\n",
            "Epoch 95/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1681 - accuracy: 0.9399 - val_loss: 0.5729 - val_accuracy: 0.8478\n",
            "Epoch 96/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1659 - accuracy: 0.9406 - val_loss: 0.5737 - val_accuracy: 0.8493\n",
            "Epoch 97/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1644 - accuracy: 0.9409 - val_loss: 0.6042 - val_accuracy: 0.8492\n",
            "Epoch 98/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1618 - accuracy: 0.9429 - val_loss: 0.5942 - val_accuracy: 0.8467\n",
            "Epoch 99/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1593 - accuracy: 0.9437 - val_loss: 0.5879 - val_accuracy: 0.8453\n",
            "Epoch 100/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1568 - accuracy: 0.9446 - val_loss: 0.6162 - val_accuracy: 0.8482\n",
            "Epoch 101/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1555 - accuracy: 0.9446 - val_loss: 0.6223 - val_accuracy: 0.8488\n",
            "Epoch 102/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1522 - accuracy: 0.9464 - val_loss: 0.6288 - val_accuracy: 0.8453\n",
            "Epoch 103/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1501 - accuracy: 0.9471 - val_loss: 0.6402 - val_accuracy: 0.8443\n",
            "Epoch 104/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1493 - accuracy: 0.9473 - val_loss: 0.6598 - val_accuracy: 0.8455\n",
            "Epoch 105/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1460 - accuracy: 0.9487 - val_loss: 0.6626 - val_accuracy: 0.8433\n",
            "Epoch 106/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1442 - accuracy: 0.9496 - val_loss: 0.6651 - val_accuracy: 0.8407\n",
            "Epoch 107/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1413 - accuracy: 0.9503 - val_loss: 0.6608 - val_accuracy: 0.8423\n",
            "Epoch 108/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1407 - accuracy: 0.9506 - val_loss: 0.6823 - val_accuracy: 0.8463\n",
            "Epoch 109/250\n",
            "1782/1782 [==============================] - 30s 16ms/step - loss: 0.1387 - accuracy: 0.9516 - val_loss: 0.6966 - val_accuracy: 0.8402\n",
            "Epoch 110/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1349 - accuracy: 0.9528 - val_loss: 0.6993 - val_accuracy: 0.8432\n",
            "Epoch 111/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1341 - accuracy: 0.9534 - val_loss: 0.7096 - val_accuracy: 0.8410\n",
            "Epoch 112/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1324 - accuracy: 0.9541 - val_loss: 0.7186 - val_accuracy: 0.8432\n",
            "Epoch 113/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1300 - accuracy: 0.9547 - val_loss: 0.7211 - val_accuracy: 0.8410\n",
            "Epoch 114/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1282 - accuracy: 0.9555 - val_loss: 0.7321 - val_accuracy: 0.8365\n",
            "Epoch 115/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1285 - accuracy: 0.9548 - val_loss: 0.7395 - val_accuracy: 0.8420\n",
            "Epoch 116/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1223 - accuracy: 0.9577 - val_loss: 0.7559 - val_accuracy: 0.8402\n",
            "Epoch 117/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1220 - accuracy: 0.9581 - val_loss: 0.7600 - val_accuracy: 0.8387\n",
            "Epoch 118/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1206 - accuracy: 0.9585 - val_loss: 0.7873 - val_accuracy: 0.8362\n",
            "Epoch 119/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1183 - accuracy: 0.9593 - val_loss: 0.7900 - val_accuracy: 0.8322\n",
            "Epoch 120/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1154 - accuracy: 0.9595 - val_loss: 0.8054 - val_accuracy: 0.8377\n",
            "Epoch 121/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1157 - accuracy: 0.9597 - val_loss: 0.8171 - val_accuracy: 0.8395\n",
            "Epoch 122/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1112 - accuracy: 0.9620 - val_loss: 0.8296 - val_accuracy: 0.8402\n",
            "Epoch 123/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1131 - accuracy: 0.9609 - val_loss: 0.8126 - val_accuracy: 0.8398\n",
            "Epoch 124/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1081 - accuracy: 0.9630 - val_loss: 0.8361 - val_accuracy: 0.8395\n",
            "Epoch 125/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1086 - accuracy: 0.9628 - val_loss: 0.8604 - val_accuracy: 0.8343\n",
            "Epoch 126/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1059 - accuracy: 0.9642 - val_loss: 0.8681 - val_accuracy: 0.8375\n",
            "Epoch 127/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1044 - accuracy: 0.9644 - val_loss: 0.8574 - val_accuracy: 0.8412\n",
            "Epoch 128/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1023 - accuracy: 0.9649 - val_loss: 0.8627 - val_accuracy: 0.8365\n",
            "Epoch 129/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1019 - accuracy: 0.9652 - val_loss: 0.8871 - val_accuracy: 0.8363\n",
            "Epoch 130/250\n",
            "1782/1782 [==============================] - 30s 17ms/step - loss: 0.0980 - accuracy: 0.9670 - val_loss: 0.9323 - val_accuracy: 0.8375\n",
            "Epoch 131/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0997 - accuracy: 0.9656 - val_loss: 0.8846 - val_accuracy: 0.8373\n",
            "Epoch 132/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0974 - accuracy: 0.9670 - val_loss: 0.9294 - val_accuracy: 0.8397\n",
            "Epoch 133/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0910 - accuracy: 0.9695 - val_loss: 0.9671 - val_accuracy: 0.8372\n",
            "Epoch 134/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0923 - accuracy: 0.9690 - val_loss: 0.9434 - val_accuracy: 0.8377\n",
            "Epoch 135/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0925 - accuracy: 0.9688 - val_loss: 0.9384 - val_accuracy: 0.8350\n",
            "Epoch 136/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0887 - accuracy: 0.9705 - val_loss: 0.9783 - val_accuracy: 0.8372\n",
            "Epoch 137/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0868 - accuracy: 0.9713 - val_loss: 1.0222 - val_accuracy: 0.8338\n",
            "Epoch 138/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0849 - accuracy: 0.9717 - val_loss: 0.9873 - val_accuracy: 0.8352\n",
            "Epoch 139/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0862 - accuracy: 0.9714 - val_loss: 1.0330 - val_accuracy: 0.8335\n",
            "Epoch 140/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0854 - accuracy: 0.9711 - val_loss: 1.0222 - val_accuracy: 0.8362\n",
            "Epoch 141/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0795 - accuracy: 0.9743 - val_loss: 1.0062 - val_accuracy: 0.8307\n",
            "Epoch 142/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0815 - accuracy: 0.9725 - val_loss: 1.0307 - val_accuracy: 0.8365\n",
            "Epoch 143/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0784 - accuracy: 0.9737 - val_loss: 1.0783 - val_accuracy: 0.8352\n",
            "Epoch 144/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0754 - accuracy: 0.9752 - val_loss: 1.0975 - val_accuracy: 0.8357\n",
            "Epoch 145/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0804 - accuracy: 0.9732 - val_loss: 1.1079 - val_accuracy: 0.8312\n",
            "Epoch 146/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0749 - accuracy: 0.9753 - val_loss: 1.1050 - val_accuracy: 0.8347\n",
            "Epoch 147/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0731 - accuracy: 0.9761 - val_loss: 1.1149 - val_accuracy: 0.8320\n",
            "Epoch 148/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0745 - accuracy: 0.9759 - val_loss: 1.1454 - val_accuracy: 0.8313\n",
            "Epoch 149/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0840 - accuracy: 0.9719 - val_loss: 1.1053 - val_accuracy: 0.8340\n",
            "Epoch 150/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0680 - accuracy: 0.9779 - val_loss: 1.1516 - val_accuracy: 0.8353\n",
            "Epoch 151/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0700 - accuracy: 0.9774 - val_loss: 1.1739 - val_accuracy: 0.8328\n",
            "Epoch 152/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0676 - accuracy: 0.9780 - val_loss: 1.1643 - val_accuracy: 0.8338\n",
            "Epoch 153/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0654 - accuracy: 0.9788 - val_loss: 1.1665 - val_accuracy: 0.8305\n",
            "Epoch 154/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0667 - accuracy: 0.9785 - val_loss: 1.1964 - val_accuracy: 0.8302\n",
            "Epoch 155/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0646 - accuracy: 0.9790 - val_loss: 1.2445 - val_accuracy: 0.8288\n",
            "Epoch 156/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0672 - accuracy: 0.9781 - val_loss: 1.2283 - val_accuracy: 0.8300\n",
            "Epoch 157/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0608 - accuracy: 0.9802 - val_loss: 1.2786 - val_accuracy: 0.8348\n",
            "Epoch 158/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0605 - accuracy: 0.9804 - val_loss: 1.2847 - val_accuracy: 0.8338\n",
            "Epoch 159/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0600 - accuracy: 0.9805 - val_loss: 1.2506 - val_accuracy: 0.8310\n",
            "Epoch 160/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 1.3037 - val_accuracy: 0.8300\n",
            "Epoch 161/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0598 - accuracy: 0.9808 - val_loss: 1.3299 - val_accuracy: 0.8310\n",
            "Epoch 162/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0584 - accuracy: 0.9812 - val_loss: 1.3225 - val_accuracy: 0.8322\n",
            "Epoch 163/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 1.3010 - val_accuracy: 0.8303\n",
            "Epoch 164/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0544 - accuracy: 0.9831 - val_loss: 1.3069 - val_accuracy: 0.8298\n",
            "Epoch 165/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0553 - accuracy: 0.9824 - val_loss: 1.3349 - val_accuracy: 0.8302\n",
            "Epoch 166/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0550 - accuracy: 0.9826 - val_loss: 1.3748 - val_accuracy: 0.8265\n",
            "Epoch 167/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0526 - accuracy: 0.9834 - val_loss: 1.3891 - val_accuracy: 0.8317\n",
            "Epoch 168/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0537 - accuracy: 0.9830 - val_loss: 1.3735 - val_accuracy: 0.8312\n",
            "Epoch 169/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0514 - accuracy: 0.9836 - val_loss: 1.4124 - val_accuracy: 0.8338\n",
            "Epoch 170/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0497 - accuracy: 0.9846 - val_loss: 1.4151 - val_accuracy: 0.8312\n",
            "Epoch 171/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 1.4159 - val_accuracy: 0.8315\n",
            "Epoch 172/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0489 - accuracy: 0.9845 - val_loss: 1.4338 - val_accuracy: 0.8333\n",
            "Epoch 173/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0493 - accuracy: 0.9848 - val_loss: 1.4743 - val_accuracy: 0.8317\n",
            "Epoch 174/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0451 - accuracy: 0.9859 - val_loss: 1.4762 - val_accuracy: 0.8348\n",
            "Epoch 175/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0455 - accuracy: 0.9858 - val_loss: 1.4680 - val_accuracy: 0.8322\n",
            "Epoch 176/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0460 - accuracy: 0.9855 - val_loss: 1.4643 - val_accuracy: 0.8337\n",
            "Epoch 177/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 1.4864 - val_accuracy: 0.8337\n",
            "Epoch 178/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0426 - accuracy: 0.9868 - val_loss: 1.5114 - val_accuracy: 0.8328\n",
            "Epoch 179/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 1.5347 - val_accuracy: 0.8278\n",
            "Epoch 180/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 1.6115 - val_accuracy: 0.8258\n",
            "Epoch 181/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0416 - accuracy: 0.9869 - val_loss: 1.5609 - val_accuracy: 0.8288\n",
            "Epoch 182/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 1.5053 - val_accuracy: 0.8307\n",
            "Epoch 183/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0397 - accuracy: 0.9876 - val_loss: 1.5695 - val_accuracy: 0.8318\n",
            "Epoch 184/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0424 - accuracy: 0.9872 - val_loss: 1.6155 - val_accuracy: 0.8340\n",
            "Epoch 185/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0375 - accuracy: 0.9887 - val_loss: 1.6176 - val_accuracy: 0.8268\n",
            "Epoch 186/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0416 - accuracy: 0.9875 - val_loss: 1.6222 - val_accuracy: 0.8303\n",
            "Epoch 187/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 1.6541 - val_accuracy: 0.8302\n",
            "Epoch 188/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0387 - accuracy: 0.9880 - val_loss: 1.6423 - val_accuracy: 0.8300\n",
            "Epoch 189/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0359 - accuracy: 0.9890 - val_loss: 1.6474 - val_accuracy: 0.8293\n",
            "Epoch 190/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0398 - accuracy: 0.9877 - val_loss: 1.6328 - val_accuracy: 0.8322\n",
            "Epoch 191/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0351 - accuracy: 0.9894 - val_loss: 1.6906 - val_accuracy: 0.8298\n",
            "Epoch 192/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0402 - accuracy: 0.9880 - val_loss: 1.6669 - val_accuracy: 0.8312\n",
            "Epoch 193/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0332 - accuracy: 0.9904 - val_loss: 1.7102 - val_accuracy: 0.8342\n",
            "Epoch 194/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0350 - accuracy: 0.9894 - val_loss: 1.7275 - val_accuracy: 0.8260\n",
            "Epoch 195/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0333 - accuracy: 0.9901 - val_loss: 1.6916 - val_accuracy: 0.8328\n",
            "Epoch 196/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0371 - accuracy: 0.9894 - val_loss: 1.7494 - val_accuracy: 0.8263\n",
            "Epoch 197/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 1.7165 - val_accuracy: 0.8303\n",
            "Epoch 198/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0281 - accuracy: 0.9917 - val_loss: 1.8279 - val_accuracy: 0.8325\n",
            "Epoch 199/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 1.8110 - val_accuracy: 0.8290\n",
            "Epoch 200/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 1.7629 - val_accuracy: 0.8263\n",
            "Epoch 201/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 1.7419 - val_accuracy: 0.8308\n",
            "Epoch 202/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0300 - accuracy: 0.9914 - val_loss: 1.8327 - val_accuracy: 0.8322\n",
            "Epoch 203/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0305 - accuracy: 0.9909 - val_loss: 1.8076 - val_accuracy: 0.8345\n",
            "Epoch 204/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0285 - accuracy: 0.9916 - val_loss: 1.7755 - val_accuracy: 0.8270\n",
            "Epoch 205/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 1.8124 - val_accuracy: 0.8322\n",
            "Epoch 206/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 1.8583 - val_accuracy: 0.8282\n",
            "Epoch 207/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0288 - accuracy: 0.9915 - val_loss: 1.9469 - val_accuracy: 0.8287\n",
            "Epoch 208/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 1.8762 - val_accuracy: 0.8298\n",
            "Epoch 209/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 1.8837 - val_accuracy: 0.8325\n",
            "Epoch 210/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 1.8619 - val_accuracy: 0.8310\n",
            "Epoch 211/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0305 - accuracy: 0.9912 - val_loss: 1.9036 - val_accuracy: 0.8290\n",
            "Epoch 212/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0261 - accuracy: 0.9926 - val_loss: 1.9059 - val_accuracy: 0.8335\n",
            "Epoch 213/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0271 - accuracy: 0.9920 - val_loss: 1.8972 - val_accuracy: 0.8337\n",
            "Epoch 214/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 1.9457 - val_accuracy: 0.8323\n",
            "Epoch 215/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 1.9301 - val_accuracy: 0.8313\n",
            "Epoch 216/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 1.9891 - val_accuracy: 0.8323\n",
            "Epoch 217/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 2.0274 - val_accuracy: 0.8317\n",
            "Epoch 218/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 1.9496 - val_accuracy: 0.8275\n",
            "Epoch 219/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 1.9710 - val_accuracy: 0.8313\n",
            "Epoch 220/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 1.9804 - val_accuracy: 0.8262\n",
            "Epoch 221/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 2.0140 - val_accuracy: 0.8305\n",
            "Epoch 222/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 1.9773 - val_accuracy: 0.8283\n",
            "Epoch 223/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0244 - accuracy: 0.9927 - val_loss: 1.9999 - val_accuracy: 0.8277\n",
            "Epoch 224/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0254 - accuracy: 0.9927 - val_loss: 1.9817 - val_accuracy: 0.8310\n",
            "Epoch 225/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 1.9875 - val_accuracy: 0.8318\n",
            "Epoch 226/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0229 - accuracy: 0.9932 - val_loss: 2.0776 - val_accuracy: 0.8302\n",
            "Epoch 227/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0223 - accuracy: 0.9938 - val_loss: 2.1423 - val_accuracy: 0.8310\n",
            "Epoch 228/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 2.0262 - val_accuracy: 0.8330\n",
            "Epoch 229/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0207 - accuracy: 0.9941 - val_loss: 2.0723 - val_accuracy: 0.8318\n",
            "Epoch 230/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0215 - accuracy: 0.9938 - val_loss: 2.1022 - val_accuracy: 0.8277\n",
            "Epoch 231/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0261 - accuracy: 0.9922 - val_loss: 2.1027 - val_accuracy: 0.8310\n",
            "Epoch 232/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 2.1008 - val_accuracy: 0.8268\n",
            "Epoch 233/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 2.0549 - val_accuracy: 0.8280\n",
            "Epoch 234/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 2.0787 - val_accuracy: 0.8328\n",
            "Epoch 235/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 2.1465 - val_accuracy: 0.8300\n",
            "Epoch 236/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0247 - accuracy: 0.9928 - val_loss: 2.0813 - val_accuracy: 0.8325\n",
            "Epoch 237/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 2.1630 - val_accuracy: 0.8285\n",
            "Epoch 238/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 2.0728 - val_accuracy: 0.8310\n",
            "Epoch 239/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 2.1232 - val_accuracy: 0.8330\n",
            "Epoch 240/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0187 - accuracy: 0.9946 - val_loss: 2.1488 - val_accuracy: 0.8322\n",
            "Epoch 241/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 2.1820 - val_accuracy: 0.8280\n",
            "Epoch 242/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 2.1634 - val_accuracy: 0.8335\n",
            "Epoch 243/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 2.1366 - val_accuracy: 0.8297\n",
            "Epoch 244/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 2.1430 - val_accuracy: 0.8302\n",
            "Epoch 245/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 2.1634 - val_accuracy: 0.8288\n",
            "Epoch 246/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0161 - accuracy: 0.9955 - val_loss: 2.1612 - val_accuracy: 0.8325\n",
            "Epoch 247/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 2.1625 - val_accuracy: 0.8300\n",
            "Epoch 248/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 2.2238 - val_accuracy: 0.8312\n",
            "Epoch 249/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 2.2350 - val_accuracy: 0.8317\n",
            "Epoch 250/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 2.2382 - val_accuracy: 0.8338\n",
            "CPU times: user 4h 10min 21s, sys: 1h 15min 15s, total: 5h 25min 36s\n",
            "Wall time: 1h 59min 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U7kcTAWftlZq"
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "encoder\n",
        ",tf.keras.layers.Embedding(input_dim=len(encoder_2000.get_vocabulary())\n",
        ",output_dim=64\n",
        ",mask_zero=True)\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,  return_sequences=True))\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))\n",
        ",tf.keras.layers.Dense(64, activation='relu')\n",
        ",tf.keras.layers.Dense(4,activation='softmax')])\n",
        "model2.compile(optimizer=tf.keras.optimizers.Adam(1e-4),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NfjOpRK6tpqs",
        "outputId": "306cdb2a-9466-4b7a-e42d-d9b1d49254ad"
      },
      "source": [
        "%%time\n",
        "history2 = model2.fit(train_dataset ,epochs = 250 ,validation_data=validation_dataset ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1782/1782 [==============================] - 67s 30ms/step - loss: 0.6744 - accuracy: 0.7284 - val_loss: 0.4624 - val_accuracy: 0.8412\n",
            "Epoch 2/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.4391 - accuracy: 0.8426 - val_loss: 0.4147 - val_accuracy: 0.8555\n",
            "Epoch 3/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.4058 - accuracy: 0.8542 - val_loss: 0.4043 - val_accuracy: 0.8535\n",
            "Epoch 4/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3914 - accuracy: 0.8590 - val_loss: 0.4077 - val_accuracy: 0.8545\n",
            "Epoch 5/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3815 - accuracy: 0.8616 - val_loss: 0.3839 - val_accuracy: 0.8628\n",
            "Epoch 6/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3746 - accuracy: 0.8638 - val_loss: 0.3869 - val_accuracy: 0.8618\n",
            "Epoch 7/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3701 - accuracy: 0.8652 - val_loss: 0.3842 - val_accuracy: 0.8633\n",
            "Epoch 8/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3660 - accuracy: 0.8662 - val_loss: 0.3837 - val_accuracy: 0.8627\n",
            "Epoch 9/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3623 - accuracy: 0.8675 - val_loss: 0.3850 - val_accuracy: 0.8623\n",
            "Epoch 10/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3589 - accuracy: 0.8692 - val_loss: 0.3848 - val_accuracy: 0.8597\n",
            "Epoch 11/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3557 - accuracy: 0.8697 - val_loss: 0.3806 - val_accuracy: 0.8622\n",
            "Epoch 12/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3523 - accuracy: 0.8704 - val_loss: 0.3762 - val_accuracy: 0.8637\n",
            "Epoch 13/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3500 - accuracy: 0.8718 - val_loss: 0.3849 - val_accuracy: 0.8585\n",
            "Epoch 14/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3470 - accuracy: 0.8734 - val_loss: 0.3819 - val_accuracy: 0.8598\n",
            "Epoch 15/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3447 - accuracy: 0.8735 - val_loss: 0.3793 - val_accuracy: 0.8610\n",
            "Epoch 16/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3408 - accuracy: 0.8757 - val_loss: 0.3801 - val_accuracy: 0.8598\n",
            "Epoch 17/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3379 - accuracy: 0.8762 - val_loss: 0.3761 - val_accuracy: 0.8632\n",
            "Epoch 18/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3345 - accuracy: 0.8774 - val_loss: 0.3801 - val_accuracy: 0.8607\n",
            "Epoch 19/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3324 - accuracy: 0.8782 - val_loss: 0.3732 - val_accuracy: 0.8653\n",
            "Epoch 20/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3286 - accuracy: 0.8789 - val_loss: 0.3715 - val_accuracy: 0.8643\n",
            "Epoch 21/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3267 - accuracy: 0.8802 - val_loss: 0.3744 - val_accuracy: 0.8640\n",
            "Epoch 22/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3222 - accuracy: 0.8818 - val_loss: 0.3746 - val_accuracy: 0.8637\n",
            "Epoch 23/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3198 - accuracy: 0.8822 - val_loss: 0.3724 - val_accuracy: 0.8628\n",
            "Epoch 24/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3158 - accuracy: 0.8841 - val_loss: 0.3772 - val_accuracy: 0.8637\n",
            "Epoch 25/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3129 - accuracy: 0.8844 - val_loss: 0.3815 - val_accuracy: 0.8607\n",
            "Epoch 26/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3104 - accuracy: 0.8856 - val_loss: 0.3733 - val_accuracy: 0.8650\n",
            "Epoch 27/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3058 - accuracy: 0.8880 - val_loss: 0.3847 - val_accuracy: 0.8625\n",
            "Epoch 28/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3035 - accuracy: 0.8893 - val_loss: 0.3789 - val_accuracy: 0.8638\n",
            "Epoch 29/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.3002 - accuracy: 0.8902 - val_loss: 0.3792 - val_accuracy: 0.8662\n",
            "Epoch 30/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2967 - accuracy: 0.8913 - val_loss: 0.3816 - val_accuracy: 0.8647\n",
            "Epoch 31/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2935 - accuracy: 0.8924 - val_loss: 0.3798 - val_accuracy: 0.8638\n",
            "Epoch 32/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2912 - accuracy: 0.8933 - val_loss: 0.3814 - val_accuracy: 0.8642\n",
            "Epoch 33/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2878 - accuracy: 0.8945 - val_loss: 0.3860 - val_accuracy: 0.8612\n",
            "Epoch 34/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2843 - accuracy: 0.8951 - val_loss: 0.3917 - val_accuracy: 0.8630\n",
            "Epoch 35/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2817 - accuracy: 0.8967 - val_loss: 0.3902 - val_accuracy: 0.8607\n",
            "Epoch 36/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2785 - accuracy: 0.8981 - val_loss: 0.3910 - val_accuracy: 0.8647\n",
            "Epoch 37/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2754 - accuracy: 0.8990 - val_loss: 0.3925 - val_accuracy: 0.8638\n",
            "Epoch 38/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2724 - accuracy: 0.9010 - val_loss: 0.3922 - val_accuracy: 0.8645\n",
            "Epoch 39/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2687 - accuracy: 0.9021 - val_loss: 0.3947 - val_accuracy: 0.8630\n",
            "Epoch 40/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2662 - accuracy: 0.9028 - val_loss: 0.4037 - val_accuracy: 0.8607\n",
            "Epoch 41/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2632 - accuracy: 0.9048 - val_loss: 0.4032 - val_accuracy: 0.8592\n",
            "Epoch 42/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2596 - accuracy: 0.9058 - val_loss: 0.4012 - val_accuracy: 0.8617\n",
            "Epoch 43/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.2564 - accuracy: 0.9068 - val_loss: 0.4092 - val_accuracy: 0.8607\n",
            "Epoch 44/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.2529 - accuracy: 0.9082 - val_loss: 0.4152 - val_accuracy: 0.8613\n",
            "Epoch 45/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.2499 - accuracy: 0.9094 - val_loss: 0.4185 - val_accuracy: 0.8587\n",
            "Epoch 46/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.2477 - accuracy: 0.9096 - val_loss: 0.4164 - val_accuracy: 0.8575\n",
            "Epoch 47/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2443 - accuracy: 0.9115 - val_loss: 0.4247 - val_accuracy: 0.8563\n",
            "Epoch 48/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2417 - accuracy: 0.9124 - val_loss: 0.4315 - val_accuracy: 0.8583\n",
            "Epoch 49/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2391 - accuracy: 0.9135 - val_loss: 0.4352 - val_accuracy: 0.8553\n",
            "Epoch 50/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.2357 - accuracy: 0.9145 - val_loss: 0.4326 - val_accuracy: 0.8565\n",
            "Epoch 51/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2311 - accuracy: 0.9168 - val_loss: 0.4392 - val_accuracy: 0.8598\n",
            "Epoch 52/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2284 - accuracy: 0.9174 - val_loss: 0.4412 - val_accuracy: 0.8538\n",
            "Epoch 53/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2260 - accuracy: 0.9188 - val_loss: 0.4493 - val_accuracy: 0.8577\n",
            "Epoch 54/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2241 - accuracy: 0.9195 - val_loss: 0.4529 - val_accuracy: 0.8602\n",
            "Epoch 55/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2196 - accuracy: 0.9214 - val_loss: 0.4546 - val_accuracy: 0.8565\n",
            "Epoch 56/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.2174 - accuracy: 0.9224 - val_loss: 0.4609 - val_accuracy: 0.8540\n",
            "Epoch 57/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2135 - accuracy: 0.9237 - val_loss: 0.4791 - val_accuracy: 0.8555\n",
            "Epoch 58/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2121 - accuracy: 0.9235 - val_loss: 0.4656 - val_accuracy: 0.8558\n",
            "Epoch 59/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2073 - accuracy: 0.9264 - val_loss: 0.4834 - val_accuracy: 0.8533\n",
            "Epoch 60/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2083 - accuracy: 0.9259 - val_loss: 0.4865 - val_accuracy: 0.8517\n",
            "Epoch 61/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2003 - accuracy: 0.9291 - val_loss: 0.4842 - val_accuracy: 0.8547\n",
            "Epoch 62/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1995 - accuracy: 0.9291 - val_loss: 0.4989 - val_accuracy: 0.8543\n",
            "Epoch 63/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1972 - accuracy: 0.9301 - val_loss: 0.4920 - val_accuracy: 0.8563\n",
            "Epoch 64/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1945 - accuracy: 0.9309 - val_loss: 0.5158 - val_accuracy: 0.8530\n",
            "Epoch 65/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1907 - accuracy: 0.9325 - val_loss: 0.5151 - val_accuracy: 0.8535\n",
            "Epoch 66/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1855 - accuracy: 0.9349 - val_loss: 0.5199 - val_accuracy: 0.8530\n",
            "Epoch 67/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1848 - accuracy: 0.9341 - val_loss: 0.5248 - val_accuracy: 0.8535\n",
            "Epoch 68/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1819 - accuracy: 0.9355 - val_loss: 0.5325 - val_accuracy: 0.8525\n",
            "Epoch 69/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1816 - accuracy: 0.9360 - val_loss: 0.5452 - val_accuracy: 0.8510\n",
            "Epoch 70/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1759 - accuracy: 0.9384 - val_loss: 0.5563 - val_accuracy: 0.8530\n",
            "Epoch 71/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1759 - accuracy: 0.9380 - val_loss: 0.5551 - val_accuracy: 0.8460\n",
            "Epoch 72/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.1701 - accuracy: 0.9398 - val_loss: 0.5660 - val_accuracy: 0.8468\n",
            "Epoch 73/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1679 - accuracy: 0.9406 - val_loss: 0.5818 - val_accuracy: 0.8502\n",
            "Epoch 74/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1642 - accuracy: 0.9422 - val_loss: 0.5791 - val_accuracy: 0.8497\n",
            "Epoch 75/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1619 - accuracy: 0.9429 - val_loss: 0.5712 - val_accuracy: 0.8477\n",
            "Epoch 76/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1612 - accuracy: 0.9429 - val_loss: 0.6091 - val_accuracy: 0.8487\n",
            "Epoch 77/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1613 - accuracy: 0.9426 - val_loss: 0.5947 - val_accuracy: 0.8437\n",
            "Epoch 78/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1548 - accuracy: 0.9461 - val_loss: 0.6050 - val_accuracy: 0.8512\n",
            "Epoch 79/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1569 - accuracy: 0.9450 - val_loss: 0.6152 - val_accuracy: 0.8480\n",
            "Epoch 80/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1509 - accuracy: 0.9466 - val_loss: 0.6195 - val_accuracy: 0.8477\n",
            "Epoch 81/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1457 - accuracy: 0.9491 - val_loss: 0.6258 - val_accuracy: 0.8470\n",
            "Epoch 82/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1475 - accuracy: 0.9483 - val_loss: 0.6469 - val_accuracy: 0.8417\n",
            "Epoch 83/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1438 - accuracy: 0.9492 - val_loss: 0.6560 - val_accuracy: 0.8465\n",
            "Epoch 84/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1426 - accuracy: 0.9498 - val_loss: 0.6599 - val_accuracy: 0.8433\n",
            "Epoch 85/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1412 - accuracy: 0.9504 - val_loss: 0.6598 - val_accuracy: 0.8442\n",
            "Epoch 86/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1410 - accuracy: 0.9508 - val_loss: 0.6697 - val_accuracy: 0.8425\n",
            "Epoch 87/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1331 - accuracy: 0.9537 - val_loss: 0.6737 - val_accuracy: 0.8397\n",
            "Epoch 88/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1295 - accuracy: 0.9545 - val_loss: 0.6982 - val_accuracy: 0.8407\n",
            "Epoch 89/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1306 - accuracy: 0.9539 - val_loss: 0.7022 - val_accuracy: 0.8443\n",
            "Epoch 90/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1268 - accuracy: 0.9560 - val_loss: 0.7001 - val_accuracy: 0.8438\n",
            "Epoch 91/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1249 - accuracy: 0.9567 - val_loss: 0.7211 - val_accuracy: 0.8407\n",
            "Epoch 92/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1222 - accuracy: 0.9571 - val_loss: 0.7290 - val_accuracy: 0.8450\n",
            "Epoch 93/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1203 - accuracy: 0.9581 - val_loss: 0.7493 - val_accuracy: 0.8473\n",
            "Epoch 94/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1198 - accuracy: 0.9581 - val_loss: 0.7585 - val_accuracy: 0.8448\n",
            "Epoch 95/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1160 - accuracy: 0.9599 - val_loss: 0.7539 - val_accuracy: 0.8420\n",
            "Epoch 96/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1168 - accuracy: 0.9589 - val_loss: 0.7655 - val_accuracy: 0.8438\n",
            "Epoch 97/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1149 - accuracy: 0.9599 - val_loss: 0.7601 - val_accuracy: 0.8363\n",
            "Epoch 98/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1090 - accuracy: 0.9624 - val_loss: 0.7913 - val_accuracy: 0.8433\n",
            "Epoch 99/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1133 - accuracy: 0.9603 - val_loss: 0.7885 - val_accuracy: 0.8430\n",
            "Epoch 100/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1051 - accuracy: 0.9631 - val_loss: 0.8046 - val_accuracy: 0.8417\n",
            "Epoch 101/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1014 - accuracy: 0.9649 - val_loss: 0.7973 - val_accuracy: 0.8418\n",
            "Epoch 102/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1054 - accuracy: 0.9638 - val_loss: 0.8346 - val_accuracy: 0.8410\n",
            "Epoch 103/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.1043 - accuracy: 0.9638 - val_loss: 0.8428 - val_accuracy: 0.8393\n",
            "Epoch 104/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0987 - accuracy: 0.9657 - val_loss: 0.8445 - val_accuracy: 0.8397\n",
            "Epoch 105/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.1019 - accuracy: 0.9645 - val_loss: 0.8483 - val_accuracy: 0.8397\n",
            "Epoch 106/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0994 - accuracy: 0.9656 - val_loss: 0.8541 - val_accuracy: 0.8410\n",
            "Epoch 107/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0957 - accuracy: 0.9672 - val_loss: 0.8742 - val_accuracy: 0.8438\n",
            "Epoch 108/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0963 - accuracy: 0.9671 - val_loss: 0.8827 - val_accuracy: 0.8402\n",
            "Epoch 109/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 0.8806 - val_accuracy: 0.8413\n",
            "Epoch 110/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0892 - accuracy: 0.9695 - val_loss: 0.8929 - val_accuracy: 0.8383\n",
            "Epoch 111/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0876 - accuracy: 0.9694 - val_loss: 0.9074 - val_accuracy: 0.8400\n",
            "Epoch 112/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0889 - accuracy: 0.9688 - val_loss: 0.9015 - val_accuracy: 0.8407\n",
            "Epoch 113/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0879 - accuracy: 0.9700 - val_loss: 0.9292 - val_accuracy: 0.8355\n",
            "Epoch 114/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0885 - accuracy: 0.9698 - val_loss: 0.9378 - val_accuracy: 0.8398\n",
            "Epoch 115/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0828 - accuracy: 0.9712 - val_loss: 0.9494 - val_accuracy: 0.8340\n",
            "Epoch 116/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0872 - accuracy: 0.9694 - val_loss: 0.9479 - val_accuracy: 0.8395\n",
            "Epoch 117/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0761 - accuracy: 0.9744 - val_loss: 0.9800 - val_accuracy: 0.8413\n",
            "Epoch 118/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0846 - accuracy: 0.9711 - val_loss: 0.9769 - val_accuracy: 0.8407\n",
            "Epoch 119/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0793 - accuracy: 0.9724 - val_loss: 0.9621 - val_accuracy: 0.8420\n",
            "Epoch 120/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0744 - accuracy: 0.9746 - val_loss: 0.9617 - val_accuracy: 0.8345\n",
            "Epoch 121/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0760 - accuracy: 0.9741 - val_loss: 0.9915 - val_accuracy: 0.8407\n",
            "Epoch 122/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0725 - accuracy: 0.9754 - val_loss: 1.0154 - val_accuracy: 0.8383\n",
            "Epoch 123/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0784 - accuracy: 0.9736 - val_loss: 1.0083 - val_accuracy: 0.8362\n",
            "Epoch 124/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0716 - accuracy: 0.9759 - val_loss: 1.0307 - val_accuracy: 0.8365\n",
            "Epoch 125/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0697 - accuracy: 0.9768 - val_loss: 1.0547 - val_accuracy: 0.8373\n",
            "Epoch 126/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0681 - accuracy: 0.9768 - val_loss: 1.0452 - val_accuracy: 0.8373\n",
            "Epoch 127/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0679 - accuracy: 0.9771 - val_loss: 1.0538 - val_accuracy: 0.8377\n",
            "Epoch 128/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0690 - accuracy: 0.9764 - val_loss: 1.0567 - val_accuracy: 0.8367\n",
            "Epoch 129/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0752 - accuracy: 0.9749 - val_loss: 1.0517 - val_accuracy: 0.8352\n",
            "Epoch 130/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0679 - accuracy: 0.9771 - val_loss: 1.0662 - val_accuracy: 0.8400\n",
            "Epoch 131/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0582 - accuracy: 0.9805 - val_loss: 1.0972 - val_accuracy: 0.8373\n",
            "Epoch 132/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0637 - accuracy: 0.9788 - val_loss: 1.1011 - val_accuracy: 0.8365\n",
            "Epoch 133/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0589 - accuracy: 0.9800 - val_loss: 1.1256 - val_accuracy: 0.8412\n",
            "Epoch 134/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0657 - accuracy: 0.9784 - val_loss: 1.1000 - val_accuracy: 0.8362\n",
            "Epoch 135/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0583 - accuracy: 0.9811 - val_loss: 1.1341 - val_accuracy: 0.8400\n",
            "Epoch 136/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0564 - accuracy: 0.9809 - val_loss: 1.1461 - val_accuracy: 0.8357\n",
            "Epoch 137/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0626 - accuracy: 0.9790 - val_loss: 1.1340 - val_accuracy: 0.8377\n",
            "Epoch 138/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0582 - accuracy: 0.9807 - val_loss: 1.1326 - val_accuracy: 0.8383\n",
            "Epoch 139/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0535 - accuracy: 0.9820 - val_loss: 1.1561 - val_accuracy: 0.8360\n",
            "Epoch 140/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 1.1745 - val_accuracy: 0.8375\n",
            "Epoch 141/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0503 - accuracy: 0.9831 - val_loss: 1.1792 - val_accuracy: 0.8365\n",
            "Epoch 142/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0535 - accuracy: 0.9823 - val_loss: 1.1841 - val_accuracy: 0.8420\n",
            "Epoch 143/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0628 - accuracy: 0.9793 - val_loss: 1.1506 - val_accuracy: 0.8425\n",
            "Epoch 144/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0521 - accuracy: 0.9827 - val_loss: 1.2037 - val_accuracy: 0.8368\n",
            "Epoch 145/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0472 - accuracy: 0.9843 - val_loss: 1.2141 - val_accuracy: 0.8415\n",
            "Epoch 146/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0509 - accuracy: 0.9827 - val_loss: 1.2032 - val_accuracy: 0.8405\n",
            "Epoch 147/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0515 - accuracy: 0.9830 - val_loss: 1.2047 - val_accuracy: 0.8402\n",
            "Epoch 148/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0482 - accuracy: 0.9841 - val_loss: 1.2206 - val_accuracy: 0.8422\n",
            "Epoch 149/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0467 - accuracy: 0.9849 - val_loss: 1.2483 - val_accuracy: 0.8390\n",
            "Epoch 150/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0546 - accuracy: 0.9829 - val_loss: 1.2537 - val_accuracy: 0.8367\n",
            "Epoch 151/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0436 - accuracy: 0.9856 - val_loss: 1.2617 - val_accuracy: 0.8392\n",
            "Epoch 152/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0450 - accuracy: 0.9852 - val_loss: 1.2517 - val_accuracy: 0.8393\n",
            "Epoch 153/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0508 - accuracy: 0.9833 - val_loss: 1.2542 - val_accuracy: 0.8398\n",
            "Epoch 154/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0412 - accuracy: 0.9868 - val_loss: 1.3192 - val_accuracy: 0.8340\n",
            "Epoch 155/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0505 - accuracy: 0.9831 - val_loss: 1.2700 - val_accuracy: 0.8437\n",
            "Epoch 156/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0432 - accuracy: 0.9862 - val_loss: 1.2876 - val_accuracy: 0.8405\n",
            "Epoch 157/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 1.2991 - val_accuracy: 0.8430\n",
            "Epoch 158/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0467 - accuracy: 0.9846 - val_loss: 1.2927 - val_accuracy: 0.8398\n",
            "Epoch 159/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0413 - accuracy: 0.9867 - val_loss: 1.2957 - val_accuracy: 0.8383\n",
            "Epoch 160/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 1.3283 - val_accuracy: 0.8385\n",
            "Epoch 161/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0451 - accuracy: 0.9851 - val_loss: 1.3457 - val_accuracy: 0.8368\n",
            "Epoch 162/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 1.3019 - val_accuracy: 0.8362\n",
            "Epoch 163/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 1.3379 - val_accuracy: 0.8425\n",
            "Epoch 164/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0381 - accuracy: 0.9873 - val_loss: 1.3323 - val_accuracy: 0.8385\n",
            "Epoch 165/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0383 - accuracy: 0.9876 - val_loss: 1.3201 - val_accuracy: 0.8375\n",
            "Epoch 166/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 1.3575 - val_accuracy: 0.8375\n",
            "Epoch 167/250\n",
            "1782/1782 [==============================] - 46s 26ms/step - loss: 0.0437 - accuracy: 0.9859 - val_loss: 1.3511 - val_accuracy: 0.8353\n",
            "Epoch 168/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0338 - accuracy: 0.9894 - val_loss: 1.3507 - val_accuracy: 0.8420\n",
            "Epoch 169/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0432 - accuracy: 0.9859 - val_loss: 1.3825 - val_accuracy: 0.8372\n",
            "Epoch 170/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 1.4109 - val_accuracy: 0.8350\n",
            "Epoch 171/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 1.4150 - val_accuracy: 0.8370\n",
            "Epoch 172/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0408 - accuracy: 0.9869 - val_loss: 1.3745 - val_accuracy: 0.8390\n",
            "Epoch 173/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 1.3825 - val_accuracy: 0.8400\n",
            "Epoch 174/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0384 - accuracy: 0.9872 - val_loss: 1.3625 - val_accuracy: 0.8408\n",
            "Epoch 175/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0306 - accuracy: 0.9901 - val_loss: 1.4404 - val_accuracy: 0.8418\n",
            "Epoch 176/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0359 - accuracy: 0.9881 - val_loss: 1.4238 - val_accuracy: 0.8408\n",
            "Epoch 177/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0335 - accuracy: 0.9894 - val_loss: 1.4404 - val_accuracy: 0.8377\n",
            "Epoch 178/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 1.4087 - val_accuracy: 0.8400\n",
            "Epoch 179/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0321 - accuracy: 0.9900 - val_loss: 1.4574 - val_accuracy: 0.8380\n",
            "Epoch 180/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0330 - accuracy: 0.9892 - val_loss: 1.4329 - val_accuracy: 0.8412\n",
            "Epoch 181/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 1.4557 - val_accuracy: 0.8360\n",
            "Epoch 182/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 1.4937 - val_accuracy: 0.8407\n",
            "Epoch 183/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 1.4739 - val_accuracy: 0.8357\n",
            "Epoch 184/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0328 - accuracy: 0.9897 - val_loss: 1.5045 - val_accuracy: 0.8398\n",
            "Epoch 185/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 1.5155 - val_accuracy: 0.8352\n",
            "Epoch 186/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 1.4649 - val_accuracy: 0.8363\n",
            "Epoch 187/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 1.4828 - val_accuracy: 0.8362\n",
            "Epoch 188/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0311 - accuracy: 0.9901 - val_loss: 1.4786 - val_accuracy: 0.8357\n",
            "Epoch 189/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0272 - accuracy: 0.9916 - val_loss: 1.5038 - val_accuracy: 0.8410\n",
            "Epoch 190/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 1.4728 - val_accuracy: 0.8417\n",
            "Epoch 191/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 1.4898 - val_accuracy: 0.8382\n",
            "Epoch 192/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0308 - accuracy: 0.9902 - val_loss: 1.5385 - val_accuracy: 0.8408\n",
            "Epoch 193/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 1.5344 - val_accuracy: 0.8387\n",
            "Epoch 194/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0383 - accuracy: 0.9882 - val_loss: 1.4962 - val_accuracy: 0.8365\n",
            "Epoch 195/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 1.5265 - val_accuracy: 0.8397\n",
            "Epoch 196/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 1.5099 - val_accuracy: 0.8412\n",
            "Epoch 197/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 1.5317 - val_accuracy: 0.8375\n",
            "Epoch 198/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 1.5145 - val_accuracy: 0.8352\n",
            "Epoch 199/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 1.4941 - val_accuracy: 0.8418\n",
            "Epoch 200/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 1.5061 - val_accuracy: 0.8437\n",
            "Epoch 201/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 1.5040 - val_accuracy: 0.8387\n",
            "Epoch 202/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0264 - accuracy: 0.9917 - val_loss: 1.5274 - val_accuracy: 0.8382\n",
            "Epoch 203/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 1.5775 - val_accuracy: 0.8407\n",
            "Epoch 204/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 1.5855 - val_accuracy: 0.8380\n",
            "Epoch 205/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 1.5681 - val_accuracy: 0.8373\n",
            "Epoch 206/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0273 - accuracy: 0.9917 - val_loss: 1.5262 - val_accuracy: 0.8403\n",
            "Epoch 207/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0228 - accuracy: 0.9928 - val_loss: 1.5598 - val_accuracy: 0.8370\n",
            "Epoch 208/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0252 - accuracy: 0.9921 - val_loss: 1.5622 - val_accuracy: 0.8310\n",
            "Epoch 209/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 1.5854 - val_accuracy: 0.8363\n",
            "Epoch 210/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 1.5799 - val_accuracy: 0.8367\n",
            "Epoch 211/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 1.5441 - val_accuracy: 0.8375\n",
            "Epoch 212/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 1.5843 - val_accuracy: 0.8402\n",
            "Epoch 213/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 1.5817 - val_accuracy: 0.8338\n",
            "Epoch 214/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 1.5915 - val_accuracy: 0.8332\n",
            "Epoch 215/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 1.5978 - val_accuracy: 0.8355\n",
            "Epoch 216/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0269 - accuracy: 0.9915 - val_loss: 1.5886 - val_accuracy: 0.8400\n",
            "Epoch 217/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 1.5687 - val_accuracy: 0.8402\n",
            "Epoch 218/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 1.5740 - val_accuracy: 0.8352\n",
            "Epoch 219/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 1.5919 - val_accuracy: 0.8365\n",
            "Epoch 220/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 1.6169 - val_accuracy: 0.8347\n",
            "Epoch 221/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 1.6136 - val_accuracy: 0.8372\n",
            "Epoch 222/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 1.6463 - val_accuracy: 0.8350\n",
            "Epoch 223/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 1.6054 - val_accuracy: 0.8392\n",
            "Epoch 224/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 1.6106 - val_accuracy: 0.8343\n",
            "Epoch 225/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 1.6017 - val_accuracy: 0.8407\n",
            "Epoch 226/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 1.5820 - val_accuracy: 0.8380\n",
            "Epoch 227/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 1.6098 - val_accuracy: 0.8395\n",
            "Epoch 228/250\n",
            "1782/1782 [==============================] - 51s 29ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 1.6415 - val_accuracy: 0.8345\n",
            "Epoch 229/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 1.6235 - val_accuracy: 0.8392\n",
            "Epoch 230/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 1.5566 - val_accuracy: 0.8383\n",
            "Epoch 231/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 1.6717 - val_accuracy: 0.8417\n",
            "Epoch 232/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 1.6665 - val_accuracy: 0.8365\n",
            "Epoch 233/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 1.6286 - val_accuracy: 0.8397\n",
            "Epoch 234/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 1.5924 - val_accuracy: 0.8378\n",
            "Epoch 235/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 1.6078 - val_accuracy: 0.8355\n",
            "Epoch 236/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 1.6241 - val_accuracy: 0.8390\n",
            "Epoch 237/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 1.6442 - val_accuracy: 0.8385\n",
            "Epoch 238/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 1.6221 - val_accuracy: 0.8353\n",
            "Epoch 239/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 1.6177 - val_accuracy: 0.8358\n",
            "Epoch 240/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 1.6273 - val_accuracy: 0.8412\n",
            "Epoch 241/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0210 - accuracy: 0.9936 - val_loss: 1.6404 - val_accuracy: 0.8415\n",
            "Epoch 242/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 1.6425 - val_accuracy: 0.8463\n",
            "Epoch 243/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 1.6647 - val_accuracy: 0.8413\n",
            "Epoch 244/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 1.6131 - val_accuracy: 0.8453\n",
            "Epoch 245/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 1.6286 - val_accuracy: 0.8388\n",
            "Epoch 246/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 1.6302 - val_accuracy: 0.8405\n",
            "Epoch 247/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 1.6343 - val_accuracy: 0.8402\n",
            "Epoch 248/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 1.6355 - val_accuracy: 0.8358\n",
            "Epoch 249/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 1.6686 - val_accuracy: 0.8403\n",
            "Epoch 250/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 1.6436 - val_accuracy: 0.8423\n",
            "CPU times: user 6h 47min 24s, sys: 1h 58min 33s, total: 8h 45min 58s\n",
            "Wall time: 3h 20min 43s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "10LSIKCk9Z_Y",
        "outputId": "c2f02720-7519-4ce9-f727-0d35d2be1578"
      },
      "source": [
        "%%time\n",
        "encoder_3000 = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=2000)\n",
        "encoder_3000.adapt(dataset_all.map(lambda text, label: text))\n",
        "vocab_3000 = np.array(encoder_3000.get_vocabulary());"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fbfc808f560> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fbfc808f560>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fbfc808f560> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fbfc808f560>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function <lambda> at 0x7fbfc808f560> and will run it as-is.\n",
            "Cause: could not parse the source code of <function <lambda> at 0x7fbfc808f560>: no matching AST found\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "CPU times: user 6min 20s, sys: 1min 59s, total: 8min 20s\n",
            "Wall time: 3min 5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "okWC7wxG9byn",
        "outputId": "11c6686e-7c4f-4bcf-e55b-3b7420bfc7ef"
      },
      "source": [
        "%%time\n",
        "doc3000_sizes = []\n",
        "corpus3000 = []\n",
        "count3000=0\n",
        "useless = 0\n",
        "percents = []\n",
        "for example, _ in dataset_all.as_numpy_iterator():\n",
        "  enc_example = encoder_3000(example)\n",
        "  num_ones = tf.math.count_nonzero(enc_example==1).numpy()\n",
        "  percent_ones = round(num_ones*100/len(enc_example))\n",
        "  percents.append(percent_ones)\n",
        "\n",
        "  s = set(list(enc_example.numpy()))\n",
        "  if s == {1}: useless+=1\n",
        "\n",
        "  doc3000_sizes.append(len(enc_example))\n",
        "  corpus3000+=list(enc_example.numpy())\n",
        "\n",
        "  count3000 += tf.math.count_nonzero(enc_example>1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 17min 53s, sys: 2min 25s, total: 20min 18s\n",
            "Wall time: 16min 40s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rIpsaZ9I9eFr"
      },
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "encoder\n",
        ",tf.keras.layers.Embedding(input_dim=len(encoder_3000.get_vocabulary())\n",
        ",output_dim=64\n",
        ",mask_zero=True)\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))\n",
        ",tf.keras.layers.Dense(64, activation='relu')\n",
        ",tf.keras.layers.Dense(4,activation='softmax')])\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(1e-4),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M90t5B9B9hNm",
        "outputId": "bd4a76a5-3e7f-4b5c-990d-0088d428ab91"
      },
      "source": [
        "%%time\n",
        "history3 = model3.fit(train_dataset ,epochs = 250 ,validation_data=validation_dataset ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1782/1782 [==============================] - 39s 17ms/step - loss: 0.7385 - accuracy: 0.7083 - val_loss: 0.4853 - val_accuracy: 0.8332\n",
            "Epoch 2/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.4495 - accuracy: 0.8407 - val_loss: 0.4281 - val_accuracy: 0.8485\n",
            "Epoch 3/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.4128 - accuracy: 0.8514 - val_loss: 0.4054 - val_accuracy: 0.8577\n",
            "Epoch 4/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3972 - accuracy: 0.8562 - val_loss: 0.3947 - val_accuracy: 0.8588\n",
            "Epoch 5/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3889 - accuracy: 0.8589 - val_loss: 0.3904 - val_accuracy: 0.8597\n",
            "Epoch 6/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3832 - accuracy: 0.8601 - val_loss: 0.3900 - val_accuracy: 0.8602\n",
            "Epoch 7/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3791 - accuracy: 0.8622 - val_loss: 0.3893 - val_accuracy: 0.8613\n",
            "Epoch 8/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3768 - accuracy: 0.8624 - val_loss: 0.3859 - val_accuracy: 0.8637\n",
            "Epoch 9/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3732 - accuracy: 0.8630 - val_loss: 0.3787 - val_accuracy: 0.8628\n",
            "Epoch 10/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3697 - accuracy: 0.8643 - val_loss: 0.3775 - val_accuracy: 0.8672\n",
            "Epoch 11/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3671 - accuracy: 0.8650 - val_loss: 0.3767 - val_accuracy: 0.8653\n",
            "Epoch 12/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3641 - accuracy: 0.8662 - val_loss: 0.3748 - val_accuracy: 0.8667\n",
            "Epoch 13/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3612 - accuracy: 0.8676 - val_loss: 0.3750 - val_accuracy: 0.8658\n",
            "Epoch 14/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3586 - accuracy: 0.8684 - val_loss: 0.3741 - val_accuracy: 0.8677\n",
            "Epoch 15/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3561 - accuracy: 0.8690 - val_loss: 0.3703 - val_accuracy: 0.8680\n",
            "Epoch 16/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3532 - accuracy: 0.8697 - val_loss: 0.3727 - val_accuracy: 0.8668\n",
            "Epoch 17/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3504 - accuracy: 0.8710 - val_loss: 0.3741 - val_accuracy: 0.8673\n",
            "Epoch 18/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.3478 - accuracy: 0.8718 - val_loss: 0.3716 - val_accuracy: 0.8680\n",
            "Epoch 19/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.3449 - accuracy: 0.8733 - val_loss: 0.3678 - val_accuracy: 0.8687\n",
            "Epoch 20/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.3424 - accuracy: 0.8742 - val_loss: 0.3736 - val_accuracy: 0.8670\n",
            "Epoch 21/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.3402 - accuracy: 0.8741 - val_loss: 0.3706 - val_accuracy: 0.8690\n",
            "Epoch 22/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3372 - accuracy: 0.8758 - val_loss: 0.3725 - val_accuracy: 0.8672\n",
            "Epoch 23/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.3346 - accuracy: 0.8771 - val_loss: 0.3694 - val_accuracy: 0.8698\n",
            "Epoch 24/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3313 - accuracy: 0.8781 - val_loss: 0.3671 - val_accuracy: 0.8697\n",
            "Epoch 25/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3290 - accuracy: 0.8787 - val_loss: 0.3743 - val_accuracy: 0.8668\n",
            "Epoch 26/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3261 - accuracy: 0.8802 - val_loss: 0.3683 - val_accuracy: 0.8695\n",
            "Epoch 27/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3236 - accuracy: 0.8803 - val_loss: 0.3656 - val_accuracy: 0.8675\n",
            "Epoch 28/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3212 - accuracy: 0.8814 - val_loss: 0.3638 - val_accuracy: 0.8692\n",
            "Epoch 29/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3191 - accuracy: 0.8828 - val_loss: 0.3666 - val_accuracy: 0.8682\n",
            "Epoch 30/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3157 - accuracy: 0.8839 - val_loss: 0.3707 - val_accuracy: 0.8648\n",
            "Epoch 31/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3130 - accuracy: 0.8844 - val_loss: 0.3657 - val_accuracy: 0.8702\n",
            "Epoch 32/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3110 - accuracy: 0.8852 - val_loss: 0.3698 - val_accuracy: 0.8677\n",
            "Epoch 33/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.3074 - accuracy: 0.8869 - val_loss: 0.3662 - val_accuracy: 0.8668\n",
            "Epoch 34/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3054 - accuracy: 0.8875 - val_loss: 0.3710 - val_accuracy: 0.8682\n",
            "Epoch 35/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3034 - accuracy: 0.8887 - val_loss: 0.3688 - val_accuracy: 0.8667\n",
            "Epoch 36/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.3005 - accuracy: 0.8891 - val_loss: 0.3745 - val_accuracy: 0.8680\n",
            "Epoch 37/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2984 - accuracy: 0.8899 - val_loss: 0.3728 - val_accuracy: 0.8675\n",
            "Epoch 38/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2955 - accuracy: 0.8915 - val_loss: 0.3809 - val_accuracy: 0.8642\n",
            "Epoch 39/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.2938 - accuracy: 0.8919 - val_loss: 0.3716 - val_accuracy: 0.8677\n",
            "Epoch 40/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2912 - accuracy: 0.8933 - val_loss: 0.3803 - val_accuracy: 0.8640\n",
            "Epoch 41/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2886 - accuracy: 0.8942 - val_loss: 0.3727 - val_accuracy: 0.8657\n",
            "Epoch 42/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2865 - accuracy: 0.8946 - val_loss: 0.3787 - val_accuracy: 0.8645\n",
            "Epoch 43/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2851 - accuracy: 0.8951 - val_loss: 0.3809 - val_accuracy: 0.8652\n",
            "Epoch 44/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2826 - accuracy: 0.8957 - val_loss: 0.3889 - val_accuracy: 0.8637\n",
            "Epoch 45/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2800 - accuracy: 0.8972 - val_loss: 0.3781 - val_accuracy: 0.8675\n",
            "Epoch 46/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2781 - accuracy: 0.8974 - val_loss: 0.3853 - val_accuracy: 0.8645\n",
            "Epoch 47/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2763 - accuracy: 0.8984 - val_loss: 0.3880 - val_accuracy: 0.8650\n",
            "Epoch 48/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2739 - accuracy: 0.8994 - val_loss: 0.3894 - val_accuracy: 0.8647\n",
            "Epoch 49/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2719 - accuracy: 0.8995 - val_loss: 0.3855 - val_accuracy: 0.8638\n",
            "Epoch 50/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2697 - accuracy: 0.9005 - val_loss: 0.3929 - val_accuracy: 0.8617\n",
            "Epoch 51/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2680 - accuracy: 0.9009 - val_loss: 0.3897 - val_accuracy: 0.8627\n",
            "Epoch 52/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2657 - accuracy: 0.9021 - val_loss: 0.3953 - val_accuracy: 0.8628\n",
            "Epoch 53/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2642 - accuracy: 0.9030 - val_loss: 0.3915 - val_accuracy: 0.8637\n",
            "Epoch 54/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2621 - accuracy: 0.9033 - val_loss: 0.4015 - val_accuracy: 0.8592\n",
            "Epoch 55/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2603 - accuracy: 0.9038 - val_loss: 0.3978 - val_accuracy: 0.8618\n",
            "Epoch 56/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2579 - accuracy: 0.9050 - val_loss: 0.4164 - val_accuracy: 0.8578\n",
            "Epoch 57/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2569 - accuracy: 0.9053 - val_loss: 0.3995 - val_accuracy: 0.8612\n",
            "Epoch 58/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2540 - accuracy: 0.9063 - val_loss: 0.4132 - val_accuracy: 0.8545\n",
            "Epoch 59/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2520 - accuracy: 0.9069 - val_loss: 0.4084 - val_accuracy: 0.8580\n",
            "Epoch 60/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2505 - accuracy: 0.9078 - val_loss: 0.4180 - val_accuracy: 0.8557\n",
            "Epoch 61/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2480 - accuracy: 0.9085 - val_loss: 0.4185 - val_accuracy: 0.8598\n",
            "Epoch 62/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2466 - accuracy: 0.9094 - val_loss: 0.4131 - val_accuracy: 0.8605\n",
            "Epoch 63/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2445 - accuracy: 0.9104 - val_loss: 0.4113 - val_accuracy: 0.8598\n",
            "Epoch 64/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2423 - accuracy: 0.9113 - val_loss: 0.4157 - val_accuracy: 0.8580\n",
            "Epoch 65/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2404 - accuracy: 0.9116 - val_loss: 0.4166 - val_accuracy: 0.8583\n",
            "Epoch 66/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2387 - accuracy: 0.9130 - val_loss: 0.4233 - val_accuracy: 0.8607\n",
            "Epoch 67/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.2372 - accuracy: 0.9131 - val_loss: 0.4284 - val_accuracy: 0.8572\n",
            "Epoch 68/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.2341 - accuracy: 0.9142 - val_loss: 0.4311 - val_accuracy: 0.8575\n",
            "Epoch 69/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2323 - accuracy: 0.9155 - val_loss: 0.4380 - val_accuracy: 0.8602\n",
            "Epoch 70/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2298 - accuracy: 0.9161 - val_loss: 0.4384 - val_accuracy: 0.8557\n",
            "Epoch 71/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2289 - accuracy: 0.9161 - val_loss: 0.4390 - val_accuracy: 0.8568\n",
            "Epoch 72/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.2264 - accuracy: 0.9175 - val_loss: 0.4450 - val_accuracy: 0.8550\n",
            "Epoch 73/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2239 - accuracy: 0.9184 - val_loss: 0.4525 - val_accuracy: 0.8557\n",
            "Epoch 74/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2227 - accuracy: 0.9191 - val_loss: 0.4482 - val_accuracy: 0.8550\n",
            "Epoch 75/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2201 - accuracy: 0.9201 - val_loss: 0.4647 - val_accuracy: 0.8565\n",
            "Epoch 76/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2174 - accuracy: 0.9209 - val_loss: 0.4613 - val_accuracy: 0.8525\n",
            "Epoch 77/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2158 - accuracy: 0.9215 - val_loss: 0.4715 - val_accuracy: 0.8578\n",
            "Epoch 78/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2137 - accuracy: 0.9227 - val_loss: 0.4643 - val_accuracy: 0.8542\n",
            "Epoch 79/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2112 - accuracy: 0.9237 - val_loss: 0.4628 - val_accuracy: 0.8532\n",
            "Epoch 80/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2100 - accuracy: 0.9231 - val_loss: 0.4832 - val_accuracy: 0.8513\n",
            "Epoch 81/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2067 - accuracy: 0.9249 - val_loss: 0.4836 - val_accuracy: 0.8553\n",
            "Epoch 82/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2055 - accuracy: 0.9255 - val_loss: 0.4923 - val_accuracy: 0.8495\n",
            "Epoch 83/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2021 - accuracy: 0.9275 - val_loss: 0.4983 - val_accuracy: 0.8528\n",
            "Epoch 84/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.2007 - accuracy: 0.9274 - val_loss: 0.4891 - val_accuracy: 0.8512\n",
            "Epoch 85/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1985 - accuracy: 0.9280 - val_loss: 0.5039 - val_accuracy: 0.8502\n",
            "Epoch 86/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1961 - accuracy: 0.9292 - val_loss: 0.5048 - val_accuracy: 0.8480\n",
            "Epoch 87/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1939 - accuracy: 0.9300 - val_loss: 0.5106 - val_accuracy: 0.8507\n",
            "Epoch 88/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1920 - accuracy: 0.9311 - val_loss: 0.5217 - val_accuracy: 0.8468\n",
            "Epoch 89/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1901 - accuracy: 0.9319 - val_loss: 0.5320 - val_accuracy: 0.8483\n",
            "Epoch 90/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1887 - accuracy: 0.9325 - val_loss: 0.5307 - val_accuracy: 0.8502\n",
            "Epoch 91/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1860 - accuracy: 0.9330 - val_loss: 0.5291 - val_accuracy: 0.8492\n",
            "Epoch 92/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1838 - accuracy: 0.9340 - val_loss: 0.5456 - val_accuracy: 0.8482\n",
            "Epoch 93/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1844 - accuracy: 0.9337 - val_loss: 0.5545 - val_accuracy: 0.8493\n",
            "Epoch 94/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1791 - accuracy: 0.9358 - val_loss: 0.5597 - val_accuracy: 0.8495\n",
            "Epoch 95/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1791 - accuracy: 0.9353 - val_loss: 0.5539 - val_accuracy: 0.8472\n",
            "Epoch 96/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1759 - accuracy: 0.9373 - val_loss: 0.5741 - val_accuracy: 0.8472\n",
            "Epoch 97/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1732 - accuracy: 0.9382 - val_loss: 0.5938 - val_accuracy: 0.8435\n",
            "Epoch 98/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1706 - accuracy: 0.9392 - val_loss: 0.5790 - val_accuracy: 0.8467\n",
            "Epoch 99/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1691 - accuracy: 0.9397 - val_loss: 0.5794 - val_accuracy: 0.8463\n",
            "Epoch 100/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1666 - accuracy: 0.9410 - val_loss: 0.5957 - val_accuracy: 0.8448\n",
            "Epoch 101/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1678 - accuracy: 0.9404 - val_loss: 0.5993 - val_accuracy: 0.8427\n",
            "Epoch 102/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1632 - accuracy: 0.9423 - val_loss: 0.6200 - val_accuracy: 0.8415\n",
            "Epoch 103/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1614 - accuracy: 0.9426 - val_loss: 0.6208 - val_accuracy: 0.8417\n",
            "Epoch 104/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1596 - accuracy: 0.9435 - val_loss: 0.6227 - val_accuracy: 0.8443\n",
            "Epoch 105/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1573 - accuracy: 0.9445 - val_loss: 0.6435 - val_accuracy: 0.8412\n",
            "Epoch 106/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.1554 - accuracy: 0.9453 - val_loss: 0.6481 - val_accuracy: 0.8432\n",
            "Epoch 107/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1531 - accuracy: 0.9458 - val_loss: 0.6416 - val_accuracy: 0.8400\n",
            "Epoch 108/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1522 - accuracy: 0.9467 - val_loss: 0.6551 - val_accuracy: 0.8405\n",
            "Epoch 109/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1510 - accuracy: 0.9472 - val_loss: 0.6500 - val_accuracy: 0.8398\n",
            "Epoch 110/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1561 - accuracy: 0.9453 - val_loss: 0.6324 - val_accuracy: 0.8413\n",
            "Epoch 111/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1505 - accuracy: 0.9470 - val_loss: 0.6714 - val_accuracy: 0.8383\n",
            "Epoch 112/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1424 - accuracy: 0.9506 - val_loss: 0.6970 - val_accuracy: 0.8388\n",
            "Epoch 113/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1414 - accuracy: 0.9507 - val_loss: 0.6886 - val_accuracy: 0.8435\n",
            "Epoch 114/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.1389 - accuracy: 0.9514 - val_loss: 0.7037 - val_accuracy: 0.8430\n",
            "Epoch 115/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1397 - accuracy: 0.9514 - val_loss: 0.6993 - val_accuracy: 0.8398\n",
            "Epoch 116/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1352 - accuracy: 0.9531 - val_loss: 0.7253 - val_accuracy: 0.8377\n",
            "Epoch 117/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1346 - accuracy: 0.9535 - val_loss: 0.7427 - val_accuracy: 0.8400\n",
            "Epoch 118/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1316 - accuracy: 0.9544 - val_loss: 0.7464 - val_accuracy: 0.8390\n",
            "Epoch 119/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1308 - accuracy: 0.9540 - val_loss: 0.7374 - val_accuracy: 0.8400\n",
            "Epoch 120/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1304 - accuracy: 0.9549 - val_loss: 0.7178 - val_accuracy: 0.8330\n",
            "Epoch 121/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1355 - accuracy: 0.9525 - val_loss: 0.7486 - val_accuracy: 0.8383\n",
            "Epoch 122/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1235 - accuracy: 0.9574 - val_loss: 0.7840 - val_accuracy: 0.8380\n",
            "Epoch 123/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1242 - accuracy: 0.9573 - val_loss: 0.7828 - val_accuracy: 0.8343\n",
            "Epoch 124/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1226 - accuracy: 0.9579 - val_loss: 0.7929 - val_accuracy: 0.8358\n",
            "Epoch 125/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1190 - accuracy: 0.9590 - val_loss: 0.8315 - val_accuracy: 0.8370\n",
            "Epoch 126/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1183 - accuracy: 0.9594 - val_loss: 0.8117 - val_accuracy: 0.8323\n",
            "Epoch 127/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1168 - accuracy: 0.9597 - val_loss: 0.8256 - val_accuracy: 0.8357\n",
            "Epoch 128/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1135 - accuracy: 0.9611 - val_loss: 0.8380 - val_accuracy: 0.8335\n",
            "Epoch 129/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1135 - accuracy: 0.9608 - val_loss: 0.8331 - val_accuracy: 0.8320\n",
            "Epoch 130/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1106 - accuracy: 0.9621 - val_loss: 0.8672 - val_accuracy: 0.8375\n",
            "Epoch 131/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1086 - accuracy: 0.9630 - val_loss: 0.8898 - val_accuracy: 0.8345\n",
            "Epoch 132/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1066 - accuracy: 0.9637 - val_loss: 0.8740 - val_accuracy: 0.8322\n",
            "Epoch 133/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.1061 - accuracy: 0.9640 - val_loss: 0.9053 - val_accuracy: 0.8312\n",
            "Epoch 134/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1052 - accuracy: 0.9641 - val_loss: 0.9204 - val_accuracy: 0.8307\n",
            "Epoch 135/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1019 - accuracy: 0.9650 - val_loss: 0.9203 - val_accuracy: 0.8312\n",
            "Epoch 136/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.1025 - accuracy: 0.9652 - val_loss: 0.9142 - val_accuracy: 0.8312\n",
            "Epoch 137/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0995 - accuracy: 0.9664 - val_loss: 0.9279 - val_accuracy: 0.8357\n",
            "Epoch 138/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0988 - accuracy: 0.9665 - val_loss: 0.9465 - val_accuracy: 0.8283\n",
            "Epoch 139/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0962 - accuracy: 0.9675 - val_loss: 0.9734 - val_accuracy: 0.8317\n",
            "Epoch 140/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0976 - accuracy: 0.9670 - val_loss: 0.9865 - val_accuracy: 0.8313\n",
            "Epoch 141/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0916 - accuracy: 0.9691 - val_loss: 0.9821 - val_accuracy: 0.8302\n",
            "Epoch 142/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0932 - accuracy: 0.9677 - val_loss: 0.9870 - val_accuracy: 0.8315\n",
            "Epoch 143/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0900 - accuracy: 0.9703 - val_loss: 1.0165 - val_accuracy: 0.8273\n",
            "Epoch 144/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0897 - accuracy: 0.9697 - val_loss: 1.0078 - val_accuracy: 0.8300\n",
            "Epoch 145/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0898 - accuracy: 0.9699 - val_loss: 1.0299 - val_accuracy: 0.8333\n",
            "Epoch 146/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0855 - accuracy: 0.9711 - val_loss: 1.0458 - val_accuracy: 0.8300\n",
            "Epoch 147/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0871 - accuracy: 0.9704 - val_loss: 1.0422 - val_accuracy: 0.8312\n",
            "Epoch 148/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0896 - accuracy: 0.9699 - val_loss: 1.0416 - val_accuracy: 0.8272\n",
            "Epoch 149/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0797 - accuracy: 0.9733 - val_loss: 1.1023 - val_accuracy: 0.8338\n",
            "Epoch 150/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0800 - accuracy: 0.9733 - val_loss: 1.0906 - val_accuracy: 0.8310\n",
            "Epoch 151/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0810 - accuracy: 0.9725 - val_loss: 1.1099 - val_accuracy: 0.8337\n",
            "Epoch 152/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0783 - accuracy: 0.9736 - val_loss: 1.1183 - val_accuracy: 0.8287\n",
            "Epoch 153/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0778 - accuracy: 0.9740 - val_loss: 1.1404 - val_accuracy: 0.8230\n",
            "Epoch 154/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0766 - accuracy: 0.9749 - val_loss: 1.1539 - val_accuracy: 0.8335\n",
            "Epoch 155/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0763 - accuracy: 0.9745 - val_loss: 1.1563 - val_accuracy: 0.8290\n",
            "Epoch 156/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0751 - accuracy: 0.9748 - val_loss: 1.1520 - val_accuracy: 0.8303\n",
            "Epoch 157/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0712 - accuracy: 0.9764 - val_loss: 1.1720 - val_accuracy: 0.8308\n",
            "Epoch 158/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0705 - accuracy: 0.9765 - val_loss: 1.1769 - val_accuracy: 0.8280\n",
            "Epoch 159/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0720 - accuracy: 0.9759 - val_loss: 1.1989 - val_accuracy: 0.8283\n",
            "Epoch 160/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0679 - accuracy: 0.9779 - val_loss: 1.1968 - val_accuracy: 0.8283\n",
            "Epoch 161/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0678 - accuracy: 0.9773 - val_loss: 1.2305 - val_accuracy: 0.8305\n",
            "Epoch 162/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0673 - accuracy: 0.9778 - val_loss: 1.2269 - val_accuracy: 0.8282\n",
            "Epoch 163/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0697 - accuracy: 0.9769 - val_loss: 1.2286 - val_accuracy: 0.8298\n",
            "Epoch 164/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0642 - accuracy: 0.9791 - val_loss: 1.2520 - val_accuracy: 0.8297\n",
            "Epoch 165/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0622 - accuracy: 0.9800 - val_loss: 1.2689 - val_accuracy: 0.8303\n",
            "Epoch 166/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0632 - accuracy: 0.9795 - val_loss: 1.2585 - val_accuracy: 0.8287\n",
            "Epoch 167/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0607 - accuracy: 0.9803 - val_loss: 1.3148 - val_accuracy: 0.8307\n",
            "Epoch 168/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0611 - accuracy: 0.9803 - val_loss: 1.2807 - val_accuracy: 0.8302\n",
            "Epoch 169/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0624 - accuracy: 0.9801 - val_loss: 1.3211 - val_accuracy: 0.8293\n",
            "Epoch 170/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0561 - accuracy: 0.9819 - val_loss: 1.3460 - val_accuracy: 0.8273\n",
            "Epoch 171/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0581 - accuracy: 0.9809 - val_loss: 1.3512 - val_accuracy: 0.8315\n",
            "Epoch 172/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0611 - accuracy: 0.9797 - val_loss: 1.3616 - val_accuracy: 0.8313\n",
            "Epoch 173/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0533 - accuracy: 0.9833 - val_loss: 1.3702 - val_accuracy: 0.8255\n",
            "Epoch 174/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0531 - accuracy: 0.9830 - val_loss: 1.4019 - val_accuracy: 0.8297\n",
            "Epoch 175/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0570 - accuracy: 0.9814 - val_loss: 1.3986 - val_accuracy: 0.8318\n",
            "Epoch 176/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 1.4247 - val_accuracy: 0.8295\n",
            "Epoch 177/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0530 - accuracy: 0.9828 - val_loss: 1.4311 - val_accuracy: 0.8273\n",
            "Epoch 178/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0560 - accuracy: 0.9820 - val_loss: 1.4084 - val_accuracy: 0.8212\n",
            "Epoch 179/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0596 - accuracy: 0.9803 - val_loss: 1.4310 - val_accuracy: 0.8240\n",
            "Epoch 180/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0459 - accuracy: 0.9858 - val_loss: 1.4570 - val_accuracy: 0.8312\n",
            "Epoch 181/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0507 - accuracy: 0.9839 - val_loss: 1.4639 - val_accuracy: 0.8275\n",
            "Epoch 182/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0478 - accuracy: 0.9849 - val_loss: 1.4993 - val_accuracy: 0.8293\n",
            "Epoch 183/250\n",
            "1782/1782 [==============================] - 29s 16ms/step - loss: 0.0490 - accuracy: 0.9846 - val_loss: 1.5035 - val_accuracy: 0.8292\n",
            "Epoch 184/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0492 - accuracy: 0.9841 - val_loss: 1.5048 - val_accuracy: 0.8282\n",
            "Epoch 185/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0436 - accuracy: 0.9867 - val_loss: 1.5002 - val_accuracy: 0.8248\n",
            "Epoch 186/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 1.5237 - val_accuracy: 0.8263\n",
            "Epoch 187/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 1.5388 - val_accuracy: 0.8278\n",
            "Epoch 188/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0438 - accuracy: 0.9860 - val_loss: 1.5842 - val_accuracy: 0.8285\n",
            "Epoch 189/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0474 - accuracy: 0.9849 - val_loss: 1.5317 - val_accuracy: 0.8253\n",
            "Epoch 190/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0399 - accuracy: 0.9874 - val_loss: 1.5595 - val_accuracy: 0.8267\n",
            "Epoch 191/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0448 - accuracy: 0.9859 - val_loss: 1.6087 - val_accuracy: 0.8310\n",
            "Epoch 192/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0419 - accuracy: 0.9873 - val_loss: 1.6201 - val_accuracy: 0.8318\n",
            "Epoch 193/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0433 - accuracy: 0.9867 - val_loss: 1.5974 - val_accuracy: 0.8282\n",
            "Epoch 194/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 1.6156 - val_accuracy: 0.8270\n",
            "Epoch 195/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 1.6141 - val_accuracy: 0.8257\n",
            "Epoch 196/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0384 - accuracy: 0.9880 - val_loss: 1.6440 - val_accuracy: 0.8228\n",
            "Epoch 197/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 1.6684 - val_accuracy: 0.8223\n",
            "Epoch 198/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0382 - accuracy: 0.9880 - val_loss: 1.6914 - val_accuracy: 0.8285\n",
            "Epoch 199/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0382 - accuracy: 0.9881 - val_loss: 1.6499 - val_accuracy: 0.8262\n",
            "Epoch 200/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 1.6602 - val_accuracy: 0.8268\n",
            "Epoch 201/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 1.6832 - val_accuracy: 0.8255\n",
            "Epoch 202/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 1.7284 - val_accuracy: 0.8287\n",
            "Epoch 203/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 1.7299 - val_accuracy: 0.8230\n",
            "Epoch 204/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0376 - accuracy: 0.9880 - val_loss: 1.7412 - val_accuracy: 0.8250\n",
            "Epoch 205/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0351 - accuracy: 0.9895 - val_loss: 1.7490 - val_accuracy: 0.8228\n",
            "Epoch 206/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 1.7839 - val_accuracy: 0.8273\n",
            "Epoch 207/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0346 - accuracy: 0.9893 - val_loss: 1.7425 - val_accuracy: 0.8242\n",
            "Epoch 208/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0341 - accuracy: 0.9897 - val_loss: 1.8155 - val_accuracy: 0.8253\n",
            "Epoch 209/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0348 - accuracy: 0.9896 - val_loss: 1.7815 - val_accuracy: 0.8273\n",
            "Epoch 210/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 1.8213 - val_accuracy: 0.8267\n",
            "Epoch 211/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0334 - accuracy: 0.9898 - val_loss: 1.8000 - val_accuracy: 0.8283\n",
            "Epoch 212/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 1.8371 - val_accuracy: 0.8307\n",
            "Epoch 213/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 1.8099 - val_accuracy: 0.8267\n",
            "Epoch 214/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0294 - accuracy: 0.9909 - val_loss: 1.8367 - val_accuracy: 0.8290\n",
            "Epoch 215/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0301 - accuracy: 0.9909 - val_loss: 1.8538 - val_accuracy: 0.8262\n",
            "Epoch 216/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0318 - accuracy: 0.9906 - val_loss: 1.8472 - val_accuracy: 0.8248\n",
            "Epoch 217/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0320 - accuracy: 0.9905 - val_loss: 1.8625 - val_accuracy: 0.8260\n",
            "Epoch 218/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 1.8990 - val_accuracy: 0.8260\n",
            "Epoch 219/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0297 - accuracy: 0.9908 - val_loss: 1.8877 - val_accuracy: 0.8268\n",
            "Epoch 220/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0273 - accuracy: 0.9918 - val_loss: 1.9252 - val_accuracy: 0.8238\n",
            "Epoch 221/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0294 - accuracy: 0.9912 - val_loss: 1.9082 - val_accuracy: 0.8293\n",
            "Epoch 222/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 1.9299 - val_accuracy: 0.8240\n",
            "Epoch 223/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0271 - accuracy: 0.9920 - val_loss: 1.9107 - val_accuracy: 0.8288\n",
            "Epoch 224/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 1.8928 - val_accuracy: 0.8253\n",
            "Epoch 225/250\n",
            "1782/1782 [==============================] - 27s 15ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 1.9227 - val_accuracy: 0.8278\n",
            "Epoch 226/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0256 - accuracy: 0.9924 - val_loss: 1.9473 - val_accuracy: 0.8270\n",
            "Epoch 227/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 1.9521 - val_accuracy: 0.8260\n",
            "Epoch 228/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 1.9623 - val_accuracy: 0.8223\n",
            "Epoch 229/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 1.9404 - val_accuracy: 0.8245\n",
            "Epoch 230/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0272 - accuracy: 0.9919 - val_loss: 1.9562 - val_accuracy: 0.8240\n",
            "Epoch 231/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0269 - accuracy: 0.9925 - val_loss: 1.9473 - val_accuracy: 0.8270\n",
            "Epoch 232/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0280 - accuracy: 0.9916 - val_loss: 1.9638 - val_accuracy: 0.8280\n",
            "Epoch 233/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0252 - accuracy: 0.9929 - val_loss: 1.9512 - val_accuracy: 0.8242\n",
            "Epoch 234/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0261 - accuracy: 0.9925 - val_loss: 1.9947 - val_accuracy: 0.8240\n",
            "Epoch 235/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0241 - accuracy: 0.9929 - val_loss: 1.9965 - val_accuracy: 0.8310\n",
            "Epoch 236/250\n",
            "1782/1782 [==============================] - 28s 15ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 1.9915 - val_accuracy: 0.8193\n",
            "Epoch 237/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 1.9840 - val_accuracy: 0.8295\n",
            "Epoch 238/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0272 - accuracy: 0.9919 - val_loss: 2.0126 - val_accuracy: 0.8278\n",
            "Epoch 239/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0206 - accuracy: 0.9941 - val_loss: 2.0313 - val_accuracy: 0.8278\n",
            "Epoch 240/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 2.0495 - val_accuracy: 0.8282\n",
            "Epoch 241/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0252 - accuracy: 0.9923 - val_loss: 2.0563 - val_accuracy: 0.8255\n",
            "Epoch 242/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0269 - accuracy: 0.9922 - val_loss: 2.0186 - val_accuracy: 0.8270\n",
            "Epoch 243/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 2.0576 - val_accuracy: 0.8268\n",
            "Epoch 244/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 2.0415 - val_accuracy: 0.8248\n",
            "Epoch 245/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 2.0298 - val_accuracy: 0.8263\n",
            "Epoch 246/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0214 - accuracy: 0.9939 - val_loss: 2.1036 - val_accuracy: 0.8267\n",
            "Epoch 247/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 2.0871 - val_accuracy: 0.8283\n",
            "Epoch 248/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0185 - accuracy: 0.9950 - val_loss: 2.1371 - val_accuracy: 0.8297\n",
            "Epoch 249/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0223 - accuracy: 0.9936 - val_loss: 2.1262 - val_accuracy: 0.8278\n",
            "Epoch 250/250\n",
            "1782/1782 [==============================] - 28s 16ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 2.1494 - val_accuracy: 0.8238\n",
            "CPU times: user 4h 4min 7s, sys: 1h 14min 3s, total: 5h 18min 11s\n",
            "Wall time: 1h 56min 14s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jvC6gJlMts47"
      },
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "encoder\n",
        ",tf.keras.layers.Embedding(input_dim=len(encoder_3000.get_vocabulary())\n",
        ",output_dim=64\n",
        ",mask_zero=True)\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128,  return_sequences=True))\n",
        ",tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))\n",
        ",tf.keras.layers.Dense(64, activation='relu')\n",
        ",tf.keras.layers.Dense(4,activation='softmax')])\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(1e-4),loss=tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "orinE2--9xKm",
        "outputId": "d2bb3c9b-b575-4d4b-da59-3152ab8b960f"
      },
      "source": [
        "%%time\n",
        "history3 = model3.fit(train_dataset ,epochs = 250 ,validation_data=validation_dataset ,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "1782/1782 [==============================] - 70s 30ms/step - loss: 0.6930 - accuracy: 0.7199 - val_loss: 0.4818 - val_accuracy: 0.8340\n",
            "Epoch 2/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.4343 - accuracy: 0.8447 - val_loss: 0.4063 - val_accuracy: 0.8597\n",
            "Epoch 3/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.4025 - accuracy: 0.8560 - val_loss: 0.3975 - val_accuracy: 0.8618\n",
            "Epoch 4/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3886 - accuracy: 0.8600 - val_loss: 0.4007 - val_accuracy: 0.8578\n",
            "Epoch 5/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3807 - accuracy: 0.8631 - val_loss: 0.3860 - val_accuracy: 0.8635\n",
            "Epoch 6/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3755 - accuracy: 0.8644 - val_loss: 0.3916 - val_accuracy: 0.8628\n",
            "Epoch 7/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3706 - accuracy: 0.8652 - val_loss: 0.3915 - val_accuracy: 0.8572\n",
            "Epoch 8/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3668 - accuracy: 0.8668 - val_loss: 0.3774 - val_accuracy: 0.8660\n",
            "Epoch 9/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3628 - accuracy: 0.8689 - val_loss: 0.3788 - val_accuracy: 0.8630\n",
            "Epoch 10/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3594 - accuracy: 0.8694 - val_loss: 0.3788 - val_accuracy: 0.8655\n",
            "Epoch 11/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3565 - accuracy: 0.8696 - val_loss: 0.3833 - val_accuracy: 0.8638\n",
            "Epoch 12/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3537 - accuracy: 0.8707 - val_loss: 0.3797 - val_accuracy: 0.8643\n",
            "Epoch 13/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3512 - accuracy: 0.8715 - val_loss: 0.3767 - val_accuracy: 0.8652\n",
            "Epoch 14/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3485 - accuracy: 0.8730 - val_loss: 0.3748 - val_accuracy: 0.8678\n",
            "Epoch 15/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3460 - accuracy: 0.8741 - val_loss: 0.3741 - val_accuracy: 0.8662\n",
            "Epoch 16/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.3430 - accuracy: 0.8747 - val_loss: 0.3757 - val_accuracy: 0.8655\n",
            "Epoch 17/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3405 - accuracy: 0.8758 - val_loss: 0.3793 - val_accuracy: 0.8645\n",
            "Epoch 18/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3377 - accuracy: 0.8765 - val_loss: 0.3722 - val_accuracy: 0.8680\n",
            "Epoch 19/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3350 - accuracy: 0.8778 - val_loss: 0.3768 - val_accuracy: 0.8658\n",
            "Epoch 20/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3326 - accuracy: 0.8787 - val_loss: 0.3726 - val_accuracy: 0.8635\n",
            "Epoch 21/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3292 - accuracy: 0.8802 - val_loss: 0.3744 - val_accuracy: 0.8643\n",
            "Epoch 22/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3269 - accuracy: 0.8806 - val_loss: 0.3738 - val_accuracy: 0.8663\n",
            "Epoch 23/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3239 - accuracy: 0.8820 - val_loss: 0.3771 - val_accuracy: 0.8655\n",
            "Epoch 24/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3213 - accuracy: 0.8831 - val_loss: 0.3766 - val_accuracy: 0.8625\n",
            "Epoch 25/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3180 - accuracy: 0.8841 - val_loss: 0.3741 - val_accuracy: 0.8670\n",
            "Epoch 26/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3150 - accuracy: 0.8850 - val_loss: 0.3738 - val_accuracy: 0.8648\n",
            "Epoch 27/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.3126 - accuracy: 0.8857 - val_loss: 0.3777 - val_accuracy: 0.8647\n",
            "Epoch 28/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3096 - accuracy: 0.8869 - val_loss: 0.3759 - val_accuracy: 0.8648\n",
            "Epoch 29/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3066 - accuracy: 0.8883 - val_loss: 0.3758 - val_accuracy: 0.8655\n",
            "Epoch 30/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3043 - accuracy: 0.8883 - val_loss: 0.3738 - val_accuracy: 0.8628\n",
            "Epoch 31/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.3004 - accuracy: 0.8900 - val_loss: 0.3836 - val_accuracy: 0.8625\n",
            "Epoch 32/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2981 - accuracy: 0.8915 - val_loss: 0.3862 - val_accuracy: 0.8647\n",
            "Epoch 33/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2944 - accuracy: 0.8931 - val_loss: 0.3868 - val_accuracy: 0.8615\n",
            "Epoch 34/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2916 - accuracy: 0.8937 - val_loss: 0.3863 - val_accuracy: 0.8615\n",
            "Epoch 35/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2884 - accuracy: 0.8950 - val_loss: 0.3862 - val_accuracy: 0.8647\n",
            "Epoch 36/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2849 - accuracy: 0.8960 - val_loss: 0.3902 - val_accuracy: 0.8610\n",
            "Epoch 37/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2829 - accuracy: 0.8970 - val_loss: 0.3931 - val_accuracy: 0.8628\n",
            "Epoch 38/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2800 - accuracy: 0.8981 - val_loss: 0.3970 - val_accuracy: 0.8620\n",
            "Epoch 39/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2761 - accuracy: 0.8996 - val_loss: 0.3994 - val_accuracy: 0.8633\n",
            "Epoch 40/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2729 - accuracy: 0.9015 - val_loss: 0.3923 - val_accuracy: 0.8633\n",
            "Epoch 41/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2697 - accuracy: 0.9020 - val_loss: 0.3969 - val_accuracy: 0.8637\n",
            "Epoch 42/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2661 - accuracy: 0.9037 - val_loss: 0.4033 - val_accuracy: 0.8607\n",
            "Epoch 43/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2633 - accuracy: 0.9048 - val_loss: 0.4071 - val_accuracy: 0.8610\n",
            "Epoch 44/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2600 - accuracy: 0.9059 - val_loss: 0.4076 - val_accuracy: 0.8608\n",
            "Epoch 45/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2601 - accuracy: 0.9059 - val_loss: 0.4073 - val_accuracy: 0.8632\n",
            "Epoch 46/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2542 - accuracy: 0.9077 - val_loss: 0.4238 - val_accuracy: 0.8605\n",
            "Epoch 47/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2494 - accuracy: 0.9101 - val_loss: 0.4190 - val_accuracy: 0.8633\n",
            "Epoch 48/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2489 - accuracy: 0.9101 - val_loss: 0.4210 - val_accuracy: 0.8603\n",
            "Epoch 49/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2435 - accuracy: 0.9120 - val_loss: 0.4275 - val_accuracy: 0.8582\n",
            "Epoch 50/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2410 - accuracy: 0.9130 - val_loss: 0.4240 - val_accuracy: 0.8628\n",
            "Epoch 51/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2372 - accuracy: 0.9144 - val_loss: 0.4349 - val_accuracy: 0.8577\n",
            "Epoch 52/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.2342 - accuracy: 0.9158 - val_loss: 0.4320 - val_accuracy: 0.8605\n",
            "Epoch 53/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2310 - accuracy: 0.9173 - val_loss: 0.4406 - val_accuracy: 0.8600\n",
            "Epoch 54/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2285 - accuracy: 0.9188 - val_loss: 0.4373 - val_accuracy: 0.8613\n",
            "Epoch 55/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2251 - accuracy: 0.9197 - val_loss: 0.4491 - val_accuracy: 0.8585\n",
            "Epoch 56/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2216 - accuracy: 0.9204 - val_loss: 0.4508 - val_accuracy: 0.8583\n",
            "Epoch 57/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2193 - accuracy: 0.9210 - val_loss: 0.4491 - val_accuracy: 0.8552\n",
            "Epoch 58/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.2147 - accuracy: 0.9224 - val_loss: 0.4499 - val_accuracy: 0.8540\n",
            "Epoch 59/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2120 - accuracy: 0.9243 - val_loss: 0.4734 - val_accuracy: 0.8580\n",
            "Epoch 60/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2094 - accuracy: 0.9249 - val_loss: 0.4743 - val_accuracy: 0.8552\n",
            "Epoch 61/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2057 - accuracy: 0.9265 - val_loss: 0.4732 - val_accuracy: 0.8558\n",
            "Epoch 62/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.2030 - accuracy: 0.9273 - val_loss: 0.4889 - val_accuracy: 0.8585\n",
            "Epoch 63/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1999 - accuracy: 0.9296 - val_loss: 0.4833 - val_accuracy: 0.8527\n",
            "Epoch 64/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1975 - accuracy: 0.9299 - val_loss: 0.4887 - val_accuracy: 0.8542\n",
            "Epoch 65/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1923 - accuracy: 0.9316 - val_loss: 0.4978 - val_accuracy: 0.8545\n",
            "Epoch 66/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1951 - accuracy: 0.9309 - val_loss: 0.4946 - val_accuracy: 0.8535\n",
            "Epoch 67/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1886 - accuracy: 0.9331 - val_loss: 0.5049 - val_accuracy: 0.8528\n",
            "Epoch 68/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1843 - accuracy: 0.9349 - val_loss: 0.5228 - val_accuracy: 0.8552\n",
            "Epoch 69/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1816 - accuracy: 0.9362 - val_loss: 0.5161 - val_accuracy: 0.8542\n",
            "Epoch 70/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1809 - accuracy: 0.9363 - val_loss: 0.5318 - val_accuracy: 0.8492\n",
            "Epoch 71/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1786 - accuracy: 0.9372 - val_loss: 0.5363 - val_accuracy: 0.8462\n",
            "Epoch 72/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1739 - accuracy: 0.9393 - val_loss: 0.5486 - val_accuracy: 0.8468\n",
            "Epoch 73/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1736 - accuracy: 0.9390 - val_loss: 0.5476 - val_accuracy: 0.8515\n",
            "Epoch 74/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1694 - accuracy: 0.9404 - val_loss: 0.5584 - val_accuracy: 0.8492\n",
            "Epoch 75/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1676 - accuracy: 0.9409 - val_loss: 0.5713 - val_accuracy: 0.8505\n",
            "Epoch 76/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1619 - accuracy: 0.9428 - val_loss: 0.5870 - val_accuracy: 0.8490\n",
            "Epoch 77/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1625 - accuracy: 0.9426 - val_loss: 0.5764 - val_accuracy: 0.8487\n",
            "Epoch 78/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1582 - accuracy: 0.9446 - val_loss: 0.5906 - val_accuracy: 0.8480\n",
            "Epoch 79/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1570 - accuracy: 0.9453 - val_loss: 0.6038 - val_accuracy: 0.8468\n",
            "Epoch 80/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1544 - accuracy: 0.9467 - val_loss: 0.6125 - val_accuracy: 0.8430\n",
            "Epoch 81/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1509 - accuracy: 0.9473 - val_loss: 0.6135 - val_accuracy: 0.8435\n",
            "Epoch 82/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1472 - accuracy: 0.9483 - val_loss: 0.6111 - val_accuracy: 0.8492\n",
            "Epoch 83/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1461 - accuracy: 0.9495 - val_loss: 0.6308 - val_accuracy: 0.8472\n",
            "Epoch 84/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1424 - accuracy: 0.9502 - val_loss: 0.6200 - val_accuracy: 0.8475\n",
            "Epoch 85/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1543 - accuracy: 0.9465 - val_loss: 0.6147 - val_accuracy: 0.8475\n",
            "Epoch 86/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1350 - accuracy: 0.9530 - val_loss: 0.6578 - val_accuracy: 0.8455\n",
            "Epoch 87/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1382 - accuracy: 0.9517 - val_loss: 0.6396 - val_accuracy: 0.8480\n",
            "Epoch 88/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1343 - accuracy: 0.9530 - val_loss: 0.6511 - val_accuracy: 0.8470\n",
            "Epoch 89/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1315 - accuracy: 0.9544 - val_loss: 0.6713 - val_accuracy: 0.8455\n",
            "Epoch 90/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1291 - accuracy: 0.9548 - val_loss: 0.6906 - val_accuracy: 0.8402\n",
            "Epoch 91/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1266 - accuracy: 0.9565 - val_loss: 0.6768 - val_accuracy: 0.8452\n",
            "Epoch 92/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1262 - accuracy: 0.9559 - val_loss: 0.6888 - val_accuracy: 0.8430\n",
            "Epoch 93/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1215 - accuracy: 0.9577 - val_loss: 0.6942 - val_accuracy: 0.8478\n",
            "Epoch 94/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.1203 - accuracy: 0.9585 - val_loss: 0.7149 - val_accuracy: 0.8477\n",
            "Epoch 95/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.1178 - accuracy: 0.9594 - val_loss: 0.7060 - val_accuracy: 0.8468\n",
            "Epoch 96/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1145 - accuracy: 0.9601 - val_loss: 0.7261 - val_accuracy: 0.8438\n",
            "Epoch 97/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.1140 - accuracy: 0.9606 - val_loss: 0.7296 - val_accuracy: 0.8423\n",
            "Epoch 98/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1124 - accuracy: 0.9614 - val_loss: 0.7607 - val_accuracy: 0.8425\n",
            "Epoch 99/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1145 - accuracy: 0.9602 - val_loss: 0.7439 - val_accuracy: 0.8410\n",
            "Epoch 100/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.7573 - val_accuracy: 0.8442\n",
            "Epoch 101/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1063 - accuracy: 0.9637 - val_loss: 0.8170 - val_accuracy: 0.8347\n",
            "Epoch 102/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1056 - accuracy: 0.9639 - val_loss: 0.7857 - val_accuracy: 0.8433\n",
            "Epoch 103/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1052 - accuracy: 0.9635 - val_loss: 0.8026 - val_accuracy: 0.8422\n",
            "Epoch 104/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.1039 - accuracy: 0.9643 - val_loss: 0.7947 - val_accuracy: 0.8428\n",
            "Epoch 105/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0999 - accuracy: 0.9658 - val_loss: 0.7959 - val_accuracy: 0.8378\n",
            "Epoch 106/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0984 - accuracy: 0.9664 - val_loss: 0.8291 - val_accuracy: 0.8420\n",
            "Epoch 107/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0964 - accuracy: 0.9669 - val_loss: 0.8320 - val_accuracy: 0.8387\n",
            "Epoch 108/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0959 - accuracy: 0.9666 - val_loss: 0.8169 - val_accuracy: 0.8407\n",
            "Epoch 109/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0942 - accuracy: 0.9677 - val_loss: 0.8443 - val_accuracy: 0.8403\n",
            "Epoch 110/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0879 - accuracy: 0.9700 - val_loss: 0.8592 - val_accuracy: 0.8410\n",
            "Epoch 111/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0885 - accuracy: 0.9697 - val_loss: 0.8878 - val_accuracy: 0.8407\n",
            "Epoch 112/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0861 - accuracy: 0.9704 - val_loss: 0.9018 - val_accuracy: 0.8377\n",
            "Epoch 113/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0933 - accuracy: 0.9683 - val_loss: 0.8544 - val_accuracy: 0.8407\n",
            "Epoch 114/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0849 - accuracy: 0.9707 - val_loss: 0.8996 - val_accuracy: 0.8375\n",
            "Epoch 115/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0814 - accuracy: 0.9722 - val_loss: 0.8877 - val_accuracy: 0.8343\n",
            "Epoch 116/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0831 - accuracy: 0.9718 - val_loss: 0.8930 - val_accuracy: 0.8372\n",
            "Epoch 117/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0812 - accuracy: 0.9728 - val_loss: 0.8883 - val_accuracy: 0.8347\n",
            "Epoch 118/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0771 - accuracy: 0.9738 - val_loss: 0.9423 - val_accuracy: 0.8373\n",
            "Epoch 119/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0765 - accuracy: 0.9735 - val_loss: 0.9383 - val_accuracy: 0.8395\n",
            "Epoch 120/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0829 - accuracy: 0.9723 - val_loss: 0.9361 - val_accuracy: 0.8368\n",
            "Epoch 121/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0733 - accuracy: 0.9759 - val_loss: 0.9567 - val_accuracy: 0.8407\n",
            "Epoch 122/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0734 - accuracy: 0.9752 - val_loss: 0.9484 - val_accuracy: 0.8367\n",
            "Epoch 123/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0704 - accuracy: 0.9764 - val_loss: 0.9781 - val_accuracy: 0.8400\n",
            "Epoch 124/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0918 - accuracy: 0.9690 - val_loss: 0.9347 - val_accuracy: 0.8408\n",
            "Epoch 125/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0665 - accuracy: 0.9776 - val_loss: 0.9409 - val_accuracy: 0.8382\n",
            "Epoch 126/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0677 - accuracy: 0.9773 - val_loss: 0.9842 - val_accuracy: 0.8413\n",
            "Epoch 127/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0666 - accuracy: 0.9775 - val_loss: 0.9931 - val_accuracy: 0.8388\n",
            "Epoch 128/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0688 - accuracy: 0.9772 - val_loss: 1.0279 - val_accuracy: 0.8385\n",
            "Epoch 129/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0683 - accuracy: 0.9770 - val_loss: 1.0012 - val_accuracy: 0.8377\n",
            "Epoch 130/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0607 - accuracy: 0.9798 - val_loss: 1.0447 - val_accuracy: 0.8393\n",
            "Epoch 131/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0675 - accuracy: 0.9773 - val_loss: 1.0560 - val_accuracy: 0.8362\n",
            "Epoch 132/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0664 - accuracy: 0.9779 - val_loss: 1.0255 - val_accuracy: 0.8385\n",
            "Epoch 133/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0616 - accuracy: 0.9791 - val_loss: 1.0426 - val_accuracy: 0.8415\n",
            "Epoch 134/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0586 - accuracy: 0.9802 - val_loss: 1.0307 - val_accuracy: 0.8415\n",
            "Epoch 135/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0629 - accuracy: 0.9790 - val_loss: 1.0567 - val_accuracy: 0.8385\n",
            "Epoch 136/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0541 - accuracy: 0.9823 - val_loss: 1.0672 - val_accuracy: 0.8393\n",
            "Epoch 137/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0652 - accuracy: 0.9785 - val_loss: 1.0631 - val_accuracy: 0.8397\n",
            "Epoch 138/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0573 - accuracy: 0.9810 - val_loss: 1.0835 - val_accuracy: 0.8375\n",
            "Epoch 139/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0548 - accuracy: 0.9818 - val_loss: 1.0978 - val_accuracy: 0.8348\n",
            "Epoch 140/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0606 - accuracy: 0.9795 - val_loss: 1.1133 - val_accuracy: 0.8387\n",
            "Epoch 141/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0489 - accuracy: 0.9839 - val_loss: 1.1082 - val_accuracy: 0.8377\n",
            "Epoch 142/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0578 - accuracy: 0.9809 - val_loss: 1.1349 - val_accuracy: 0.8360\n",
            "Epoch 143/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0532 - accuracy: 0.9825 - val_loss: 1.1252 - val_accuracy: 0.8337\n",
            "Epoch 144/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0550 - accuracy: 0.9820 - val_loss: 1.1385 - val_accuracy: 0.8343\n",
            "Epoch 145/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0564 - accuracy: 0.9815 - val_loss: 1.1209 - val_accuracy: 0.8400\n",
            "Epoch 146/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0491 - accuracy: 0.9840 - val_loss: 1.1565 - val_accuracy: 0.8332\n",
            "Epoch 147/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0537 - accuracy: 0.9823 - val_loss: 1.1611 - val_accuracy: 0.8395\n",
            "Epoch 148/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0448 - accuracy: 0.9855 - val_loss: 1.1854 - val_accuracy: 0.8377\n",
            "Epoch 149/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0709 - accuracy: 0.9772 - val_loss: 1.1016 - val_accuracy: 0.8387\n",
            "Epoch 150/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0444 - accuracy: 0.9858 - val_loss: 1.1873 - val_accuracy: 0.8337\n",
            "Epoch 151/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0421 - accuracy: 0.9865 - val_loss: 1.1719 - val_accuracy: 0.8328\n",
            "Epoch 152/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0487 - accuracy: 0.9840 - val_loss: 1.1932 - val_accuracy: 0.8353\n",
            "Epoch 153/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0477 - accuracy: 0.9845 - val_loss: 1.1931 - val_accuracy: 0.8370\n",
            "Epoch 154/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0573 - accuracy: 0.9822 - val_loss: 1.1644 - val_accuracy: 0.8388\n",
            "Epoch 155/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0405 - accuracy: 0.9872 - val_loss: 1.1892 - val_accuracy: 0.8338\n",
            "Epoch 156/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0481 - accuracy: 0.9845 - val_loss: 1.2144 - val_accuracy: 0.8342\n",
            "Epoch 157/250\n",
            "1782/1782 [==============================] - 47s 27ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 1.2351 - val_accuracy: 0.8350\n",
            "Epoch 158/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0470 - accuracy: 0.9846 - val_loss: 1.2174 - val_accuracy: 0.8352\n",
            "Epoch 159/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0447 - accuracy: 0.9856 - val_loss: 1.2039 - val_accuracy: 0.8367\n",
            "Epoch 160/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 1.2339 - val_accuracy: 0.8345\n",
            "Epoch 161/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0437 - accuracy: 0.9858 - val_loss: 1.2515 - val_accuracy: 0.8392\n",
            "Epoch 162/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0382 - accuracy: 0.9875 - val_loss: 1.2567 - val_accuracy: 0.8353\n",
            "Epoch 163/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0410 - accuracy: 0.9868 - val_loss: 1.2632 - val_accuracy: 0.8345\n",
            "Epoch 164/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 1.2563 - val_accuracy: 0.8315\n",
            "Epoch 165/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0437 - accuracy: 0.9855 - val_loss: 1.2744 - val_accuracy: 0.8333\n",
            "Epoch 166/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0396 - accuracy: 0.9868 - val_loss: 1.2956 - val_accuracy: 0.8320\n",
            "Epoch 167/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0379 - accuracy: 0.9879 - val_loss: 1.2816 - val_accuracy: 0.8330\n",
            "Epoch 168/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 1.3072 - val_accuracy: 0.8367\n",
            "Epoch 169/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0396 - accuracy: 0.9874 - val_loss: 1.2994 - val_accuracy: 0.8375\n",
            "Epoch 170/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 1.2981 - val_accuracy: 0.8310\n",
            "Epoch 171/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0332 - accuracy: 0.9897 - val_loss: 1.3646 - val_accuracy: 0.8330\n",
            "Epoch 172/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0380 - accuracy: 0.9879 - val_loss: 1.3343 - val_accuracy: 0.8328\n",
            "Epoch 173/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0380 - accuracy: 0.9877 - val_loss: 1.3255 - val_accuracy: 0.8390\n",
            "Epoch 174/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 1.3663 - val_accuracy: 0.8315\n",
            "Epoch 175/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0373 - accuracy: 0.9878 - val_loss: 1.3559 - val_accuracy: 0.8323\n",
            "Epoch 176/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0358 - accuracy: 0.9885 - val_loss: 1.3745 - val_accuracy: 0.8350\n",
            "Epoch 177/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 1.3681 - val_accuracy: 0.8348\n",
            "Epoch 178/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0373 - accuracy: 0.9880 - val_loss: 1.3413 - val_accuracy: 0.8372\n",
            "Epoch 179/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0328 - accuracy: 0.9895 - val_loss: 1.3780 - val_accuracy: 0.8357\n",
            "Epoch 180/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 1.3483 - val_accuracy: 0.8340\n",
            "Epoch 181/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 1.3575 - val_accuracy: 0.8393\n",
            "Epoch 182/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 1.3513 - val_accuracy: 0.8338\n",
            "Epoch 183/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 1.3892 - val_accuracy: 0.8387\n",
            "Epoch 184/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 1.3939 - val_accuracy: 0.8400\n",
            "Epoch 185/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0291 - accuracy: 0.9907 - val_loss: 1.3952 - val_accuracy: 0.8385\n",
            "Epoch 186/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 1.4124 - val_accuracy: 0.8367\n",
            "Epoch 187/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 1.4214 - val_accuracy: 0.8363\n",
            "Epoch 188/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 1.4352 - val_accuracy: 0.8328\n",
            "Epoch 189/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 1.3977 - val_accuracy: 0.8347\n",
            "Epoch 190/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0302 - accuracy: 0.9904 - val_loss: 1.4538 - val_accuracy: 0.8360\n",
            "Epoch 191/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0281 - accuracy: 0.9917 - val_loss: 1.4174 - val_accuracy: 0.8352\n",
            "Epoch 192/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 1.4287 - val_accuracy: 0.8377\n",
            "Epoch 193/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 1.4238 - val_accuracy: 0.8342\n",
            "Epoch 194/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 1.4473 - val_accuracy: 0.8350\n",
            "Epoch 195/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0293 - accuracy: 0.9904 - val_loss: 1.4548 - val_accuracy: 0.8367\n",
            "Epoch 196/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 1.4632 - val_accuracy: 0.8348\n",
            "Epoch 197/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0286 - accuracy: 0.9911 - val_loss: 1.4757 - val_accuracy: 0.8347\n",
            "Epoch 198/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 1.4593 - val_accuracy: 0.8343\n",
            "Epoch 199/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 1.4734 - val_accuracy: 0.8377\n",
            "Epoch 200/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 1.4739 - val_accuracy: 0.8323\n",
            "Epoch 201/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0301 - accuracy: 0.9908 - val_loss: 1.4463 - val_accuracy: 0.8313\n",
            "Epoch 202/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0276 - accuracy: 0.9914 - val_loss: 1.4713 - val_accuracy: 0.8378\n",
            "Epoch 203/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0219 - accuracy: 0.9930 - val_loss: 1.4968 - val_accuracy: 0.8340\n",
            "Epoch 204/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0305 - accuracy: 0.9906 - val_loss: 1.4648 - val_accuracy: 0.8385\n",
            "Epoch 205/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 1.4711 - val_accuracy: 0.8338\n",
            "Epoch 206/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 1.5487 - val_accuracy: 0.8337\n",
            "Epoch 207/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 1.4855 - val_accuracy: 0.8373\n",
            "Epoch 208/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0243 - accuracy: 0.9921 - val_loss: 1.4917 - val_accuracy: 0.8363\n",
            "Epoch 209/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 1.5318 - val_accuracy: 0.8402\n",
            "Epoch 210/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 1.4756 - val_accuracy: 0.8375\n",
            "Epoch 211/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0236 - accuracy: 0.9925 - val_loss: 1.5196 - val_accuracy: 0.8355\n",
            "Epoch 212/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0265 - accuracy: 0.9916 - val_loss: 1.5018 - val_accuracy: 0.8327\n",
            "Epoch 213/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 1.5263 - val_accuracy: 0.8357\n",
            "Epoch 214/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 1.5341 - val_accuracy: 0.8355\n",
            "Epoch 215/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0265 - accuracy: 0.9914 - val_loss: 1.5062 - val_accuracy: 0.8337\n",
            "Epoch 216/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 1.5510 - val_accuracy: 0.8365\n",
            "Epoch 217/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 1.5161 - val_accuracy: 0.8377\n",
            "Epoch 218/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0207 - accuracy: 0.9935 - val_loss: 1.5717 - val_accuracy: 0.8397\n",
            "Epoch 219/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0248 - accuracy: 0.9926 - val_loss: 1.5463 - val_accuracy: 0.8353\n",
            "Epoch 220/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 1.5536 - val_accuracy: 0.8353\n",
            "Epoch 221/250\n",
            "1782/1782 [==============================] - 47s 26ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 1.5610 - val_accuracy: 0.8353\n",
            "Epoch 222/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 1.5634 - val_accuracy: 0.8373\n",
            "Epoch 223/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 1.5550 - val_accuracy: 0.8358\n",
            "Epoch 224/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 1.5910 - val_accuracy: 0.8355\n",
            "Epoch 225/250\n",
            "1782/1782 [==============================] - 48s 27ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 1.5921 - val_accuracy: 0.8365\n",
            "Epoch 226/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 1.5713 - val_accuracy: 0.8382\n",
            "Epoch 227/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.5898 - val_accuracy: 0.8368\n",
            "Epoch 228/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 1.5686 - val_accuracy: 0.8363\n",
            "Epoch 229/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 1.6313 - val_accuracy: 0.8348\n",
            "Epoch 230/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 1.5957 - val_accuracy: 0.8372\n",
            "Epoch 231/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0201 - accuracy: 0.9934 - val_loss: 1.6096 - val_accuracy: 0.8375\n",
            "Epoch 232/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 1.6130 - val_accuracy: 0.8363\n",
            "Epoch 233/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0223 - accuracy: 0.9930 - val_loss: 1.6155 - val_accuracy: 0.8337\n",
            "Epoch 234/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 1.6035 - val_accuracy: 0.8338\n",
            "Epoch 235/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 1.6363 - val_accuracy: 0.8375\n",
            "Epoch 236/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 1.6118 - val_accuracy: 0.8382\n",
            "Epoch 237/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 1.6512 - val_accuracy: 0.8383\n",
            "Epoch 238/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0206 - accuracy: 0.9936 - val_loss: 1.6339 - val_accuracy: 0.8373\n",
            "Epoch 239/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 1.6362 - val_accuracy: 0.8355\n",
            "Epoch 240/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 1.6325 - val_accuracy: 0.8362\n",
            "Epoch 241/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 1.6308 - val_accuracy: 0.8345\n",
            "Epoch 242/250\n",
            "1782/1782 [==============================] - 51s 28ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 1.5988 - val_accuracy: 0.8357\n",
            "Epoch 243/250\n",
            "1782/1782 [==============================] - 50s 28ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 1.6020 - val_accuracy: 0.8385\n",
            "Epoch 244/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 1.6486 - val_accuracy: 0.8372\n",
            "Epoch 245/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 1.6409 - val_accuracy: 0.8350\n",
            "Epoch 246/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 1.6156 - val_accuracy: 0.8367\n",
            "Epoch 247/250\n",
            "1782/1782 [==============================] - 49s 28ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 1.6263 - val_accuracy: 0.8355\n",
            "Epoch 248/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 1.6205 - val_accuracy: 0.8347\n",
            "Epoch 249/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 1.6212 - val_accuracy: 0.8355\n",
            "Epoch 250/250\n",
            "1782/1782 [==============================] - 49s 27ms/step - loss: 0.0242 - accuracy: 0.9919 - val_loss: 1.6271 - val_accuracy: 0.8383\n",
            "CPU times: user 6h 57min 47s, sys: 2h 50s, total: 8h 58min 37s\n",
            "Wall time: 3h 23min 13s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "rYU4z8kKt0UE",
        "outputId": "0b8a1f53-3bad-4ee1-eeb7-193f39dd1f72"
      },
      "source": [
        "import pandas as pd\n",
        "results=pd.DataFrame({\n",
        "    'Test': [1,2,3,4,5,6],\n",
        "    'Name': ['1000_shallow', '1000_deep', '2000_shallow', '2000_deep', '3000_shallow', '3000_deep'],\n",
        "    'Train_Time': [118.24, 125.15, 119.38, 200.43, 116.14, 203.13],\n",
        "    'Train_Accuracy': [99.53, 99.48, 99.52, 99.34, 99.33, 99.19],\n",
        "    'Validation_Accuracy': [82.55, 84.03, 83.38, 84.23, 82.38, 83.83]\n",
        "})\n",
        "results"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test</th>\n",
              "      <th>Name</th>\n",
              "      <th>Train_Time</th>\n",
              "      <th>Train_Accuracy</th>\n",
              "      <th>Validation_Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1000_shallow</td>\n",
              "      <td>118.24</td>\n",
              "      <td>99.53</td>\n",
              "      <td>82.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1000_deep</td>\n",
              "      <td>125.15</td>\n",
              "      <td>99.48</td>\n",
              "      <td>84.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2000_shallow</td>\n",
              "      <td>119.38</td>\n",
              "      <td>99.52</td>\n",
              "      <td>83.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2000_deep</td>\n",
              "      <td>200.43</td>\n",
              "      <td>99.34</td>\n",
              "      <td>84.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3000_shallow</td>\n",
              "      <td>116.14</td>\n",
              "      <td>99.33</td>\n",
              "      <td>82.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>3000_deep</td>\n",
              "      <td>203.13</td>\n",
              "      <td>99.19</td>\n",
              "      <td>83.83</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Test          Name  Train_Time  Train_Accuracy  Validation_Accuracy\n",
              "0     1  1000_shallow      118.24           99.53                82.55\n",
              "1     2     1000_deep      125.15           99.48                84.03\n",
              "2     3  2000_shallow      119.38           99.52                83.38\n",
              "3     4     2000_deep      200.43           99.34                84.23\n",
              "4     5  3000_shallow      116.14           99.33                82.38\n",
              "5     6     3000_deep      203.13           99.19                83.83"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}